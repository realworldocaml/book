  <section id="the-compiler-frontend-parsing-and-type-checking" data-type="chapter">
    <h1>The Compiler Frontend: Parsing and <span class="keep-together">Type Checking</span></h1>

    <p>Compiling source code into executable programs is a fairly
    complex libraries, linkers, and assemblers. It's important to
    understand how these fit together to help with your day-to-day
    workflow of developing, debugging, and deploying
    applications.<idx>compilation process/toolchain for</idx></p>

    <p>OCaml has a strong emphasis on static type safety and
    rejects source code that doesn't meet its requirements as early
    as possible. The compiler does this by running the source code
    through a series of checks and transformations. Each stage
    performs its job (e.g., type checking, optimization, or code
    generation) and discards some information from the previous
    stage. The final native code output is low-level assembly code
    that doesn't know anything about the OCaml modules or objects
    that the compiler started with.<idx>static checking</idx><idx>compile-time static checking</idx></p>

    <p>You don't have to do all of this manually, of course. The
    compiler frontends (<code>ocamlc</code> and
    <code>ocamlopt</code>) are invoked via the command line and
    chain the stages together for you. Sometimes though, you'll
    need to dive into the toolchain to hunt down a bug or
    investigate a performance problem. This chapter explains the
    compiler pipeline in more depth so you understand how to
    harness the command-line tools effectively. <idx>OCaml toolchain/ocamlc</idx><idx>OCaml toolchain/ocamlopt</idx></p>

    <p>In this chapter, we'll cover the following topics:</p>

    <ul>
      <li>
        <p>The compilation pipeline and what each stage
        represents</p>
      </li>

      <li>
        <p>Source preprocessing via Camlp4 and the intermediate
        forms</p>
      </li>

      <li>
        <p>The type-checking process, including module
        resolution</p>
      </li>
    </ul>

    <p>The details of the compilation process into executable code
    can be found next, in <a href="23-compiler-backend.html#the-compiler-backend-byte-code-and-native-code" data-type="xref">The Compiler Backend Byte Code And Native
    Code</a>.</p>

    <section id="an-overview-of-the-toolchain" data-type="sect1">
      <h1>An Overview of the Toolchain</h1>

      <p>The OCaml tools accept textual source code as input, using
      the filename extensions <code>.ml</code> and
      <code>.mli</code> for modules and signatures, respectively.
      We explained the basics of the build process in <a href="04-files-modules-and-programs.html#files-modules-and-programs" data-type="xref">Files Modules And Programs</a>, so we'll
      assume you've built a few OCaml programs already by this
      point.<idx>OCaml toolchain/overview of</idx></p>

      <p>Each source file represents a <em>compilation unit</em>
      that is built separately. The compiler generates intermediate
      files with different filename extensions to use as it
      advances through the compilation stages. The linker takes a
      collection of compiled units and produces a standalone
      executable or library archive that can be reused by other
      applications.<idx>compilation units</idx></p>

      <p>The overall compilation pipeline looks like this:
      <idx>compilation process/diagram of</idx></p>

      <figure style="float: 0">
        <img src="images/front-end/pipeline.png"/>
      </figure>

      <p>Notice that the pipeline branches toward the end. OCaml
      has multiple compiler backends that reuse the early stages of
      compilation but produce very different final outputs. The
      <em>bytecode</em> can be run by a portable interpreter and
      can even be transformed into JavaScript (via <a href="http://ocsigen.org/js_of_ocaml">js_of_ocaml</a>) or C source
      code (via <a href="https://github.com/ocaml-bytes/ocamlcc">OCamlCC</a>). The
      <em>native code</em> compiler generates specialized
      executable binaries suitable for high-performance
      applications.<idx>compilation process/compiler source code</idx><idx>code compilers/bytecode vs. native code</idx></p>

      <aside data-type="sidebar">
        <h5>Obtaining the Compiler Source Code</h5>

        <p>Although it's not necessary to understand the examples,
        you may find it useful to have a copy of the OCaml source
        tree checked out while you read through this chapter. The
        source code is available from multiple places:</p>

        <ul>
          <li>
            <p>Stable releases as <em class="filename">zip</em> and
            <em class="filename">tar</em> archives from the
            <a href="http://caml.inria.fr/download.en.html">OCaml
            download site</a></p>
          </li>

          <li>
            <p>A Subversion anonymous mirror of the main
            development sources available on the <a href="http://caml.inria.fr/ocaml/anonsvn.en.html">development
            resources</a> page online</p>
          </li>

          <li>
            <p>A Git mirror of the Subversion repository with all
            the history and development branches included,
            browsable online at <a href="https://github.com/ocaml/ocaml">GitHub</a></p>
          </li>
        </ul>

        <p>The source tree is split up into subdirectories. The
        core compiler consists of:</p>

        <dl>
          <dt><code>config/</code></dt>

          <dd>
            Configuration directives to tailor OCaml for your
            operating system and architecture.
          </dd>

          <dt><code>bytecomp/</code> and <code>byterun/</code></dt>

          <dd>
            Bytecode compiler and runtime, including the garbage
            collector (GC).
          </dd>

          <dt><code>asmcomp/</code> and <code>asmrun/</code></dt>

          <dd>
            Native-code compiler and runtime. The native runtime
            symlinks many modules from the <code>byterun</code>
            directory to share code, most notably the GC.
          </dd>

          <dt><code>parsing/</code></dt>

          <dd>
            The OCaml lexer, parser, and libraries for
            manipulating them.
          </dd>

          <dt><code>typing/</code></dt>

          <dd>
            The static type checking implementation and type
            definitions.
          </dd>

          <dt><code>camlp4/</code></dt>

          <dd>
            The source code macro preprocessor.
          </dd>

          <dt><code>driver/</code></dt>

          <dd>
            Command-line interfaces for the compiler tools.
          </dd>
        </dl>

        <p>A number of tools and scripts are also built alongside
        the core compiler:</p>

        <dl>
          <dt><code>debugger/</code></dt>

          <dd>
            The interactive bytecode debugger.
          </dd>

          <dt><code>toplevel/</code></dt>

          <dd>
            Interactive top-level console.
          </dd>

          <dt><code>emacs/</code></dt>

          <dd>
            A <em>caml-mode</em> for the Emacs editor.
          </dd>

          <dt><code>stdlib/</code></dt>

          <dd>
            The compiler standard library, including the
            <code>Pervasives</code> module.
          </dd>

          <dt><code>ocamlbuild/</code></dt>

          <dd>
            Build system that automates common OCaml compilation
            modes.
          </dd>

          <dt><code>otherlibs/</code></dt>

          <dd>
            Optional libraries such as the Unix and graphics
            modules.
          </dd>

          <dt><code>tools/</code></dt>

          <dd>
            Command-line utilities such as <code>ocamldep</code>
            that are installed with the compiler.
          </dd>

          <dt><code>testsuite/</code></dt>

          <dd>
            Regression tests for the core compiler.
          </dd>
        </dl>
      </aside>

      <p>We'll go through each of the compilation stages now and
      explain how they will be useful to you during day-to-day
      OCaml development.</p>
    </section>

    <section id="parsing-source-code" data-type="sect1">
      <h1>Parsing Source Code</h1>

      <p>When a source file is passed to the OCaml compiler, its
      first task is to parse the text into a more structured
      abstract syntax tree (AST). The parsing logic is implemented
      in OCaml itself using the techniques described earlier in
      <a href="16-parsing-with-ocamllex-and-menhir.html#parsing-with-ocamllex-and-menhir" data-type="xref">Parsing With Ocamllex And Menhir</a>. The
      lexer and parser rules can be found in the
      <code>parsing</code> directory in the source
      distribution.<idx>AST (abstract syntax-tree)</idx> <idx id="SCpras">source code/parsing of</idx><idx id="PARSsource">parsing/of source code</idx><idx id="CPpars">compilation process/parsing source code</idx></p>

      <section id="syntax-errors" data-type="sect2">
        <h2>Syntax Errors</h2>

        <p>The OCaml parser's goal is to output a well-formed AST
        data structure to the next phase of compilation, and so it
        any source code that doesn't match basic syntactic
        requirements. The compiler emits a <em>syntax error</em> in
        this situation, with a pointer to the filename and line and
        character number that's as close to the error as
        possible.<idx>errors/syntax errors</idx><idx>syntax errors</idx></p>

        <p>Here's an example syntax error that we obtain by
        performing a module assignment as a statement instead of as
        a <code>let</code> binding:</p>
        <link rel="import" href="code/front-end/broken_module.ml"/>

        <p>The code results in a syntax error when compiled:</p>
        <link rel="import" href="code/front-end/build_broken_module.errsh"/>

        <p>The correct version of this source code creates the
        <code>MyString</code> module correctly via a local open,
        and compiles successfully:</p>
        <link rel="import" href="code/front-end/fixed_module.ml"/>

        <p>The syntax error points to the line and character number
        of the first token that couldn't be parsed. In the broken
        example, the <code>module</code> keyword isn't a valid
        token at that point in parsing, so the error location
        information is correct.</p>
      </section>

      <section id="automatically-indenting-source-code" data-type="sect2">
        <h2>Automatically Indenting Source Code</h2>

        <p>Sadly, syntax errors do get more inaccurate sometimes,
        depending on the nature of your mistake. Try to spot the
        deliberate error in the following function definitions:
        <idx>source code/automatically indenting</idx></p>
        <link rel="import" href="code/front-end/follow_on_function.ml"/>

        <p>When you compile this file, you'll get a syntax error
        again:</p>
        <link rel="import" href="code/front-end/build_follow_on_function.errsh"/>

        <p>The line number in the error points to the end of the
        <code>add_and_print</code> function, but the actual error
        is at the end of the <em>first</em> function definition.
        There's an extra semicolon at the end of the first
        definition that causes the second definition to become part
        of the first <code>let</code> binding. This eventually
        results in a parsing error at the very end of the second
        function.</p>

        <p>This class of bug (due to a single errant character) can
        be hard to spot in a large body of code. Luckily, there's a
        great tool available via OPAM called <span class="command"><em>ocp-indent</em></span> that applies
        structured indenting rules to your source code on a
        line-by-line basis. This not only beautifies your code
        layout, but it also makes this syntax error much easier to
        locate.<idx>debugging/single errant characters</idx></p>

        <p>Let's run our erroneous file through <span class="command"><em>ocp-indent</em></span> and see how it
        processes it:</p>
        <link rel="import" href="code/front-end/indent_follow_on_function.sh"/>

        <p>The <code>add_and_print</code> definition has been
        indented as if it were part of the first
        <code>concat_and_print</code> definition, and the errant
        semicolon is now much easier to spot. We just need to
        remove that semicolon and rerun <span class="command"><em>ocp-indent</em></span> to verify that the
        syntax is correct:</p>
        <link rel="import" href="code/front-end/indent_follow_on_function_fixed.sh"/>

        <p>The <span class="command"><em>ocp-indent</em></span>
        <a href="https://github.com/OCamlPro/ocp-indent">home
        page</a> documents how to integrate it with your favorite
        editor. All the Core libraries are formatted using it to
        ensure consistency, and it's a good idea to do this before
        publishing your own source code online.</p>
      </section>

      <section id="generating-documentation-from-interfaces" data-type="sect2">
        <h2>Generating Documentation from Interfaces</h2>

        <p>Whitespace and source code comments are removed during
        parsing and aren't significant in determining the semantics
        of the program. However, other tools in the OCaml
        distribution can interpret comments for their own ends.
        <idx>OCaml toolchain/ocamldoc</idx><idx>interfaces/generating documentation from</idx><idx>documentation, generating from interfaces</idx></p>

        <p>The <span class="command"><em>ocamldoc</em></span> tool
        uses specially formatted comments in the source code to
        generate documentation bundles. These comments are combined
        with the function definitions and signatures, and output as
        structured documentation in a variety of formats. It can
        generate HTML pages, LaTeX and PDF documents, UNIX manual
        pages, and even module dependency graphs that can be viewed
        using <a href="http://www.graphviz.org">Graphviz</a>.</p>

        <p>Here's a sample of some source code that's been
        annotated with <span class="command"><em>ocamldoc</em></span> comments:</p>
        <link rel="import" href="code/front-end/doc.ml"/>

        <p>The <span class="command"><em>ocamldoc</em></span>
        comments are distinguished by beginning with the double
        asterisk. There are formatting conventions for the contents
        of the comment to mark metadata. For instance, the
        <code>@tag</code> fields mark specific properties such as
        the author of that section of code.</p>

        <p>Try compiling the HTML documentation and UNIX man pages
        by running <span class="command"><em>ocamldoc</em></span>
        over the source file:</p>
        <link rel="import" href="code/front-end/build_ocamldoc.rawsh"/>

        <p>You should now have HTML files inside the <em class="filename">html/</em> directory and also be able to view
        the UNIX manual pages held in <em class="filename">man/man3</em>. There are quite a few comment
        formats and options to control the output for the various
        backends. Refer to the <a href="http://caml.inria.fr/pub/docs/manual-ocaml/manual029.html">
        OCaml manual</a> for the complete list.<idx>Xen</idx><idx>JSON data/Xen custom generator for</idx><idx>Bibtex</idx><idx>OCaml toolchain/ocamldoc-generators</idx><idx>Argot HTML generator</idx><idx>HTML generators</idx><a data-type="indexterm" data-startref="SCpras">&nbsp;</a><a data-type="indexterm" data-startref="PARSsource">&nbsp;</a><a data-type="indexterm" data-startref="CPpars">&nbsp;</a></p>

        <div data-type="tip">
          <h1>Using Custom ocamldoc Generators</h1>

          <p>The default HTML output stylesheets from <span class="command"><em>ocamldoc</em></span> are pretty spartan and
          distinctly Web 1.0. The tool supports plugging in custom
          documentation generators, and there are several available
          that provide prettier or more detailed output:</p>

          <ul>
            <li>
              <p><a href="http://argot.x9c.fr/">Argot</a> is an
              enhanced HTML generator that supports code folding
              and searching by name or type definition.</p>
            </li>

            <li>
              <p><a href="https://gitorious.org/ocamldoc-generators/ocamldoc-generators">
              ocamldoc generators</a> add support for Bibtex
              references within comments and generating literate
              documentation that embeds the code alongside the
              comments.</p>
            </li>

            <li>
              <p>JSON output is available via a custom <a href="https://github.com/xen-org/ocamldoc-json">generator</a>
              in Xen.</p>
            </li>
          </ul>
        </div>
      </section>
    </section>

    <section id="preprocessing-source-code" data-type="sect1">
      <h1>Preprocessing Source Code</h1>

      <p>One powerful feature in OCaml is a facility to extend the
      standard-language grammar without having to modify the
      compiler. You can roughly think of it as a type-safe version
      of the <code>cpp</code> preprocessor used in C/C++ to control
      conditional compilation directives.<idx>grammars/extension of standard language</idx><idx id="SCpreproc">source code/preprocessing of</idx><idx id="CPpreproc">compilation process/preprocessing source code</idx></p>

      <p>The OCaml distribution includes a system called Camlp4 for
      writing extensible parsers. This provides some OCaml
      libraries that are used to define grammars, as well as
      dynamically loadable syntax extensions of such grammars.
      Camlp4 modules register new language keywords and later
      transform these keywords (or indeed, any portion of the input
      program) into conventional OCaml code that can be understood
      by the rest of the compiler.<idx id="SEcamlp">syntax extension/in Camlp4</idx><idx>programming/dynamic programming</idx><idx>dynamic programming</idx><idx>Bin_prot library</idx><idx>Sexplib package/sexp converter</idx><idx>fieldslib</idx><idx>parsing/extensible parsers</idx><idx>extensible parsers</idx><idx id="camlp">Camlp4 syntax extension mechanism</idx></p>

      <p>We've already seen several Core libraries that use
      Camlp4:</p>

      <dl>
        <dt><code>Fieldslib</code></dt>

        <dd>
          Generates first-class values that represent fields of
          a record
        </dd>

        <dt><code>Sexplib</code></dt>

        <dd>
          To convert types to textual s-expressions
        </dd>

        <dt><code>Bin_prot</code></dt>

        <dd>
          For efficient binary conversion and parsing
        </dd>
      </dl>

      <p>These libraries all extend the language in quite a minimal
      way by adding a <code>with</code> keyword to type
      declarations to signify that extra code should be generated
      from that declaration. For example, here's a trivial use of
      Sexplib and Fieldslib:</p>
      <link rel="import" href="code/front-end/type_conv_example.ml"/>

      <p>Compiling this code will normally give you a syntax error
      if you do so without Camlp4, since the <code>with</code>
      keyword isn't normally allowed after a type definition:</p>
      <link rel="import" href="code/front-end/build_type_conv_without_camlp4.errsh"/>

      <p>Now add in the syntax extension packages for Fieldslib and
      Sexplib, and everything will compile again:</p>
      <link rel="import" href="code/front-end/build_type_conv_with_camlp4.rawsh"/>

      <p>We've specified a couple of additional flags here. The
      <code>-syntax</code> flag directs <span class="command"><em>ocamlfind</em></span> to add the
      <code>-pp</code> flag to the compiler command line. This flag
      instructs the compiler to run the preprocessor during its
      parsing phase.</p>

      <p>The <code>-package</code> flag imports other OCaml
      libraries. The <code>.syntax</code> suffix in the package
      name is a convention that indicates these libraries are
      preprocessors that should be run during parsing. The syntax
      extension modules are dynamically loaded into the
      <span class="command"><em>camlp4o</em></span> command, which
      rewrites the input source code into conventional OCaml code
      that has no trace of the new keywords. The compiler then
      compiles this transformed code with no knowledge of the
      preprocessor's actions.</p>

      <p>Both Fieldslib and Sexplib need this new <code>with</code>
      keyword, but they both can't register the same extension.
      Instead, a library called Type_conv provides the common
      extension framework for them to use. Type_conv registers the
      <code>with</code> grammar extension to Camlp4, and the
      OCamlfind packaging ensures that it's loaded before Fieldslib
      or Sexplib.</p>

      <p>The two extensions generate boilerplate OCaml code based
      on the type definition at compilation time. This avoids the
      performance hit of doing the code generation dynamically and
      also doesn't require a just-in-time (JIT) runtime that can be
      a source of unpredictable dynamic behavior. Instead, all the
      extra code is simply generated at compilation time via
      Camlp4, and type information can be discarded from the
      runtime image.

	<idx data-primary-sortas="Just">&quot;Just-in-Time&quot;
	  dynamic patching</idx>
      </p>

      <p>The syntax extensions accept an input AST and output a
      modified one. If you're not familiar with the Camlp4 module
      in question, how do you figure out what changes it's made to
      your code? The obvious way is to read the documentation that
      accompanies the extension. Another approach is to use the
      toplevel to explore the extension's behavior or run Camlp4
      manually yourself to see the transformation in action. We'll
      show you how to do both of these now.</p>

      <section id="using-camlp4-interactively" data-type="sect2">
        <h2>Using Camlp4 Interactively</h2>

        <p>The <span class="command"><em>utop</em></span> toplevel can
        run the phrases that you type
        through <span class="command"><em>camlp4</em></span>
        automatically. You should have at least these lines in
        your <code>~/.ocamlinit</code> file in your home directory
        (see <a href="http://realworldocaml.org/install">this Real
        World OCaml page</a> for more information):</p>

        <link rel="import" part="0.5" href="code/front-end/camlp4_toplevel.mlt"/>

        <p>The first directive loads
        the <span class="command"><em>ocamlfind</em></span> top-level
        interface that lets you
        require <span class="command"><em>ocamlfind</em></span>
        packages (including all their dependent packages). The second
        directive instructs the toplevel to filter all phrases via
        Camlp4. You can now
        run <span class="command"><em>utop</em></span> and load the
        syntax extensions in. We'll use the <code>comparelib</code>
        syntax extension for our experiments.</p>

        <p>OCaml provides a built-in polymorphic comparison
        operator that inspects the runtime representation of two
        values to see if they're equal. As we noted in <a href="13-maps-and-hashtables.html#maps-and-hash-tables" data-type="xref">Maps And Hash Tables</a>, the polymorphic
        comparison is less efficient than defining explicit
        comparison functions between values. However, it quickly
        becomes tedious to manually define comparison functions for
        complex type definitions. <idx>interactive input/with camlp4</idx><idx>polymorphic comparisons</idx></p>

        <p>Let's see how <code>comparelib</code> solves this
        problem by running it in <span class="command"><em>utop</em></span>:</p>
        <link rel="import" href="code/front-end/camlp4_toplevel.mlt" part="1"/>

        <p>The first definition of <code>t</code> is a standard
        OCaml phrase and results in the expected output. The second
        one includes the <code>with compare</code> directive. This
        is intercepted by <code>comparelib</code> and transformed
        into the original type definition with two new functions
        also <span class="keep-together">included</span>.</p>
      </section>

      <section id="running-camlp4-from-the-command-line" data-type="sect2">
        <h2>Running Camlp4 from the Command Line</h2>

        <p>The toplevel is a quick way to examine the signatures
        generated from the extensions, but how can we see what
        these new functions actually do? We can't do this from
        <span class="command"><em>utop</em></span> directly, since
        it embeds the Camlp4 invocation as an automated part of its
        operation.<idx>command-line parsing/with Camlp4</idx></p>

        <p>Let's turn to the command line to obtain the result of
        the <code>comparelib</code> transformation instead. Create
        a file that contains the type declaration from earlier:</p>
        <link rel="import" href="code/front-end/comparelib_test.ml"/>

        <p>We need to run the Camlp4 binary with the library paths
        to Comparelib and Type_conv. Let's use a small shell script
        to wrap this invocation:</p>
        <link rel="import" href="code/front-end/camlp4_dump.cmd"/>

        <p>The script uses the <span class="command"><em>ocamlfind</em></span> package manager to list
        the include and library paths needed by
        <code>comparelib</code>. It then invokes the <span class="command"><em>camlp4o</em></span> preprocessor with these
        paths and outputs the resulting AST to the standard
        output:</p>
        <link rel="import" href="code/front-end/process_comparelib_test.sh"/>

        <p>The output contains the original type definition
        accompanied by some automatically generated code that
        implements an explicit comparison function for each field
        in the record. If you're using the extension in your
        compiler command line, this generated code is then compiled
        as if you had typed it in yourself.</p>

        <p>Note that although the generated code uses
        <code>Pervasives.compare</code>, it is also annotated with
        a <code>string</code> type. This lets the compiler use a
        specialized string comparison function and not actually
        call the runtime polymorphic comparison function. This has
        implications for correctness, too: recall from <a href="13-maps-and-hashtables.html#maps-and-hash-tables" data-type="xref">Maps And Hash Tables</a> that
        <code>comparelib</code> provides reliable comparison
        functions that work for values that are logically the same
        but that have differing internal representations (e.g.,
        <code>Int.Set.t</code>).<idx>wildcards</idx><idx>bindings/wildcards in let bindings</idx><idx>let syntax/wildcards in bindings</idx></p>

        <div class="allow_break" data-type="note">
          <h1>A Style Note: Wildcards in let Bindings</h1>

          <p>You may have noticed the <code>let _ = fun</code>
          construct in the autogenerated code above. The underscore
          in a <code>let</code> binding is just the same as a
          wildcard underscore in a pattern match, and tells the
          compiler to accept any return value and discard it
          immediately.</p>

          <p>This is fine for mechanically generated code from
          Type_conv but should be avoided in code that you write by
          hand. If it's a unit-returning expression, then write a
          <code>unit</code> binding explicitly instead. This will
          cause a type error if the expression changes type in the
          future (e.g., due to code refactoring):</p>
        </div>
        <link rel="import" href="code/front-end/let_unit.syntax"/>

        <p>If the expression has a different type, then write it
        explicitly:</p>
        <link rel="import" href="code/front-end/let_notunit.ml"/>

        <p>The last one is used to ignore Async expressions that
        should run in the background rather than blocking in the
        current thread.</p>

        <p>One other important reason for using wildcard matches is
        to bind a variable name to something that you want to use
        in future code but don't want to use right away. This would
        normally generate an "unused value" compiler warning. These
        warnings are suppressed for any variable name that's
        prepended with an underscore:</p>
        <link rel="import" href="code/front-end/unused_var.ml"/>

        <p>Although you don't use <code>_z</code> in your code,
        this will never generate an unused variable warning.</p>
      </section>

      <section id="preprocessing-module-signatures" data-type="sect2">
        <h2>Preprocessing Module Signatures</h2>

        <p>Another useful feature of <code>type_conv</code> is that
        it can generate module signatures, too. Copy the earlier
        type definition into a <code>comparelib_test.mli</code>
        that's got exactly the same <span class="keep-together">content</span>:<idx>signatures/preprocessing module signatures</idx><idx>modules/preprocessing signatures of</idx></p>
        <link rel="import" href="code/front-end/comparelib_test.mli"/>

        <p>If you rerun the Camlp4 dumper script now, you'll see
        that different code is produced for signature files:</p>
        <link rel="import" href="code/front-end/process_comparelib_interface.sh"/>

        <p>The external signature generated by
        <code>comparelib</code> is much simpler than the actual
        code. Running Camlp4 directly on the original source code
        lets you see these all these transformations precisely.
        <idx>grammars/avoiding grammar clashes</idx><idx>macros</idx><idx>conditional compilation</idx><idx>whitespace-sensitive indentation</idx><idx>syntax extension/potential overuse of</idx></p>

        <div class="allow_break" data-type="caution">
          <h1>Don't Overdo the Syntax Extensions</h1>

          <p>Syntax extensions are a powerful extension mechanism
          that can completely alter your source code's layout and
          style. Core includes a very conservative set of
          extensions that take care to minimize the syntax changes.
          There are a number of third-party libraries that are much
          more ambitious—some introduce whitespace-sensitive
          indentation, while others build entirely new embedded
          languages using OCaml as a host language, and yet others
          introduce conditional compilation for macros or optional
          logging.</p>

          <p>While it's tempting to compress all your boilerplate
          code into Camlp4 extensions, it can make your source code
          much harder for other people to quickly read and
          understand. Core mainly focuses on type-driven code
          generation using the <code>type_conv</code> extension and
          doesn't fundamentally change the OCaml syntax.</p>

          <p>Another thing to consider before deploying your own
          syntax extension is compatibility with other extensions.
          Two separate extensions can create a grammar clash that
          leads to odd syntax errors and hard-to-reproduce bugs.
          That's why most of Core's syntax extensions go through
          <code>type_conv</code>, which acts as a single point for
          extending the grammar via the <code>with</code>
          keyword.</p>
        </div>
      </section>

      <section id="further-reading-on-camlp4" data-type="sect2">
        <h2>Further Reading on Camlp4</h2>

        <p>We've deliberately only shown you how to use Camlp4
        extensions here, and not how to build your own. The full
        details of building new extensions are fairly daunting and
        could be the subject of an entirely new book.<idx>syntax extension/building new</idx><idx data-see="syntax extensions">extensions</idx></p>

        <p>The best resources to get started are:<a data-type="indexterm" data-startref="SEcamlp">&nbsp;</a><a data-type="indexterm" data-startref="camlp">&nbsp;</a><a data-type="indexterm" data-startref="SCpreproc">&nbsp;</a><a data-type="indexterm" data-startref="CPpreproc">&nbsp;</a></p>

        <ul>
          <li>
            <p>A series of <a href="http://ambassadortothecomputers.blogspot.co.uk/p/reading-camlp4.html">
            blog posts</a> by Jake Donham describe the internals of
            Camlp4 and its syntax extension mechanism</p>
          </li>

          <li>
            <p>The online <a href="http://brion.inria.fr/gallium/index.php/Camlp4">Camlp4
            wiki</a></p>
          </li>

          <li>
            <p>Using OPAM to install existing Camlp4 extensions and
            inspecting their source code</p>
          </li>
        </ul>
      </section>
    </section>

    <section id="static-type-checking" data-type="sect1">
      <h1>Static Type Checking</h1>

      <p>After obtaining a valid abstract syntax tree, the compiler
      has to verify that the code obeys the rules of the OCaml type
      system. Code that is syntactically correct but misuses values
      is rejected with an explanation of the problem.</p>

      <p>Although type checking is done in a single pass in OCaml,
      it actually consists of three distinct steps that happen
      simultaneously:<idx data-seealso="subtyping">explicit subtyping</idx><idx data-seealso="type inference">automatic type inference</idx><idx>subtyping/in static type checking</idx><idx>modules/in static type checking</idx><idx>type inference/in static type checking</idx><idx id="CPstatictype">compilation process/static type checking</idx></p>

      <dl>
        <dt>automatic type inference</dt>

        <dd>
          An algorithm that calculates types for a module
          without requiring manual type annotations
        </dd>

        <dt>module system</dt>

        <dd>
          Combines software components with explicit knowledge
          of their type signatures
        </dd>

        <dt>explicit subtyping</dt>

        <dd>
          Checks for objects and polymorphic variants
        </dd>
      </dl>

      <p>Automatic type inference lets you write succinct code for
      a particular task and have the compiler ensure that your use
      of variables is locally consistent.</p>

      <p>Type inference doesn't scale to very large codebases that
      depend on separate compilation of files. A small change in
      one module may ripple through thousands of other files and
      libraries and require all of them to be recompiled. The
      module system solves this by providing the facility to
      combine and manipulate explicit type signatures for modules
      within a large project, and also to reuse them via functors
      and first-class modules.<idx>modules/benefits of</idx><idx>type inference/drawbacks of</idx></p>

      <p>Subtyping in OCaml objects is always an explicit operation
      (via the <code>:&gt;</code> operator). This means that it
      doesn't complicate the core type inference engine and can be
      tested as a separate concern.</p>

      <section id="displaying-inferred-types-from-the-compiler" data-type="sect2">
        <h2>Displaying Inferred Types from the Compiler</h2>

        <p>We've already seen how you can explore type inference
        directly from the toplevel. It's also possible to generate
        type signatures for an entire file by asking the compiler
        to do the work for you. Create a file with a single type
        definition and value:</p>
        <link rel="import" href="code/front-end/typedef.ml"/>

        <p>Now run the compiler with the <code>-i</code> flag to
        infer the type signature for that file. This runs the type
        checker but doesn't compile the code any further after
        displaying the interface to the standard output:</p>
        <link rel="import" href="code/front-end/infer_typedef.sh"/>

        <p>The output is the default signature for the module that
        represents the input file. It's often useful to redirect
        this output to an <code>mli</code> file to give you a
        starting signature to edit the external interface without
        having to type it all in by hand.</p>

        <p>The compiler stores a compiled version of the interface
        as a <code>cmi</code> file. This interface is either
        obtained from compiling an <code>mli</code> signature file
        for a module, or by the inferred type if there is only an
        <code>ml</code> implementation present.</p>

        <p>The compiler makes sure that your <code>ml</code> and
        <code>mli</code> files have compatible signatures. The type
        checker throws an immediate error if this isn't the
        case:</p>
        <!-- TODO SanderSpies: properly format the following -->
        <link rel="import" href="code/front-end/conflicting_interface.ml"/>
        <link rel="import" href="code/front-end/conflicting_interface.mli"/>
        <link rel="import" href="code/front-end/conflicting_interfaces.errsh"/>

        <div class="allow_break" data-type="note">
          <h1>Which Comes First: The ml or the mli?</h1>

          <p>There are two schools of thought on which order OCaml
          code should be written in. It's very easy to begin
          writing code by starting with an <code>ml</code> file and
          using the type inference to guide you as you build up
          your functions. The <code>mli</code> file can then be
          generated as described, and the exported functions
          documented.<idx data-seealso="compilaton process">code compilers/order of code</idx><idx>mli files</idx><idx>files/mli files</idx><idx>ml files</idx><idx>files/ml files</idx></p>

          <p>If you're writing code that spans multiple files, it's
          sometimes easier to start by writing all the
          <code>mli</code> signatures and checking that they
          type-check against one another. Once the signatures are
          in place, you can write the implementations with the
          confidence that they'll all glue together correctly, with
          no cyclic dependencies among the modules.</p>

          <p>As with any such stylistic debate, you should
          experiment with which system works best for you. Everyone
          agrees on one thing though: no matter in what order you
          write them, production code should always explicitly
          define an <code>mli</code> file for every <code>ml</code>
          file in the project. It's also perfectly fine to have an
          <code>mli</code> file without a corresponding
          <code>ml</code> file if you're only declaring signatures
          (such as module types).</p>

          <p>Signature files provide a place to write succinct
          documentation and to abstract internal details that
          shouldn't be exported. Maintaining separate signature
          files also speeds up incremental compilation in larger
          code bases, since recompiling a <code>mli</code>
          signature is much faster than a full compilation of the
          implementation to native code.</p>
        </div>
      </section>

      <section id="type-inference-1" data-type="sect2">
        <h2>Type Inference</h2>

        <p>Type inference is the process of determining the
        appropriate types for expressions based on their use. It's
        a feature that's partially present in many other languages
        such as Haskell and Scala, but OCaml embeds it as a
        fundamental feature throughout the core language.
        <idx>Hindley-Milner algorithm</idx> <idx>type inference/algorithm basis of</idx></p>

        <p>OCaml type inference is based on the Hindley-Milner
        algorithm, which is notable for its ability to infer the
        most general type for an expression without requiring any
        explicit type annotations. The algorithm can deduce
        multiple types for an expression and has the notion of a
        <em>principal type</em> that is the most general choice
        from the possible inferences. Manual type annotations can
        specialize the type explicitly, but the automatic inference
        selects the most general type unless told otherwise.</p>

        <p>OCaml does have some language extensions that strain the
        limits of principal type inference, but by and large, most
        programs you write will never <em>require</em> annotations
        (although they sometimes help the compiler produce better
        error messages).</p>

        <section id="adding-type-annotations-to-find-errors" data-type="sect3">
          <h3>Adding type annotations to find errors</h3>

          <p>It's often said that the hardest part of writing OCaml
          code is getting past the type checker—but once the code
          does compile, it works correctly the first time! This is
          an exaggeration of course, but it can certainly feel true
          when moving from a dynamically typed language. The OCaml
          static type system protects you from certain classes of
          bugs such as memory errors and abstraction violations by
          rejecting your program at compilation time rather than by
          generating an error at runtime. Learning how to navigate
          the type checker's compile-time feedback is key to
          building robust libraries and applications that take full
          advantage of these static checks.<idx>type inference/error detection with</idx><idx>annotations, for type checking</idx><idx>errors/detecting with type annotations</idx><idx>type annotations</idx><idx>compile-time static checking</idx></p>

          <p>There are a couple of tricks to make it easier to
          quickly locate type errors in your code. The first is to
          introduce manual type annotations to narrow down the
          source of your error more accurately. These annotations
          shouldn't actually change your types and can be removed
          once your code is correct. However, they act as anchors
          to locate errors while you're still writing your
          code.</p>

          <p>Manual type annotations are particularly useful if you
          use lots of polymorphic variants or objects. Type
          inference with row polymorphism can generate some very
          large signatures, and errors tend to propagate more
          widely than if you are using more explicitly typed
          variants or classes.<idx>polymorphic variant types/type checking and</idx><idx>row polymorphism</idx></p>

          <p>For instance, consider this broken example that
          expresses some simple algebraic operations over
          integers:</p>
          <link rel="import" href="code/front-end/broken_poly.ml"/>

          <p>There's a single character typo in the code so that it
          uses <code>Nu</code> instead of <code>Num</code>. The
          resulting type error is impressive:</p>
          <link rel="import" href="code/front-end/build_broken_poly.errsh"/>

          <p>The type error is perfectly accurate, but rather
          verbose and with a line number that doesn't point to the
          exact location of the incorrect variant name. The best
          the compiler can do is to point you in the general
          direction of the <code>algebra</code> function
          application.</p>

          <p>This is because the type checker doesn't have enough
          information to match the inferred type of the
          <code>algebra</code> definition to its application a few
          lines down. It calculates types for both expressions
          separately, and when they don't match up, outputs the
          difference as best it can.</p>

          <p>Let's see what happens with an explicit type
          annotation to help the compiler out:</p>
          <link rel="import" href="code/front-end/broken_poly_with_annot.ml"/>

          <p>This code contains exactly the same error as before,
          but we've added a closed type definition of the
          polymorphic variants, and a type annotation to the
          <code>algebra</code> definition. The compiler error we
          get is much more useful now:</p>
          <link rel="import" href="code/front-end/build_broken_poly_with_annot.errsh"/>

          <p>This error points directly to the correct line number
          that contains the typo. Once you fix the problem, you can
          remove the manual annotations if you prefer more succinct
          code. You can also leave the annotations there, of
          course, to help with future refactoring and
          debugging.</p>
        </section>

        <section id="enforcing-principal-typing" data-type="sect3">
          <h3>Enforcing principal typing</h3>

          <p>The compiler also has a stricter <em>principal type
          checking</em> mode that is activated via the <span class="keep-together"><code>-principal</code></span> flag. This
          warns about risky uses of type information to ensure that
          the type inference has one principal result. A type is
          considered risky if the success or failure of type
          inference depends on the order in which subexpressions
          are typed.<idx>type inference/principality checks</idx><idx>risky type</idx><idx>principal type checking</idx></p>

          <p>The principality check only affects a few language
          features:</p>

          <ul>
            <li>
              <p>Polymorphic methods for objects</p>
            </li>

            <li>
              <p>Permuting the order of labeled arguments in a
              function from their type definition</p>
            </li>

            <li>
              <p>Discarding optional labeled arguments</p>
            </li>

            <li>
              <p>Generalized algebraic data types (GADTs) present
              from OCaml 4.0 onward</p>
            </li>

            <li>
              <p>Automatic disambiguation of record field and
              constructor names (since OCaml 4.1)</p>
            </li>
          </ul>

          <p>Here's an example of principality warnings when used
          with record disambiguation.</p>
          <link rel="import" href="code/front-end/non_principal.ml"/>

          <p>Inferring the signature with <code>-principal</code>
          will show you a new warning:</p>
          <link rel="import" href="code/front-end/build_non_principal.sh"/>

          <p>This example isn't principal, since the inferred type
          for <code>x.foo</code> is guided by the inferred type of
          <code>x.bar</code>, whereas principal typing requires
          that each subexpression's type can be calculated
          independently. If the <code>x.bar</code> use is removed
          from the definition of <code>f</code>, its argument would
          be of type <code>t</code> and not <code>type
          s</code>.</p>

          <p>You can fix this either by permuting the order of the
          type declarations, or by adding an explicit type
          annotation:</p>
          <link rel="import" href="code/front-end/principal.ml"/>

          <p>There is now no ambiguity about the inferred types,
          since we've explicitly given the argument a type, and the
          order of inference of the subexpressions no longer
          matters.</p>
          <link rel="import" href="code/front-end/build_principal.sh"/>

          <p>The <span class="command"><em>ocamlbuild</em></span>
          equivalent is to add the tag <code>principal</code> to
          your build. The <em>corebuild</em> wrapper script
          actually adds this by default, but it does no harm to
          explicitly repeat it:</p>
          <link rel="import" href="code/front-end/build_principal_corebuild.sh"/>

          <p>Ideally, all code should systematically use
          <code>-principal</code>. It reduces variance in type
          inference and enforces the notion of a single known type.
          However, there are drawbacks to this mode: type inference
          is slower, and the <code>cmi</code> files become larger.
          This is generally only a problem if you extensively use
          objects, which usually have larger type signatures to
          cover all their methods.</p>

          <p>If compiling in principal mode works, it is guaranteed
          that the program will pass type checking in nonprincipal
          mode, too. For this reason, the <span class="command"><em>corebuild</em></span> wrapper script
          activates principal mode by default, preferring stricter
          type inference over a small loss in compilation speed and
          extra disk space usage.</p>

          <p>Bear in mind that the <code>cmi</code> files generated
          in principal mode differ from the default mode. Try to
          ensure that you compile your whole project with it
          activated. Getting the files mixed up won't let you
          violate type safety, but it can result in the type
          checker failing unexpectedly very occasionally. In this
          case, just recompile with a clean source tree.</p>
        </section>
      </section>

      <section id="modules-and-separate-compilation" data-type="sect2">
        <h2>Modules and Separate Compilation</h2>

        <p>The OCaml module system enables smaller components to be
        reused effectively in large projects while still retaining
        all the benefits of static type safety. We covered the
        basics of using modules earlier in <a href="04-files-modules-and-programs.html#files-modules-and-programs" data-type="xref">Files Modules And Programs</a>. The module
        language that operates over these signatures also extends
        to functors and first-class modules, described in <a href="09-functors.html#functors" data-type="xref">Functors</a>
        and <a href="10-first-class-modules.html#first-class-modules" data-type="xref">First Class Modules</a>, respectively.
        <idx>modules/separate compilation in</idx></p>

        <p>This section discusses how the compiler implements them
        in more detail. Modules are essential for larger projects
        that consist of many source files (also known as
        <em>compilation units</em>). It's impractical to recompile
        every single source file when changing just one or two
        files, and the module system minimizes such recompilation
        while still encouraging code reuse. <idx>compilation units</idx></p>

        <section id="the-mapping-between-files-and-modules" data-type="sect3">
          <h3>The mapping between files and modules</h3>

          <p>Individual compilation units provide a convenient way
          to break up a big module hierarchy into a collection of
          files. The relationship between files and modules can be
          explained directly in terms of the module system.
          <idx>files/relationship with modules</idx></p>

          <p>Create a file called <code>alice.ml</code> with the
          following contents:</p>
          <link rel="import" href="code/front-end/alice.ml"/>

          <p>and a corresponding signature file:</p>
          <link rel="import" href="code/front-end/alice.mli"/>

          <p>These two files are exactly analogous to including the
          following code directly in another module that references
          <code>Alice</code>:</p>
          <link rel="import" href="code/front-end/alice_combined.ml"/>
        </section>

        <section id="defining-a-module-search-path" data-type="sect3">
          <h3>Defining a module search path</h3>

          <p>In the preceding example, <code>Alice</code> also has
          a reference to another module <code>Bob</code>. For the
          overall type of <code>Alice</code> to be valid, the
          compiler also needs to check that the <code>Bob</code>
          module contains at least a <code>Bob.name</code> value
          and defines a <code>Bob.t</code> type. <idx>modules/defining search paths</idx></p>

          <p>The type checker resolves such module references into
          concrete structures and signatures in order to unify
          types across module boundaries. It does this by searching
          a list of directories for a compiled interface file
          matching that module's name. For example, it will look
          for <code>alice.cmi</code> and <code>bob.cmi</code> on
          the search path and use the first ones it encounters as
          the interfaces for <code>Alice</code> and
          <code>Bob</code>.</p>

          <p>The module search path is set by adding
          <code>-I</code> flags to the compiler command line with
          the directory containing the <code>cmi</code> files as
          the argument. Manually specifying these flags gets
          complex when you have lots of libraries, and is the
          reason why the OCamlfind frontend to the compiler exists.
          OCamlfind automates the process of turning third-party
          package names and build descriptions into command-line
          flags that are passed to the compiler command line.</p>

          <p>By default, only the current directory and the OCaml
          standard library will be searched for <code>cmi</code>
          files. The <code>Pervasives</code> module from the
          standard library will also be opened by default in every
          compilation unit. The standard library location is
          obtained by running <code>ocamlc -where</code> and can be
          overridden by setting the <code>CAMLLIB</code>
          environment variable. Needless to say, don't override the
          default path unless you have a good reason to (such as
          setting up a cross-compilation environment).
          <idx>cmi files</idx> <idx>files/cmi files</idx> <idx>OCaml toolchain/ocamlogjinfo</idx></p>

          <aside data-type="sidebar">
            <h5>Inspecting Compilation Units with ocamlobjinfo</h5>

            <p>For separate compilation to be sound, we need to
            ensure that all the <code>cmi</code> files used to
            type-check a module are the same across compilation
            runs. If they vary, this raises the possibility of two
            modules checking different type signatures for a common
            module with the same name. This in turn lets the
            program completely violate the static type system and
            can lead to memory corruption and crashes.</p>

            <p>OCaml guards against this by recording a MD5
            checksum in every <code>cmi</code>. Let's examine our
            earlier <code>typedef.ml</code> more closely:</p>
            <link rel="import" href="code/front-end/typedef_objinfo.sh"/>

            <p><code>ocamlobjinfo</code> examines the compiled
            interface and displays what other compilation units it
            depends on. In this case, we don't use any external
            modules other than <code>Pervasives</code>. Every
            module depends on <code>Pervasives</code> by default,
            unless you use the <code>-nopervasives</code> flag
            (this is an advanced use case, and you shouldn't
            normally need it).</p>

            <p>The long alphanumeric identifier beside each module
            name is a hash calculated from all the types and values
            exported from that compilation unit. It's used during
            type-checking and linking to ensure that all of the
            compilation units have been compiled consistently
            against one another. A difference in the hashes means
            that a compilation unit with the same module name may
            have conflicting type signatures in different modules.
            The compiler will reject such programs with an error
            similar to this:</p>
            <link rel="import" href="code/front-end/inconsistent_compilation_units.rawsh"/>

            <p>This hash check is very conservative, but ensures
            that separate compilation remains type-safe all the way
            up to the final link phase. Your build system should
            ensure that you never see the preceding error messages,
            but if you do run into it, just clean out your
            intermediate files and recompile from scratch.</p>
          </aside>
        </section>
      </section>

      <section id="packing-modules-together" data-type="sect2">
        <h2>Packing Modules Together</h2>

        <p>The module-to-file mapping described so far rigidly
        enforces a 1:1 mapping between a top-level module and a
        file. It's often convenient to split larger modules into
        separate files to make editing easier, but still compile
        them all into a single OCaml module. <idx>modules/packing together</idx></p>

        <p>The <code>-pack</code> compiler option accepts a list of
        compiled object files (<code>.cmo</code> in bytecode and
        <code>.cmx</code> for native code) and their associated
        <code>.cmi</code> compiled interfaces, and combines them
        into a single module that contains them as submodules of
        the output. Packing thus generates an entirely new
        <code>.cmo</code> (or <code>.cmx</code> file) and
        <code>.cmi</code> that includes the input modules.</p>

        <p>Packing for native code introduces an additional
        requirement: the modules that are intended to be packed
        must be compiled with the <code>-for-pack</code> argument
        that specifies the eventual name of the pack. The easiest
        way to handle packing is to let <span class="command"><em>ocamlbuild</em></span> figure out the
        command-line arguments for you, so let's try that out next
        with a simple example.</p>

        <p>First, create a couple of toy modules called
        <code>A.ml</code> and <code>B.ml</code> that contain a
        single value. You will also need a <code>_tags</code> file
        that adds the <code>-for-pack</code> option for the
        <code>cmx</code> files (but careful to exclude the pack
        target itself). Finally, the <code>X.mlpack</code> file
        contains the list of modules that are intended to be packed
        under module <code>X</code>. There are special rules in
        <span class="command"><em>ocamlbuild</em></span> that tell
        it how to map <code>%.mlpack</code> files to the packed
        <code>%.cmx</code> or <code>%.cmo</code> equivalent:</p>
        <link rel="import" href="code/packing/show_files.sh"/>

        <p>You can now run <em>corebuild</em> to build the
        <code>X.cmx</code> file directly, but let's create a new
        module to link against <code>X</code> to complete the
        example:</p>
        <link rel="import" href="code/packing/test.ml"/>

        <p>You can now compile this test module and see that its
        inferred interface is the result of using the packed
        contents of <code>X</code>. We further verify this by
        examining the imported interfaces in <code>Test</code> and
        confirming that neither <code>A</code> nor <code>B</code>
        are mentioned in there and that only the packed
        <code>X</code> module is used:</p>
        <link rel="import" href="code/packing/build_test.sh"/>

        <div data-type="warning">
          <h1>Packing and Search Paths</h1>

          <p>One very common build error that happens with packing
          is confusion resulting from building the packed
          <code>cmi</code> in the same directory as the submodules.
          When you add this directory to your module search path,
          the submodules are also visible. If you forget to include
          the top-level prefix (e.g., <code>X.A</code>) and instead
          use a submodule directly (<code>A</code>), then this will
          compile and link fine.</p>

          <p>However, the types of <code>A</code> and
          <code>X.A</code> are <em>not</em> automatically
          equivalent so the type checker will complain if you
          attempt to mix and match the packed and unpacked versions
          of the library.</p>

          <p>This mostly only happens with unit tests, since they
          are built at the same time as the library. You can avoid
          it by being aware of the need to open the packed module
          from the test, or only using the library after it has
          been installed (and hence not exposing the intermediate
          compiled modules).</p>
        </div>
      </section>

      <section id="shorter-module-paths-in-type-errors" data-type="sect2">
        <h2>Shorter Module Paths in Type Errors</h2>

        <p>Core uses the OCaml module system quite extensively to
        provide a complete replacement standard library. It
        collects these modules into a single <code>Std</code>
        module, which provides a single module that needs to be
        opened to import the replacement modules and functions.
        <idx>errors/reducing verbosity in</idx></p>

        <p>There's one downside to this approach: type errors
        suddenly get much more verbose. We can see this if you run
        the vanilla OCaml toplevel (not <span class="command"><em>utop</em></span>).</p>
        <link rel="import" href="code/front-end/short_paths_1.rawsh"/>

        <p>This type error without <code>Core</code> has a
        straightforward type error. When we switch to Core, though,
        it gets more verbose:</p>
        <link rel="import" href="code/front-end/short_paths_2.rawsh"/>

        <p>The default <code>List</code> module in OCaml is
        overridden by <code>Core.List</code>. The compiler does
        its best to show the type equivalence, but at the cost of a
        more verbose error message.</p>

        <p>The compiler can remedy this via a so-called short paths
        heuristic. This causes the compiler to search all the type
        aliases for the shortest module path and use that as the
        preferred output type. The option is activated by passing
        <code>-short-paths</code> to the compiler, and works on the
        toplevel, too.<idx>short paths heuristic</idx></p>
        <link rel="import" href="code/front-end/short_paths_3.rawsh"/>

        <p>The <span class="command"><em>utop</em></span> enhanced
        toplevel activates short paths by default, which is why we
        have not had to do this before in our interactive examples.
        However, the compiler doesn't default to the short path
        heuristic, since there are some situations where the type
        aliasing information is useful to know, and it would be
        lost in the error if the shortest module path is always
        picked.</p>

        <p>You'll need to choose for yourself if you prefer short
        paths or the default behavior in your own projects, and
        pass the <code>-short-paths</code> flag to the compiler if
        you need it.<a data-type="indexterm" data-startref="CPstatictype">&nbsp;</a></p>
      </section>
    </section>

    <section id="the-typed-syntax-tree" data-type="sect1">
      <h1>The Typed Syntax Tree</h1>

      <p>When the type checking process has successfully completed,
      it is combined with the AST to form a <em>typed abstract
      syntax tree</em>. This contains precise location information
      for every token in the input file, and decorates each token
      with concrete type information.<idx>cmti files</idx><idx>cmt files</idx><idx>files/cmtii files</idx><idx>files/cmt files</idx><idx>AST (abstract syntax-tree)</idx><idx id="typesyntree">typed syntax tree</idx><idx id="CPtypsyn">compilation process/typed syntax tree</idx></p>

      <p>The compiler can output this as compiled <code>cmt</code>
      and <code>cmti</code> files that contain the typed AST for
      the implementation and signatures of a compilation unit. This
      is activated by passing the <code>-bin-annot</code> flag to
      the compiler.</p>

      <p>The <code>cmt</code> files are particularly useful for IDE
      tools to match up OCaml source code at a specific location to
      the inferred or external types.</p>

      <section id="using-ocp-index-for-auto-completion" data-type="sect2">
        <h2>Using ocp-index for Autocompletion</h2>

        <p>One such command-line tool to display autocompletion
        information in your editor is <span class="command"><em>ocp-index</em></span>. Install it via OPAM as
        follows:<idx>autocompletion</idx><idx>ocp-index</idx></p>
        <link rel="import" href="code/front-end/install_ocp_index.rawsh"/>

        <p>Let's refer back to our Ncurses binding example from the
        beginning of <a href="19-foreign-function-interface.html#foreign-function-interface" data-type="xref">Foreign Function Interface</a>. This
        module defined bindings for the Ncurses library. First,
        compile the interfaces with
        <span><code>-bin-annot</code></span> so that we can obtain
        the <code>cmt</code> and <code>cmti</code> files, and then
        run <span class="command"><em>ocp-index</em></span> in
        completion mode:</p>
        <link rel="import" href="code/ocp-index/index_ncurses.sh"/>

        <p>You need to pass <span class="command"><em>ocp-index</em></span> a set of directories to
        search for <code>cmt</code> files in, and a fragment of
        text to autocomplete. As you can imagine, autocompletion is
        invaluable on larger codebases. See the <a href="https://github.com/ocamlpro/ocp-index"><em>ocp-index</em></a>
        home page for more information on how to integrate it with
        your favorite editor.</p>
      </section>

      <section id="examining-the-typed-syntax-tree-directly" data-type="sect2">
        <h2>Examining the Typed Syntax Tree Directly</h2>

        <p>The compiler has a couple of advanced flags that can
        dump the raw output of the internal AST representation. You
        can't depend on these flags to give the same output across
        compiler revisions, but they are a useful learning
        tool.<idx>flags</idx></p>

        <p>We'll use our toy <code>typedef.ml</code> again:</p>
        <link rel="import" href="code/front-end/typedef.ml"/>

        <p>Let's first look at the untyped syntax tree that's
        generated from the parsing phase:</p>
        <link rel="import" href="code/front-end/parsetree_typedef.sh"/>

        <p>This is rather a lot of output for a simple two-line
        program, but it shows just how much structure the OCaml
        parser generates even from a small source file.</p>

        <p>Each portion of the AST is decorated with the precise
        location information (including the filename and character
        location of the token). This code hasn't been type checked
        yet, so the raw tokens are all included.</p>

        <p>The typed AST that is normally output as a compiled
        <code>cmt</code> file can be displayed in a more
        developer-readable form via the <code>-dtypedtree</code>
        option:</p>
        <link rel="import" href="code/front-end/typedtree_typedef.sh"/>

        <p>The typed AST is more explicit than the untyped syntax
        tree. For instance, the type declaration has been given a
        unique name (<code>t/1008</code>), as has the
        <code>v</code> value (<code>v/1011</code>). <a data-type="indexterm" data-startref="typesyntree">&nbsp;</a>
        <a data-type="indexterm" data-startref="CPtypsyn">&nbsp;</a></p>

        <p>You'll rarely need to look at this raw output from the
        compiler unless you're building IDE tools such as
        <span class="command"><em>ocp-index</em></span>, or are
        hacking on extensions to the core compiler itself. However,
        it's useful to know that this intermediate form exists
        before we delve further into the code generation process
        next, in <a href="23-compiler-backend.html#the-compiler-backend-byte-code-and-native-code" data-type="xref">The Compiler Backend Byte Code And Native
        Code</a>.</p>

        <p>There are several new integrated tools emerging that
        combine these typed AST files with common editors such as
        Emacs or Vim. The best of these is <a href="https://github.com/def-lkb/merlin">Merlin</a>, which adds
        value and module autocompletion, displays inferred types
        and can build and display errors directly from within your
        editor. There are instructions available on its homepage
        for configuring Merlin with your favorite editor.</p>
      </section>
    </section>
  </section>
