<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta name="generator" content="HTML Tidy for HTML5 for Mac OS X version 4.9.20"/>

    <title></title>
  </head>

  <body>
    <section xmlns="http://www.w3.org/1999/xhtml" id="concurrent-programming-with-async" data-type="chapter">
      <h1>Concurrent Programming with Async</h1>


      <p>
	The logic of building programs that interact with the outside
	world is often dominated by waiting; waiting for the click of
	a mouse, or for data to be fetched from disk, or for space to
	be available on an outgoing network buffer. Even mildly
	sophisticated interactive applications are
	typically <em>concurrent</em>, needing to wait for multiple
	different events at the same time, responding immediately to
	whatever event happens first.

	<idx>interactive input/concurrent programming for</idx>
	<idx>concurrent programming</idx>
	<idx>programming/concurrent programming with Async</idx></p>

      <p>
	One approach to concurrency is to use preemptive system threads,
	which is the dominant approach in languages like Java or C#. In
	this model, each task that may require simultaneous waiting is
	given an operating system thread of its own so it can block
	without stopping the entire program.

	<idx>threads/preemptive vs. single-threaded programs</idx></p>

      <p>
	Another approach is to have a single-threaded program, where
	that single thread runs an <em>event loop</em> whose job is to
	react to external events like timeouts or mouse clicks by
	invoking a callback function that has been registered for that
	purpose. This approach shows up in languages like JavaScript
	that have single-threaded runtimes, as well as in many GUI
	toolkits.

	<idx>event loops</idx>
	<idx data-seealso="threads">system threads</idx></p>

      <p>
	Each of these mechanisms has its own trade-offs. System
	threads require significant memory and other resources per
	thread. Also, the operating system can arbitrarily interleave
	the execution of system threads, requiring the programmer to
	carefully protect shared resources with locks and condition
	variables, which is exceedingly error-prone.</p>

      <p>
	Single-threaded event-driven systems, on the other hand,
	execute a single task at a time and do not require the same
	kind of complex synchronization that preemptive threads do.
	However, the inverted control structure of an event-driven
	program often means that your own control flow has to be
	threaded awkwardly through the system's event loop, leading to
	a maze of event callbacks.</p>

      <p>
	This chapter covers the Async library, which offers a hybrid
	model that aims to provide the best of both worlds, avoiding
	the performance compromises and synchronization woes of
	preemptive threads without the confusing inversion of control
	that usually comes with event-driven systems.

	<idx>Async library/benefits of</idx></p>

      <section id="async-basics" data-type="sect1">
	<h1>Async Basics</h1>

	<p>
	  Recall how I/O is typically done in Core. Here's a simple
	  example:</p>

	<link rel="import" href="code/async/main.mlt" part="1"/>

	<p>
	  From the type of <code>In_channel.read_all</code>, you can
	  see that it must be a blocking operation. In particular, the
	  fact that it returns a concrete string means it can't return
	  until the read has completed. The blocking nature of the
	  call means that no progress can be made on anything else
	  until the call is complete.

	  <idx>blocking</idx></p>

	<p>
	  In Async, well-behaved functions never block. Instead,
	  they return a value of type <code>Deferred.t</code> that acts
	  as a placeholder that will eventually be filled in with the
	  result. As an example, consider the signature of the Async
	  equivalent of <code>In_channel.read_all</code>.
	  <idx>Deferred.t</idx></p>

	<link rel="import" href="code/async/main.mlt" part="3"/>

	<p>
	  We first load the Async package in the toplevel
	  using <code>#require</code>, and then open the
	  module. Async, Like Core, is designed to be an extension to
	  your basic programming environment, and is intended to be
	  opened.</p>

	<p>
	  A deferred is essentially a handle to a value that may be
	  computed in the future. As such, if we
	  call <code>Reader.file_contents</code>, the resulting
	  deferred will initially be empty, as you can see by
	  calling <code>Deferred.peek</code>.  <idx>Deferred.peek</idx></p>

	<link rel="import" href="code/async/main.mlt" part="4"/>

	<p>
	  The value in <code>contents</code> isn't yet determined
	  partly because nothing running could do the necessary I/O.
	  When using Async, processing of I/O and other events is
	  handled by the Async scheduler. When writing a standalone
	  program, you need to start the scheduler explicitly, but
	  <span class="command"><em>utop</em></span> knows about Async
	  and can start the scheduler automatically. More than that,
	  <span class="command"><em>utop</em></span> knows about
	  deferred values, and when you type in an expression of type
	  <code>Deferred.t</code>, it will make sure the scheduler is
	  running and block until the deferred is determined. Thus, we
	  can write:</p>

	<link rel="import" href="code/async/main.mlt" part="5"/>


	<p>
	  Slightly confusingly, the type shown here is not the type
	  of <code>contents</code>, which is <code>string
	  Deferred.t</code>, but rather <code>string</code>, the type
	  of the value contained within that deferred.</p>

	<p>
	  If we peek again, we'll see that the value
	  of <code>contents</code> has been filled in.</p>

	<link rel="import" href="code/async/main.mlt" part="6"/>

	<p>
	  In order to do real work with deferreds, we need a way of
	  waiting for a deferred computation to finish, which we do
	  using <code>Deferred.bind</code>. Here's the type-signature
	  of <code>bind</code>.</p>

	<link rel="import" href="code/async/main.mlt" part="7"/>

	<p>
	  <code>bind</code> is effectively a way of sequencing
	  concurrent computations. In particular, <code>Deferred.bind
	  d ~f</code> causes <code>f</code> to be called after the
	  value of <code>d</code> has been determined.
	  <idx>Deferred.bind</idx></p>

	<p>
	  Here's a simple use of <code>bind</code> for a function
	  that replaces a file with an uppercase version of its
	  contents. </p>

	<link rel="import" href="code/async/main.mlt" part="8"/>

	<p>Again, <code>bind</code> is acting as a
	  sequencing operator, causing the file to be saved via the
	  call to <code>Writer.save</code> only after the contents of
	  the file were first read
	  via <code>Reader.file_contents</code>.</p>

	<p>
	  Writing out <code>Deferred.bind</code> explicitly can be
	  rather verbose, and so Async includes an infix operator for
	  it: <code>&gt;&gt;=</code>. Using this operator, we can
	  rewrite <code>uppercase_file</code> as follows:</p>

	<link rel="import" href="code/async/main.mlt" part="9"/>

	<p>
	  In the preceding code, we've dropped the parentheses around
	  the function on the righthand side of the bind, and we
	  didn't add a level of indentation for the contents of that
	  function. This is standard practice for using the
	  infix <code>bind</code>operator.

	  <idx>bind function</idx></p>

	<p>
	  Now let's look at another potential use of
	  <code>bind</code>. In this case, we'll write a function that
	  counts the number of lines in a file:</p>

	<link rel="import" href="code/async/main.mlt" part="10"/>

	<p>
	  This looks reasonable enough, but as you can see, the
	  compiler is unhappy. The issue here is that <code>bind</code>
	  expects a function that returns a deferred, but we've
	  provided it a function that returns the nondeferred result
	  directly. To make these signatures match, we need a function
	  for taking an ordinary value and wrapping it in a deferred.
	  This function is a standard part of Async and is called
	  <code>return</code>:

	  <idx>return function</idx></p>


	<link rel="import" href="code/async/main.mlt" part="11"/>

	<p>
	  Using <code>return</code>, we can
	  make <code>count_lines</code> compile:</p>


	<link rel="import" href="code/async/main.mlt" part="12"/>

	<p>
	  Together, <code>bind</code> and <code>return</code> form a
	  design pattern in functional programming known as a
	  <em>monad</em>. You'll run across this signature in many
	  applications beyond just threads. Indeed, we already ran
	  across monads in <a href="07-error-handling.html#bind-and-other-error-handling-idioms" data-type="xref">Bind And Other Error Handling
	    Idioms</a>.

	  <idx>monads</idx></p>

	<p>
	  Calling <code>bind</code> and <code>return</code> together
	  is a fairly common pattern, and as such there is a standard
	  shortcut for it called <code>Deferred.map</code>, which has
	  the following signature:</p>

	<link rel="import" href="code/async/main.mlt" part="13"/>

	<p>
	  and comes with its own infix equivalent,
	  <code>&gt;&gt;|</code>. Using it, we can rewrite
	  <code>count_lines</code> again a bit more succinctly:</p>

	<link rel="import" href="code/async/main.mlt" part="14"/>

	<p>
	  Note that <code>count_lines</code> returns a deferred, but
	  <span class="command"><em>utop</em></span> waits for that
	  deferred to become determined, and shows us the contents of
	  the deferred instead.</p>

	<div data-type="note">
	  <h1>Using <code>Let_syntax</code> with Async</h1>

	  <p>As was discussed
	    in <a href="07-error-handling.html#bind-and-other-error-handling-idioms"
		  data-type="xref">Error Handling</a>,
	    there is a special syntax designed
	    for working with monads, called <code>Let_syntax</code>.
	    Here's what the <code>bind</code>-using version
	    of <code>count_lines</code> looks like with that
	    syntax.</p>
          <link rel="import" href="code/async/main.mlt" part="12.1"/>

	  <p>And here's the <code>map</code>-based version
	    of <code>count_lines</code>.</p>
          <link rel="import" href="code/async/main.mlt" part="14.1"/>

	  <p>The difference here is just syntactic, with these
	    examples compiling down to the same thing as the
	    corresponding examples written using infix
	    operators. What's nice about <code>Let_syntax</code> is
	    that it highlights the analogy between monadic bind and
	    OCaml's built-in let-binding, thereby making your code
	    more uniform and more readable.
	  </p>

	  <p>
	    <code>Let_syntax</code> works for any monad, and you
	    decide which monad is in use by opening the
	    appropriate <code>Let_syntax</code>
	    module. Opening <code>Async</code> also implicitly
	    opens <code>Deferred.Let_syntax</code>, but in some
	    contexts you may may want to do that explicitly.</p>

	  <p>To keep things simple, we'll use the infix
	    notation for map and bind for the remainder of the
	    chapter. But once you get comfortable with Async and
	    monadic programming, <code>Let_syntax</code> can make your
	    code easier to read. </p>

	</div>

	<section id="ivars-and-upon" data-type="sect2">
          <h2>Ivars and Upon</h2>

          <p>
	    Deferreds are usually built using combinations
            of <code>bind</code>, <code>map</code>
            and <code>return</code>, but sometimes you want to
            construct a deferred where you can programmatically decide
            when it gets filled in.  This can be done using
            an <em>ivar</em>. (The term ivar dates back to a language
            called Concurrent ML that was developed by John Reppy in
            the early '90s. The "i" in ivar stands for incremental.)

	    <idx>ivars</idx>
	    <idx>Async library/ivars</idx></p>

          <p>
	    There are three fundamental operations for working with
            an ivar: you can create one, using
            <code>Ivar.create</code>; you can read off the deferred
            that corresponds to the ivar in question, using
            <code>Ivar.read</code>; and you can fill an ivar, thus
            causing the corresponding deferred to become determined,
            using <code>Ivar.fill</code>. These operations are
            illustrated below:</p>

          <link rel="import" href="code/async/main.mlt" part="15"/>

          <p>
	    Ivars are something of a low-level feature; operators
            like <code>map</code>, <code>bind</code> and
            <code>return</code> are typically easier to use and think
            about. But ivars can be useful when you want to build a
            synchronization pattern that isn't already well
            supported.</p>

          <p>
	    As an example, imagine we wanted a way of scheduling a
            sequence of actions that would run after a fixed delay. In
            addition, we'd like to guarantee that these delayed
            actions are executed in the same order they were scheduled
            in.  Here's a signature that captures this idea:</p>

          <link rel="import" href="code/async/main.mlt" part="16"/>

          <p>
	    An action is handed to <code>schedule</code> in the form
            of a deferred-returning thunk (a thunk is a function whose
            argument is of type <code>unit</code>). A deferred is
            handed back to the caller of <code>schedule</code> that
            will eventually be filled with the contents of the deferred
            value returned by the thunk. To implement this, we'll use
            an operator called <code>upon</code>, which has the
            following signature:

	    <idx>thunks</idx></p>


          <link rel="import" href="code/async/main.mlt" part="17"/>

          <p>
	    Like <code>bind</code> and <code>return</code>,
            <code>upon</code> schedules a callback to be executed when
            the deferred it is passed is determined; but unlike those
            calls, it doesn't create a new deferred for this callback
            to fill.</p>

          <p>
	    Our delayer implementation is organized around a queue
            of thunks, where every call to <code>schedule</code> adds a
            thunk to the queue and also schedules a job in the future
            to grab a thunk off the queue and run it. The waiting will
            be done using the function <code>after</code>, which takes
            a time span and returns a deferred which becomes determined
            after that time span elapses:</p>

          <link rel="import" href="code/async/main.mlt" part="18"/>

          <p>
	    This code isn't particularly long, but it is subtle. In
            particular, note how the queue of thunks is used to ensure
            that the enqueued actions are run in order, even if the
            thunks scheduled by <code>upon</code> are run out of order.
            This kind of subtlety is typical of code that involves
            ivars and <code>upon</code>, and because of this, you
            should stick to the simpler map/bind/return style of
            working with deferreds when you can.<a data-type="indexterm" data-startref="ALbas">&nbsp;</a></p>

	  <div data-type="note">
	    <h1>Understanding <code>bind</code> in terms of ivars
	    and <code>upon</code></h1>

	    <p>
	      Here's roughly what happens when you write <code>let d'
	      = Deferred.bind d ~f</code>.
	    </p>

	    <ul>
	      <li><p>A new ivar <code>i</code> is created to hold the
		  final result of the computation. The corresponding
		  deferred is returned</p></li>
	      <li><p>A function is registered to be called when the
		  deferred <code>d</code> becomes determined.</p></li>
	      <li><p> That function, once run, calls <code>f</code> with the value that was
		  determined for <code>d</code>.</p></li>
	      <li><p> Another function is registered to be called when
		  the deferred returned by <code>f</code> becomes
		  determined.</p></li>
	      <li> <p>When that function is called, it uses it to fill
		  <code>i</code>, causing the corresponding deferred
		  it to become determined.</p> </li>
	    </ul>

	    <p>
	      That sounds like a lot, but we can implement this
	      relatively concisely.</p>
            <link rel="import" href="code/async/main.mlt"
		  part="18.1"/>

	    <p> Async's real implementation has more optimizations and
	      is therefore more complicated. But the above
	      implementation is still a useful first-order mental
	      model for how bind works under the covers. And it's
	      another good example of how <code>upon</code> and ivars
	      can useful for building concurrency primitives.
	    </p>
	  </div>

	</section>
      </section>

      <section id="examples-an-echo-server" data-type="sect1">
	<h1>Example: An Echo Server</h1>

	<p>
	  Now that we have the basics of Async under our belt, let's
	  look at a small standalone Async program. In particular,
	  we'll write an echo server, <em>i.e.</em>, a program that accepts
	  connections from clients and spits back whatever is sent to
	  it.<idx id="echo">echo servers</idx> <idx id="ALecho">Async
	  library/echo server example</idx></p>

	<p>
	  The first step is to create a function that can copy data
	  from an input to an output. Here, we'll use Async's
	  <code>Reader</code> and <code>Writer</code> modules, which
	  provide a convenient abstraction for working with input and
	  output channels:

	  <idx>Writer module</idx>
	  <idx>Reader module</idx>
	  <idx>I/O (input/output) operations/copying data</idx></p>


	<link rel="import" href="code/async/echo/echo.ml"/>

	<p>
	  Bind is used in the code to sequence the operations:
	  first, we call <code>Reader.read</code> to get a block of
	  input. Then, when that's complete and if a new block was
	  returned, we write that block to the writer. Finally, we wait
	  until the writer's buffers are flushed, waiting on the
	  deferred returned by <code>Writer.flushed</code>, at which
	  point we recurse. If we hit an end-of-file condition, the
	  loop is ended. The deferred returned by a call to
	  <code>copy_blocks</code> becomes determined only once the
	  end-of-file condition is hit.

	  <idx>end-of-file condition</idx></p>

	<p>
	  One important aspect of how this is written is that it
	  uses <em>pushback</em>, which is to say that if the writer
	  can't make progress writing, the reader will stop reading. If
	  you don't implement pushback in your servers, then a stopped
	  client can cause your program to leak memory, since you'll
	  need to allocate space for the data that's been read in but
	  not yet written out.

	  <idx>pushback</idx></p>

	<p>
	  You might also be concerned that the chain of deferreds
	  that is built up as you go through the loop would lead to a
	  memory leak. After all, this code constructs an ever-growing
	  chain of binds, each of which creates a deferred. In this
	  case, however, all of the deferreds should become determined
	  precisely when the final deferred in the chain is determined,
	  in this case, when the <code>Eof</code> condition is hit.
	  Because of this, we could safely replace all of these
	  deferreds with a single deferred. Async has logic to do just
	  this, and so there's no memory leak after all. This is
	  essentially a form of tail-call optimization, lifted to the
	  Async monad.

	  <idx>tail calls</idx></p>

	<p>
	  <code>copy_blocks</code> provides the logic for handling a
	  client connection, but we still need to set up a server to
	  receive such connections and dispatch to
	  <code>copy_blocks</code>. For this, we'll use Async's
	  <code>Tcp</code> module, which has a collection of utilities
	  for creating TCP clients and servers:

	  <idx>TCP clients/servers</idx></p>


	<link rel="import" href="code/async/echo/echo.ml" part="1"/>

	<p>
	  The result of calling <code>Tcp.Server.create</code> is a
	  <code>Tcp.Server.t</code>, which is a handle to the server
	  that lets you shut the server down. We don't use that
	  functionality here, so we explicitly ignore
	  <code>server</code> to suppress the unused-variables error.
	  We put in a type annotation around the ignored value to make
	  the nature of the value we're ignoring <span class="keep-together">explicit</span>.</p>

	<p>
	  The most important argument to
	  <code>Tcp.Server.create</code> is the final one, which is the
	  client connection handler. Notably, the preceding code does
	  nothing explicit to close down the client connections when
	  the communication is done. That's because the server will
	  automatically shut down the connection once the deferred
	  returned by the handler becomes determined.</p>

	<p>
	  Finally, we need to initiate the server and start the
	  Async scheduler:</p>

	<link rel="import" href="code/async/echo/echo.ml" part="2"/>

	<p>
	  One of the most common newbie errors with Async is to
	  forget to run the scheduler. It can be a bewildering mistake,
	  because without the scheduler, your program won't do anything
	  at all; even calls to <code>printf</code> won't reach the
	  terminal.</p>

	<p>
	  It's worth noting that even though we didn't spend much
	  explicit effort on thinking about multiple clients, this
	  server is able to handle many concurrent clients without
	  further modification.</p>

	<p>
	  Now that we have the echo server, we can connect to the
	  echo server using the netcat tool, which is invoked as
	  <code>nc</code>:</p>
  <link rel="import" href="code/async/echo/jbuild"/>
	<link rel="import" href="code/async/echo/run_echo.sh"/>

	<aside data-type="note">
          <h5>Functions that Never Return</h5>

          <p>
	    You might wonder what's going on with the call
            to <code>never_returns</code>. <code>never_returns</code> is
            an idiom that comes from Core that is used to mark functions
            that don't return. Typically, a function that doesn't return
            is inferred as having return type <code>'a</code>:

	    <idx>Scheduler.go</idx>
	    <idx>loop_forever</idx>
	    <idx>never_returns</idx>
	    <idx>functions/non-returning</idx></p>


          <link rel="import" href="code/async/main.mlt" part="19"/>

          <p>
	    This can be surprising when you call a function like
            this expecting it to return <code>unit</code>. The
            type-checker won't necessarily complain in such a case:</p>

          <link rel="import" href="code/async/main.mlt" part="20"/>

          <p>
	    With a name like <code>loop_forever</code>, the meaning
            is clear enough. But with something like
            <code>Scheduler.go</code>, the fact that it never returns
            is less clear, and so we use the type system to make it
            more explicit by giving it a return type of
            <code>never_returns</code>. Let's do the same trick with
            <code>loop_forever</code>:</p>

          <link rel="import" href="code/async/main.mlt" part="21"/>

          <p>
	    The type <code>never_returns</code> is uninhabited, so a
            function can't return a value of type
            <code>never_returns</code>, which means only a function
            that never returns can have <code>never_returns</code> as
            its return type! Now, if we rewrite our
            <code>do_stuff</code> function, we'll get a helpful type
            error:</p>

          <link rel="import" href="code/async/main.mlt" part="22"/>

          <p>
	    We can resolve the error by calling the function
            <code>never_returns</code>:</p>

          <link rel="import" href="code/async/main.mlt" part="23"/>

          <p>
	    Thus, we got the compilation to go through by explicitly
            marking in the source that the call to
            <code>loop_forever</code> never returns.</p>
	</aside>

	<section id="improving-the-echo-server" data-type="sect2">
          <h2>Improving the Echo Server</h2>

          <p>
	    Let's try to go a little bit farther with our echo
            server by walking through a few improvements. In
            particular, we will:</p>

          <ul>
            <li>
              <p>
		Add a proper command-line interface with
		<code>Command</code></p>
            </li>

            <li>
              <p>
		Add a flag to specify the port to listen on and a
		flag to make the server echo back the capitalized
		version of whatever was sent to it</p>
            </li>

            <li>
              <p>
		Simplify the code using Async's <code>Pipe</code>
		interface</p>
            </li>
          </ul>

          <p>
	    The following code does all of this:</p>

          <link rel="import" href="code/async/better_echo.ml"/>

          <p>
	    Note the use of <code>Deferred.never</code> in the
            <code>run</code> function. As you might guess from the
            name, <code>Deferred.never</code> returns a deferred that
            is never determined. In this case, that indicates that the
            echo server doesn't ever shut down.

	    <idx>Deferred.never</idx></p>

          <p>
	    The biggest change in the preceding code is the use of
            Async's <code>Pipe</code>. A <code>Pipe</code> is an
            asynchronous communication channel that's used for
            connecting different parts of your program. You can think
            of it as a consumer/producer queue that uses deferreds for
            communicating when the pipe is ready to be read from or
            written to. Our use of pipes is fairly minimal here, but
            they are an important part of Async, so it's worth
            discussing them in some detail.

	    <idx>pipes</idx></p>

          <p>
	    Pipes are created in connected read/write pairs:</p>

          <link rel="import" href="code/async/main.mlt" part="24"/>

          <p>
	    <code>r</code> and <code>w</code> are really just read
            and write handles to the same underlying object. Note that
            <code>r</code> and <code>w</code> have weakly polymorphic
            types, as discussed in <a href="01-guided-tour.html#imperative-programming" data-type="xref">Imperative Programming</a>, and so can only contain
            values of a single, yet-to-be-determined type.</p>

          <p>
	    If we just try and write to the writer, we'll see that
            we block indefinitely in <span class="command"><em>utop</em></span>. You can break out of the
            wait by hitting
            <strong><code>Control-C</code></strong>:</p>

          <link rel="import" href="code/async/pipe_write_break.rawscript"/>

          <p>
	    The deferred returned by write completes on its own once
            the value written into the pipe has been read out:</p>

          <link rel="import" href="code/async/main.mlt" part="25"/>

          <p>
	    In the function <code>run</code>, we're taking advantage
            of one of the many utility functions provided for pipes in
            the <code>Pipe</code> module. In particular, we're using
            <code>Pipe.transfer</code> to set up a process that takes
            data from a reader-pipe and moves it to a writer-pipe.
            Here's the type of <code>Pipe.transfer</code>:</p>

          <link rel="import" href="code/async/main.mlt" part="26"/>

          <p>
	    The two pipes being connected are generated by the
            <code>Reader.pipe</code> and <code>Writer.pipe</code> call
            respectively. Note that pushback is preserved throughout
            the process, so that if the writer gets blocked, the
            writer's pipe will stop pulling data from the reader's
            pipe, which will prevent the reader from reading in more
            data.</p>

          <p>
	    Importantly, the deferred returned by
            <code>Pipe.transfer</code> becomes determined once the
            reader has been closed and the last element is transferred
            from the reader to the writer. Once that deferred becomes
            determined, the server will shut down that client
            connection. So, when a client disconnects, the rest of the
            shutdown happens transparently.</p>

          <p>
	    The command-line parsing for this program is based on
            the Command library that we introduced in <a href="14-command-line-parsing.html#command-line-parsing" data-type="xref">Command Line Parsing</a>. Opening
            <code>Async</code>, shadows the <code>Command</code>
            module with an extended version that contains the
            <code>async</code> call:</p>

          <link rel="import" href="code/async/main.mlt" part="27"/>

          <p>
	    This differs from the ordinary
            <code>Command.basic</code> call in that the main function
            must return a <code>Deferred.t</code>, and that the running
            of the command (using <code>Command.run</code>)
            automatically starts the Async scheduler, without requiring
            an explicit call to <code>Scheduler.go</code>.<a data-type="indexterm" data-startref="echo">&nbsp;</a><a data-type="indexterm" data-startref="ALecho">&nbsp;</a></p>
	</section>
      </section>

      <section id="example-searching-definitions-with-duckduckgo" data-type="sect1">
	<h1>Example: Searching Definitions with DuckDuckGo</h1>

	<p>
	  DuckDuckGo is a search engine with a freely available
	  search interface. In this section, we'll use Async to write a
	  small command-line utility for querying DuckDuckGo to extract
	  definitions for a collection of terms.

	  <idx>cohttp library</idx>
	  <idx>uri library</idx>
	  <idx>textwrap library</idx>
	  <idx>DuckDuckGo search engine/additional libraries needed</idx>
	  <idx>search engines</idx></p>

	<p>
	  Our code is going to rely on a number of other libraries,
	  all of which can be installed using OPAM. Refer to <a href="http://realworldocaml.org/install">this Real World OCaml
	    page</a> if you need help on the installation. Here's the
	  list of libraries we'll need:<idx id="ALduckduck">Async library/DuckDuckGo searching example</idx></p>

	<dl>
          <dt><code>textwrap</code></dt>

          <dd>
            <p>
	      A library for wrapping long lines. We'll use this for
              printing out our results.</p>
          </dd>

          <dt><code>uri</code></dt>

          <dd>
            <p>
	      A library for handling URIs, or "Uniform Resource
              Identifiers," of which HTTP URLs are an example.</p>
          </dd>

          <dt><code>yojson</code></dt>

          <dd>
            <p>
	      A JSON parsing library that was described in <a href="15-json.html#handling-json-data" data-type="xref">Handling Json Data</a>.</p>
          </dd>

          <dt><code>cohttp</code></dt>

          <dd>
            <p>
	      A library for creating HTTP clients and servers. We
              need Async support, which comes with the
              <code>cohttp.async</code> package.</p>
          </dd>
	</dl>

	<p>
	  Now let's dive into the implementation.</p>

	<section id="uri-handling" data-type="sect2">
          <h2>URI Handling</h2>

          <p>
	    HTTP URLs, which identify endpoints across the Web, are
            actually part of a more general family known as Uniform
            Resource Identifiers (URIs). The full URI specification is
            defined in <a href="http://tools.ietf.org/html/rfc3986">RFC3986</a> and is
            rather complicated. Luckily, the <code>uri</code> library
            provides a strongly typed interface that takes care of much
            of the hassle.

	    <idx>RFC3986</idx>
	    <idx>Uniform Resource Identifiers (URIs)</idx>
	    <idx>DuckDuckGo search engine/URI handling in</idx></p>

          <p>
	    We'll need a function for generating the URIs that we're
            going to use to query the DuckDuckGo servers:</p>


          <link rel="import" href="code/async/search/search.ml"/>

          <p>
	    A <code>Uri.t</code> is constructed from the
            <code>Uri.of_string</code> function, and a query parameter
            <code>q</code> is added with the desired search query. The
            library takes care of encoding the URI correctly when
            outputting it in the network protocol.</p>
	</section>

	<section id="parsing-json-strings" data-type="sect2">
          <h2>Parsing JSON Strings</h2>

          <p>
	    The HTTP response from DuckDuckGo is in JSON, a common
            (and thankfully simple) format that is specified in
            <a href="http://www.ietf.org/rfc/rfc4627.txt">RFC4627</a>.
            We'll parse the JSON data using the Yojson library, which
            was introduced in <a href="15-json.html#handling-json-data" data-type="xref">Handling Json Data</a>.

	    <idx>Yojson library/parsing JSON with</idx>
	    <idx>DuckDuckGo search engine/parsing JSON strings in</idx>
	    <idx>RFC4627</idx></p>

          <p>
	    We expect the response from DuckDuckGo to come across as
            a JSON record, which is represented by the
            <code>Assoc</code> tag in Yojson's JSON variant. We expect
            the definition itself to come across under either the key
            "Abstract" or "Definition," and so the following code looks
            under both keys, returning the first one for which a
            nonempty value is defined:</p>

          <link rel="import" href="code/async/search/search.ml" part="1"/>
	</section>

	<section id="executing-an-http-client-query" data-type="sect2">
          <h2>Executing an HTTP Client Query</h2>

          <p>
	    Now let's look at the code for dispatching the search
            queries over HTTP, using the Cohttp library:

	    <idx>query-handlers/executing an HTTP client query</idx>
	    <idx>client queries</idx>
	    <idx>HTTP client queries</idx>
	    <idx>DuckDuckGo search engine/executing an HTTP client query in</idx></p>


          <link rel="import" href="code/async/search/search.ml" part="2"/>

          <p>
	    To better understand what's going on, it's useful to
            look at the type for <code>Cohttp_async.Client.get</code>,
            which we can do in <span class="command"><em>utop</em></span>:</p>

          <link rel="import" href="code/async/main.mlt" part="28"/>

          <p>
	    The <code>get</code> call takes as a required argument a
            URI and returns a deferred value containing a
            <code>Cohttp.Response.t</code> (which we ignore) and a pipe
            reader to which the body of the request will be
            written.</p>

          <p>
	    In this case, the HTTP body probably isn't very large,
            so we call <code>Pipe.to_list</code> to collect the strings
            from the pipe as a single deferred list of strings. We then
            join those strings using <code>String.concat</code> and
            pass the result through our parsing function.</p>

          <p>
	    Running a single search isn't that interesting from a
            concurrency perspective, so let's write code for
            dispatching multiple searches in parallel. First, we need
            code for formatting and printing out the search result:</p>

          <link rel="import" href="code/async/search/search.ml" part="3"/>

          <p>
	    We use the <code>Wrapper</code> module from the
            <code>textwrap</code> package to do the line wrapping. It
            may not be obvious that this routine is using Async, but it
            does: the version of <code>printf</code> that's called here
            is actually Async's specialized <code>printf</code> that
            goes through the Async scheduler rather than printing
            directly. The original definition of <code>printf</code> is
            shadowed by this new one when you open
            <code>Async</code>. An important side effect of this is
            that if you write an Async program and forget to start the
            scheduler, calls like <code>printf</code> won't actually
            generate any output!</p>

          <p>
	    The next function dispatches the searches in parallel,
            waits for the results, and then prints:</p>

          <link rel="import" href="code/async/search/search.ml" part="4"/>

          <p>
	    We used <code>List.map</code> to call
            <code>get_definition</code> on each word, and
            <code>Deferred.all</code> to wait for all the results.
            Here's the type of <code>Deferred.all</code>:</p>

          <link rel="import" href="code/async/main.mlt" part="29"/>

          <p>
	    Note that the list returned by <code>Deferred.all</code>
            reflects the order of the deferreds passed to it. As such,
            the definitions will be printed out in the same order that
            the search words are passed in, no matter what order the
            queries return in. We could rewrite this code to print out
            the results as they're received (and thus potentially out
            of order) as follows:</p>

          <link rel="import" href="code/async/search_out_of_order.ml" part="1"/>

          <p>
	    The difference is that we both dispatch the query and
            print out the result in the closure passed to
            <code>map</code>, rather than wait for all of the results
            to get back and then print them out together. We use
            <code>Deferred.all_unit</code>, which takes a list of
            <code>unit</code> deferreds and returns a single
            <code>unit</code> deferred that becomes determined when
            every deferred on the input list is determined. We can see
            the type of this function in <span class="command"><em>utop</em></span>:</p>

          <link rel="import" href="code/async/main.mlt" part="30"/>

          <p>
	    Finally, we create a command-line interface using
            <code>Command.async</code>:</p>

          <link rel="import" href="code/async/search/search.ml" part="5"/>

          <p>
	    And that's all we need for a simple but usable
            definition searcher:<a data-type="indexterm" data-startref="ALduckduck">&nbsp;</a></p>
          <link rel="import" href="code/async/search/jbuild"/>
          <link rel="import" href="code/async/search/run_search.sh"/>
	</section>
      </section>

      <section id="exception-handling" data-type="sect1">
	<h1>Exception Handling</h1>

	<p>
	  When programming with external resources, errors are
	  everywhere: everything from a flaky server to a network
	  outage to exhausting of local resources can lead to a runtime
	  error. When programming in OCaml, some of these errors will
	  show up explicitly in a function's return type, and some of
	  them will show up as exceptions. We covered exception
	  handling in OCaml in <a href="07-error-handling.html#exceptions" data-type="xref">Exceptions</a>, but as we'll see, exception handling
	  in a concurrent program presents some new challenges.

	  <idx>exceptions/in concurrent programming</idx>

	  <idx>concurrent programming</idx> <idx id="ALexcept">Async library/exception handling in</idx></p>

	<p>
	  Let's get a better sense of how exceptions work in Async
	  by creating an asynchronous computation that (sometimes)
	  fails with an exception. The function
	  <code>maybe_raise</code> <span class="keep-together">blocks
	    for half a second,</span> and then either throws an exception
	  or returns <code>unit</code>, alternating between the two
	  behaviors on subsequent calls:</p>

	<link rel="import" href="code/async/main.mlt" part="31"/>

	<p>
	  In <span class="command"><em>utop</em></span>, the
	  exception thrown by <code>maybe_raise ()</code> terminates
	  the evaluation of just that expression, but in a standalone
	  program, an uncaught exception would bring down the entire
	  process.</p>

	<p>
	  So, how could we capture and handle such an exception? You
	  might try to do this using OCaml's built-in
	  <code>try/with</code> statement, but as you can see that
	  doesn't quite do the trick:</p>

	<link rel="import" href="code/async/main.mlt" part="32"/>

	<p>
	  This didn't work because <code>try/with</code> only
	  captures exceptions that are thrown in the code directly
	  executed within it, while <code>maybe_raise</code> schedules
	  an Async job to run in the future, and it's that job that
	  throws an exception.</p>

	<p>
	  We can capture this kind of asynchronous error using the
	  <code>try_with</code> function provided by Async:

	  <idx>exceptions/asynchronous errors</idx></p>


	<link rel="import" href="code/async/main.mlt" part="33"/>

	<p>
	  <code>try_with f</code> takes as its argument a
	  deferred-returning thunk <code>f</code> and returns a
	  deferred that becomes determined either as <code>Ok</code> of
	  whatever <code>f</code> returned, or <code>Error exn</code>
	  if <code>f</code> threw an exception before its return value
	  became determined.</p>

	<section id="monitors" data-type="sect2">
          <h2>Monitors</h2>

          <p>
	    <code>try_with</code> is a great way of handling
            exceptions in Async, but it's not the whole story. All of
            Async's exception-handling mechanisms,
            <code>try_with</code> included, are built on top of Async's
            system of <em>monitors</em>, which are inspired by the
            error-handling mechanism in Erlang of the same name.
            Monitors are fairly low-level and are only occasionally
            used directly, but it's nonetheless worth understanding how
            they work.

	    <idx>monitors</idx></p>

          <p>
	    In Async, a monitor is a context that determines what to
            do when there is an unhandled exception. Every Async job
            runs within the context of some monitor, which, when the
            job is running, is referred to as the current monitor. When
            a new Async job is scheduled, say, using <code>bind</code>
            or <code>map</code>, it inherits the current monitor of the
            job that spawned it.</p>

          <p>
	    Monitors are arranged in a treeâ€”when a new monitor is
            created (say, using <code>Monitor.create</code>), it is a
            child of the current monitor. You can explicitly run jobs
            within a monitor using <code>within</code>, which takes a
            thunk that returns a nondeferred value, or
            <code>within'</code>, which takes a thunk that returns a
            deferred. Here's an example:</p>

          <link rel="import" href="code/async/main.mlt" part="34"/>

          <p>
	    In addition to the ordinary stack-trace, the exception
            displays the trace of monitors through which the exception
            traveled, starting at the one we created, called "blow up
            monitor." The other monitors you see come
            from <span class="command"><em>utop</em></span>'s special
            handling of deferreds.</p>

          <p>
	    Monitors can do more than just augment the error-trace of
            an exception. You can also use a monitor to explicitly
            handle errors delivered to that
            monitor. The <code>Monitor.detach_and_get_error_stream</code>
            call is a particularly important one. It detaches the
            monitor from its parent, handing back the stream of errors
            that would otherwise have been delivered to the parent
            monitor. This allows one to do custom handling of errors,
            which may include reraising errors to the parent. Here is
            a very simple example of a function that captures and
            ignores errors in the processes it spawns.</p>

          <link rel="import" href="code/async/main.mlt" part="35"/>

	  <p>
	    The deferred returned by this function is never
	    determined, since the computation ends with an exception
	    rather than a return value. That means that if we run this
	    function in <span class="command"><em>utop</em></span>,
	    we'll never get our prompt back.</p>

	  <p>
	    We can fix this by using <code>Deferred.any</code> along
	    with a timeout to get a deferred we know will become
	    determined eventually. <code>Deferred.any</code> takes a
	    list of deferreds, and returns a deferred which will
	    become determined assuming any of its arguments becomes
	    determined.
	  </p>

          <link rel="import" href="code/async/main.mlt" part="35.5"/>

          <p>
	    As you can see, the message "an error happened" is printed
	    out before the timeout expires. </p>

          <p>
	    Here's an example of a monitor that passes some exceptions
            through to the parent and handles others.  Exceptions are
            sent to the parent using <code>Monitor.send_exn</code>,
            with <code>Monitor.current</code> being called to find the
            current monitor, which is the parent of the newly created
            monitor.</p>

          <link rel="import" href="code/async/main.mlt" part="36"/>

          <p>
	    Note that we use <code>Monitor.extract_exn</code> to grab
            the underlying exception that was thrown. Async wraps
            exceptions it catches with extra information, including
            the monitor trace, so you need to grab the underlying
            exception if you want to depend on the details of the
            original exception thrown.</p>

          <p>
	    If we pass in an exception other
            than <code>Ignore_me</code>, like, say, the built-in
            exception <code>Not_found</code>, then the exception will
            be passed to the parent monitor and delivered as
            usual:</p>

          <link rel="import" href="code/async/main.mlt" part="37"/>

          <p>
	    If instead we use <code>Ignore_me</code>, the exception
            will be ignored, and the computation will finish when the
            timeout expires.</p>

          <link rel="import" href="code/async/main.mlt" part="38"/>

          <p>
	    In practice, you should rarely use monitors directly,
            and instead use functions like <code>try_with</code> and
            <code>Monitor.protect</code> that are built on top of
            monitors. One example of a library that uses monitors
            directly is <code>Tcp.Server.create</code>, which tracks
            both exceptions thrown by the logic that handles the
            network connection and by the callback for responding to an
            individual request, in either case responding to an
            exception by closing the connection. It is for building
            this kind of custom error handling that monitors can be
            helpful.</p>
	</section>

	<section id="example-handling-exceptions-with-duckduckgo" data-type="sect2">
          <h2>Example: Handling Exceptions with DuckDuckGo</h2>

          <p>
	    Let's now go back and improve the exception handling of
            our DuckDuckGo client. In particular, we'll change it so
            that any query that fails is reported without preventing
            other queries from completing.

	    <idx>exceptions/search engine example</idx>
	    <idx>DuckDuckGo search engine/exception handling in</idx></p>

          <p>
	    The search code as it is fails rarely, so let's make a
            change that allows us to trigger failures more predictably.
            We'll do this by making it possible to distribute the
            requests over multiple servers. Then, we'll handle the
            errors that occur when one of those servers is
            misspecified.</p>

          <p>
	    First we'll need to change <code>query_uri</code> to
            take an argument specifying the server to connect to:</p>

          <link rel="import" href="code/async/search_with_configurable_server/search_with_configurable_server.ml" part="1"/>

          <p>
	    In addition, we'll make the necessary changes to get the
            list of servers on the command-line, and to distribute the
            search queries round-robin across the list of servers. Now,
            let's see what happens if we rebuild the application and
            run it giving it a list of servers, some of which won't
            respond to the query:</p>
          <link rel="import" href="code/async/search_with_configurable_server/jbuild"/>
          <link rel="import" href="code/async/search_with_configurable_server/run_search_with_configurable_server.errsh"/>

          <p>
	    As you can see, we got a "Connection refused" failure,
            which ends the entire program, even though one of the two
            queries would have gone through successfully on its own. We
            can handle the failures of individual connections
            separately by using the <code>try_with</code> function
            within each call to <code>get_definition</code>, as
            follows:</p>

          <link rel="import" href="code/async/search_with_error_handling/search_with_error_handling.ml" part="1"/>

          <p>
	    Here, we first use <code>try_with</code> to capture the
            exception, and then use map (the <code>&gt;&gt;|</code>
            operator) to convert the error into the form we want: a
            pair whose first element is the word being searched for,
            and the second element is the (possibly erroneous)
            result.</p>

          <p>
	    Now we just need to change the code for
            <code>print_result</code> so that it can handle the new
            type:</p>

          <link rel="import" href="code/async/search_with_error_handling/search_with_error_handling.ml" part="2"/>

          <p>
	    Now, if we run that same query, we'll get individualized
            handling of the connection failures:</p>
          <link rel="import" href="code/async/search_with_error_handling/jbuild"/>
          <link rel="import" href="code/async/search_with_error_handling/run_search_with_error_handling.sh"/>

          <p>
	    Now, only the query that went to <code>localhost</code>
            failed.</p>

          <p>
	    Note that in this code, we're relying on the fact that
            <code>Cohttp_async.Client.get</code> will clean up after
            itself after an exception, in particular by closing its
            file descriptors. If you need to implement such
            functionality directly, you may want to use the
            <code>Monitor.protect</code> call, which is analogous to
            the <code>protect</code> call described in <a href="07-error-handling.html#cleaning-up-in-the-presence-of-exceptions" data-type="xref">Cleaning Up In The Presence Of
              Exceptions</a>.<a data-type="indexterm" data-startref="ALexcept">&nbsp;</a></p>
	</section>
      </section>

      <section id="timeouts-cancellation-and-choices" data-type="sect1">
	<h1>Timeouts, Cancellation, and Choices</h1>

	<p>
	  In a concurrent program, one often needs to combine
	  results from multiple, distinct concurrent subcomputations
	  going on in the same program. We already saw this in our
	  DuckDuckGo example, where we used <code>Deferred.all</code>
	  and <code>Deferred.all_unit</code> to wait for a list of
	  deferreds to become determined. Another useful primitive is
	  <code>Deferred.both</code>, which lets you wait until two
	  deferreds of different types have returned, returning both
	  values as a tuple. Here, we use the function
	  <code>sec</code>, which is shorthand for creating a time-span
	  equal to a given number of seconds:

	  <idx>errors/timeouts and cancellations</idx>
	  <idx>Deferred.both</idx>
	  <idx>cancellations</idx>
	  <idx>timeouts</idx>
	  <idx>Async library/timeouts and cancellations</idx></p>


	<link rel="import" href="code/async/main.mlt" part="39"/>

	<p>
	  Sometimes, however, we want to wait only for the first of
	  multiple events to occur. This happens particularly when
	  dealing with timeouts. In that case, we can use the call
	  <code>Deferred.any</code>, which, given a list of deferreds,
	  returns a single deferred that will become determined once
	  any of the values on the list is determined.</p>

	<link rel="import" href="code/async/main.mlt" part="40"/>

	<p>
	  Let's use this to add timeouts to our DuckDuckGo searches.
	  The following code is a wrapper for
	  <code>get_definition</code> that takes a timeout (in the form
	  of a <code>Time.Span.t</code>) and returns either the
	  definition, or, if that takes too long, an error:</p>

	<link rel="import" href="code/async/search_with_timeout.ml" part="1"/>

	<p>
	  We use <code>&gt;&gt;|</code> above to transform the
	  deferred values we're waiting for so that
	  <code>Deferred.any</code> can choose between values of the
	  same type.</p>

	<p>
	  A problem with this code is that the HTTP query kicked off
	  by <code>get_definition</code> is not actually shut down when
	  the timeout fires. As such,
	  <code>get_definition_with_timeout</code> can leak an open
	  connection. Happily, Cohttp does provide a way of shutting
	  down a client. You can pass a deferred under the label
	  <code>interrupt</code> to
	  <code>Cohttp_async.Client.get</code>. Once
	  <code>interrupt</code> is determined, the client connection
	  will be shut down.</p>

	<p>
	  The following code shows how you can change
	  <code>get_definition</code> and
	  <code>get_definition_with_timeout</code> to cancel the
	  <code>get</code> call if the timeout expires:</p>

	<link rel="import" href="code/async/search_with_timeout_no_leak_simple/search_with_timeout_no_leak_simple.ml" part="1"/>

	<p>
	  Next, we'll modify
	  <code>get_definition_with_timeout</code> to create a deferred
	  to pass in to <code>get_definition</code>, which will become
	  determined when our timeout expires:</p>

	<link rel="import" href="code/async/search_with_timeout_no_leak_simple/search_with_timeout_no_leak_simple.ml" part="2"/>

	<p>
	  This will work and will cause the connection to shutdown
	  cleanly when we time out; but our code no longer explicitly
	  knows whether or not the timeout has kicked in. In
	  particular, the error message on a timeout will now be
	  <code>"Unexpected failure"</code> rather than <code>"Timed
	    out"</code>, which it was in our previous implementation.</p>

	<p>
	  We can get more precise handling of timeouts using Async's
	  <code>choose</code> function. <code>choose</code> lets you
	  pick among a collection of different deferreds, reacting to
	  exactly one of them. Each deferred is paired, using the
	  function <code>choice</code>, with a function that is called
	  if and only if that deferred is chosen. Here's the type
	  signature of <code>choice</code> and <code>choose</code>:</p>

	<link rel="import" href="code/async/main.mlt" part="41"/>

	<p>
	  Note that there's no guarantee that the winning deferred
	  will be the one that becomes determined first. But
	  <code>choose</code> does guarantee that only one
	  <code>choice</code> will be chosen, and only the chosen
	  <code>choice</code> will execute the attached function.</p>

	<p>
	  In the following example, we use <code>choose</code> to
	  ensure that the <code>interrupt</code> deferred becomes
	  determined if and only if the timeout deferred is chosen.
	  Here's the code:</p>

	<link rel="import" href="code/async/search_with_timeout_no_leak/search_with_timeout_no_leak.ml" part="2"/>

	<p>
	  Now, if we run this with a suitably small timeout, we'll
	  see that one query succeeds and the other fails reporting a
	  timeout:</p>
  <link rel="import" href="code/async/search_with_timeout_no_leak/jbuild"/>
	<link rel="import" href="code/async/search_with_timeout_no_leak/run_search_with_timeout_no_leak.sh"/>
      </section>

      <section id="working-with-system-threads" data-type="sect1">
	<h1>Working with System Threads</h1>

	<p>
	  Although we haven't worked with them yet, OCaml does have
	  built-in support for true system threads, i.e., kernel-level
	  threads whose interleaving is controlled by the operating
	  system. We discussed in the beginning of the chapter why
	  Async is generally a better choice than system threads, but
	  even if you mostly use Async, OCaml's system threads are
	  sometimes necessary, and it's worth understanding them.

	  <idx>parallelism</idx>
	  <idx>kernel-level threads</idx>
	  <idx>threads/kernel-level threads</idx>
	  <idx id="systhrd">system threads</idx>
	  <idx id="ALsysthr">Async library/system threads and</idx></p>

	<p>
	  The most surprising aspect of OCaml's system threads is
	  that they don't afford you any access to physical
	  parallelism. That's because OCaml's runtime has a single
	  runtime lock that at most one thread can be holding at a
	  time.</p>

	<p>
	  Given that threads don't provide physical parallelism, why
	  are they useful at all?</p>

	<p>
	  The most common reason for using system threads is that
	  there are some operating system calls that have no
	  nonblocking alternative, which means that you can't run them
	  directly in a system like Async without blocking your entire
	  program. For this reason, Async maintains a thread pool for
	  running such calls. Most of the time, as a user of Async you
	  don't need to think about this, but it is happening under the
	  covers.

	  <idx>threads/benefits of</idx></p>

	<p>
	  Another reason to have multiple threads is to deal with
	  non-OCaml libraries that have their own event loop or for
	  another reason need their own threads. In that case, it's
	  sometimes useful to run some OCaml code on the foreign thread
	  as part of the communication to your main program. OCaml's
	  foreign function interface is discussed in more detail in
	  <a href="19-foreign-function-interface.html#foreign-function-interface" data-type="xref">Foreign Function Interface</a>.</p>

	<p>
	  Another occasional use for system threads is to better
	  interoperate with compute-intensive OCaml code. In Async, if
	  you have a long-running computation that never calls
	  <code>bind</code> or <code>map</code>, then that computation
	  will block out the Async runtime until it completes.</p>

	<p>
	  One way of dealing with this is to explicitly break up the
	  calculation into smaller pieces that are separated by binds.
	  But sometimes this explicit yielding is impractical, since it
	  may involve intrusive changes to an existing codebase.
	  Another solution is to run the code in question in a separate
	  thread. Async's <code>In_thread</code> module provides
	  multiple facilities for doing just this,
	  <code>In_thread.run</code> being the simplest. We can simply
	  write:

	  <idx>In_thread module</idx></p>


	<link rel="import" href="code/async/main.mlt" part="42"/>

	<p>
	  to cause <code>List.range 1 10</code> to be run on one of
	  Async's worker threads. When the computation is complete, the
	  result is placed in the deferred, where it can be used in the
	  ordinary way from Async.</p>

	<p>
	  Interoperability between Async and system threads can be
	  quite tricky. Consider the following function for testing how
	  responsive Async is. The function takes a deferred-returning
	  thunk, and it first runs that thunk, and then uses
	  <code>Clock.every</code> to wake up every 100 milliseconds
	  and print out a timestamp, until the returned deferred
	  becomes determined, at which point it prints out one last
	  timestamp:</p>

	<link rel="import" href="code/async/main.mlt" part="43"/>

	<p>
	  If we feed this function a simple timeout deferred, it
	  works as you might expect, waking up roughly every 100
	  milliseconds:</p>

	<link rel="import" href="code/async/main.mlt" part="44"/>

	<p>
	  Now see what happens if, instead of waiting on a clock
	  event, we wait for a busy loop to finish running:</p>

	<link rel="import" href="code/async/main.mlt" part="45"/>

	<p>
	  As you can see, instead of waking up 10 times a second,
	  <code>log_delays</code> is blocked out entirely while
	  <code>busy_loop</code> churns away.</p>

	<p>
	  If, on the other hand, we use <code>In_thread.run</code>
	  to offload this to a different system thread, the behavior
	  will be different:</p>

	<link rel="import" href="code/async/main.mlt" part="46"/>

	<p>
	  Now <code>log_delays</code> does get a chance to run, but
	  not nearly as often as every 100 milliseconds. The reason is
	  that now that we're using system threads, we are at the mercy
	  of the operating system to decide when each thread gets
	  scheduled. The behavior of threads is very much dependent on
	  the operating system and how it is configured.</p>

	<p>
	  Another tricky aspect of dealing with OCaml threads has to
	  do with allocation. When compiling to native code, OCaml's
	  threads only get a chance to give up the runtime lock when
	  they interact with the allocator, so if there's a piece of
	  code that doesn't allocate at all, then it will never allow
	  another OCaml thread to run. Bytecode doesn't have this
	  behavior, so if we run a nonallocating loop in bytecode, our
	  timer process will get to run:</p>

	<link rel="import" href="code/async/main.mlt" part="47"/>

	<p>
	  But if we compile this to a native-code executable, then
	  the nonallocating busy loop will block anything else from
	  running:</p>

	<link rel="import" href="code/async/run_native_code_log_delays.rawsh"/>

	<p>
	  The takeaway from these examples is that predicting thread
	  interleavings is a subtle business. Staying within the bounds
	  of Async has its limitations, but it leads to more
	  predictable behavior.</p>

	<section id="thread-safety-and-locking" data-type="sect2">
          <h2>Thread-Safety and Locking</h2>

          <p>
	    Once you start working with system threads, you'll need
            to be careful about mutable data structures. Most mutable
            OCaml data structures do not have well-defined semantics
            when accessed concurrently by multiple threads. The issues
            you can run into range from runtime exceptions to corrupted
            data structures to, in some rare cases, segfaults. That
            means you should always use mutexes when sharing mutable
            data between different systems threads. Even data
            structures that seem like they should be safe but are
            mutable under the covers, like lazy values, can have
            undefined behavior when accessed from multiple threads.

	    <idx>mutexes</idx>
	    <idx>segfaults</idx>
	    <idx>threads/locking and</idx>
	    <idx>threads/thread-safety</idx></p>

          <p>
	    There are two commonly available mutex packages for
            OCaml: the <code>Mutex</code> module that's part of the
            standard library, which is just a wrapper over OS-level
            mutexes and <code>Nano_mutex</code>, a more efficient
            alternative that takes advantage of some of the locking
            done by the OCaml runtime to avoid needing to create an
            OS-level mutex much of the time. As a result, creating a
            <code>Nano_mutex.t</code> is 20 times faster than creating
            a <code>Mutex.t</code>, and acquiring the mutex is about 40
            percent faster.</p>

          <p>
	    Overall, combining Async and threads is quite tricky,
            but it can be done safely if the following hold:</p>

          <ul>
            <li>
              <p>
		There is no shared mutable state between the various
		threads involved.</p>
            </li>

            <li>
              <p>
		The computations executed by
		<code>In_thread.run</code> do not make any calls to the
		Async library.</p>
            </li>
          </ul>

          <p>
	    It is possible to safely use threads in ways that
            violate these constraints. In particular, foreign threads
            can acquire the Async lock using calls from the
            <code>Thread_safe</code> module in Async, and thereby run
            Async computations safely. This is a very flexible way of
            connecting threads to the Async world, but it's a complex
            use case that is beyond the scope of this chapter.

            <a data-type="indexterm" data-startref="systhrd">&nbsp;</a>
	    <a data-type="indexterm" data-startref="ALsysthr">&nbsp;</a>
	  </p>
	</section>
      </section>
    </section>
  </body>
</html>
