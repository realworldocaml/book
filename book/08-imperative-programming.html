

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 (experimental) for Mac OS X https://github.com/w3c/tidy-html5/tree/c63cc39"/>

  <title></title>
</head>

<body>
  <section xmlns="http://www.w3.org/1999/xhtml" id="imperative-programming-1" data-type="chapter">
    <h1>Imperative Programming</h1>

    <p>
      Most of the code shown so far in this book, and indeed, most
      OCaml code in general, is <em>pure</em>. Pure code works
      without mutating the program's internal state, performing I/O,
      reading the clock, or in any other way interacting with
      changeable parts of the world. Thus, a pure function behaves
      like a mathematical function, always returning the same results
      when given the same inputs, and never affecting the world
      except insofar as it returns the value of its computation.
      <em>Imperative</em> code, on the other hand, operates by side
      effects that modify a program's internal state or interact with
      the outside world. An imperative function has a new effect, and
      potentially returns different results, every time it's
      called.

      <idx>imperative programming/benefits of</idx>
      <idx>pure	code</idx>
      <idx>programming/immutable vs. imperative</idx>
      <idx id="PROGimper">programming/imperative programming</idx>
    </p>

    <p>
      Pure code is the default in OCaml, and for good reason—it's
      generally easier to reason about, less error prone and more
      composable. But imperative code is of fundamental importance to
      any practical programming language, because real-world tasks
      require that you interact with the outside world, which is by
      its nature imperative. Imperative programming can also be
      important for performance. While pure code is quite efficient in
      OCaml, there are many algorithms that can only be implemented
      efficiently using imperative techniques.</p>

    <p>
      OCaml offers a happy compromise here, making it easy and
      natural to program in a pure style, but also providing great
      support for imperative programming. This chapter will walk you
      through OCaml's imperative features, and help you use them to
      their fullest.</p>

    <section id="example-imperative-dictionaries" data-type="sect1">
      <h1>Example: Imperative Dictionaries</h1>

      <p>
	We'll start with the implementation of a simple imperative
	dictionary, i.e., a mutable mapping from keys to values. This
	is really for illustration purposes; both Core and the
	standard library provide imperative dictionaries, and for
	most real-world tasks, you should use one of those
	implementations. There's more advice on using Core's
	implementation in particular in
	<a href="13-maps-and-hashtables.html#maps-and-hash-tables" data-type="xref">Maps And Hash Tables</a>.

	<idx id="DICTimper">dictionaries, imperative</idx>
	<idx>Core standard library/imperative dictionaries in</idx>
	<idx id="IPimpdict">imperative programming/imperative
	  dictionaries</idx>
      </p>

      <p>
	The dictionary we'll describe now, like those in Core and
	the standard library, will be implemented as a hash table. In
	particular, we'll use an <em>open hashing</em> scheme, where
	the hash table will be an array of buckets, each bucket
	containing a list of key/value pairs that have been hashed
	into that bucket.

	<idx>open hashing</idx>
      </p>

      <p>
	Here's the interface we'll match, provided as
	an <code>mli</code>. The type <code>('a, 'b) t</code> represents
	a dictionary with keys of type <code>'a</code> and data of
	type <code>'b</code>:</p>

      <link rel="import" href="code/imperative-programming/dictionary.mli" part="1"/>

      <p>
	The <code>mli</code> also includes a collection of helper
	functions whose purpose and behavior should be largely
	inferrable from their names and type signatures. Notice that
	a number of the functions, in particular, ones like
	<code>add</code> that modify the dictionary, return
	<code>unit</code>. This is typical of functions that act by
	side effect.</p>

      <p>
	We'll now walk through the implementation (contained in
	the corresponding <code>ml</code> file) piece by piece,
	explaining different imperative constructs as they come
	up.</p>

      <p>
	Our first step is to define the type of a dictionary as a
	record with two fields:</p>

      <link rel="import" href="code/imperative-programming/dictionary.ml" part="1"/>

      <p>
	The first field, <code>length</code>, is declared as
	mutable. In OCaml, records are immutable by default, but
	individual fields are mutable when marked as such. The second
	field, <code>buckets</code>, is immutable but contains an
	array, which is itself a mutable data
	structure.

	<idx>fields/mutability of</idx></p>

      <p>
	Now we'll start putting together the basic functions for
	manipulating a dictionary:</p>

      <link rel="import" href="code/imperative-programming/dictionary.ml" part="2"/>

      <p>
	Note that <code>num_buckets</code> is a constant, which
	means our bucket array is of fixed length. A practical
	implementation would need to be able to grow the array as the
	number of elements in the dictionary increases, but we'll
	omit this to simplify the presentation.</p>

      <p>
	The function <code>hash_bucket</code> is used throughout the
	rest of the module to choose the position in the array that a
	given key should be stored at. It is implemented on top
	of <code>Hashtbl.hash</code>, which is a hash function
	provided by the OCaml runtime that can be applied to values of
	any type. Thus, its own type is polymorphic: <code>'a
	  -&gt; int</code>.</p>

      <p>
	The other functions defined above are fairly
	straightforward:</p>

      <dl>
        <dt><code>create</code></dt>

        <dd> <p>Creates an empty dictionary.</p> </dd>

        <dt><code>length</code></dt>

        <dd>
          <p>Grabs the length from the corresponding record field,
          thus returning the number of entries stored in the
          dictionary.</p>
        </dd>

        <dt><code>find</code></dt>

        <dd>
          <p>Looks for a matching key in the table and returns the
          corresponding value if found as an option.</p>
        </dd>
      </dl>

      <p>
	Another important piece of imperative syntax shows up in
	<code>find</code>: we write <code>array.(index)</code> to
	grab a value from an array. <code>find</code> also uses
	<code>List.find_map</code>, which you can see the type of by
	typing it into the toplevel:</p>

      <link rel="import" href="code/imperative-programming/examples.mlt" part="1"/>

      <p>
	<code>List.find_map</code> iterates over the elements of
	the list, calling <code>f</code> on each one until a
	<code>Some</code> is returned by <code>f</code>, at which
	point that value is returned. If <code>f</code> returns
	<code>None</code> on all values, then <code>None</code> is
	returned.</p>

      <p>
	Now let's look at the implementation of <code>iter</code>:</p>

      <link rel="import" href="code/imperative-programming/dictionary.ml" part="3"/>

      <p>
	<code>iter</code> is designed to walk over all the entries in
	the dictionary. In particular, <code>iter t ~f</code> will
	call <code>f</code> for each key/value pair in
	dictionary <code>t</code>. Note that <code>f</code> must
	return <code>unit</code>, since it is expected to work by side
	effect rather than by returning a value, and the
	overall <code>iter</code> function returns <code>unit</code>
	as well.</p>

      <p>
	The code for <code>iter</code> uses two forms of iteration:
	a <code>for</code> loop to walk over the array of buckets; and
	within that loop a call to <code>List.iter</code> to walk over
	the values in a given bucket. We could have done the outer
	loop with a recursive function instead of a <code>for</code>
	loop, but <code>for</code> loops are syntactically convenient,
	and are more familiar and idiomatic in imperative
	contexts.</p>

      <p>
	The following code is for adding and removing mappings from
	the dictionary:</p>

      <link rel="import" href="code/imperative-programming/dictionary.ml" part="4"/>

      <p>
	This preceding code is made more complicated by the fact that
	we need to detect whether we are overwriting or removing an
	existing binding, so we can decide
	whether <code>t.length</code> needs to be changed. The helper
	function <code>bucket_has_key</code> is used for this
	purpose.</p>

      <p>
	Another piece of syntax shows up in both <code>add</code>
	and <code>remove</code>: the use of the <code>&lt;-</code>
	operator to update elements of an array (<code>array.(i)
	  &lt;- expr</code>) and for updating a record field
	(<code>record.field &lt;- expression</code>).</p>

      <p>
	We also use <code>;</code>, the sequencing operator, to
	express a sequence of imperative actions. We could have done
	the same using <code>let</code> bindings:</p>

      <link rel="import" href="code/imperative-programming/dictionary2.ml" part="1"/>

      <p>but <code>;</code> is more concise and idiomatic. More
      generally,</p>

      <link rel="import" href="code/imperative-programming/semicolon.syntax"/>

      <p>is equivalent to</p>

      <link rel="import" href="code/imperative-programming/let-unit.syntax"/>

      <p>
	When a sequence expression <code>expr1; expr2</code> is
	evaluated, <code>expr1</code> is evaluated first, and
	then <code>expr2</code>. The expression <code>expr1</code>
	should have type <code>unit</code> (though this is a warning
	rather than a hard restriction.
	The <code>-strict-sequence</code> compiler flag makes this a
	hard restriction, which is generally a good idea), and the
	value of <code>expr2</code> is returned as the value of the
	entire sequence. For example, the sequence <code>print_string
	"hello world"; 1 + 2</code> first prints the
	string <code>"hello world"</code>, then returns the
	integer <code>3</code>.</p>

      <p>
	Note also that we do all of the side-effecting operations
	at the very end of each function. This is good practice
	because it minimizes the chance that such operations will be
	interrupted with an exception, leaving the data structure in
	an inconsistent state.

	<a data-type="indexterm" data-startref="DICTimper">&nbsp;</a>
	<a data-type="indexterm" data-startref="IPimpdict">&nbsp;</a></p>
    </section>

    <section id="primitive-mutable-data" data-type="sect1">
      <h1>Primitive Mutable Data</h1>

      <p>Now that we've looked at a complete example, let's take a
      more systematic look at imperative programming in OCaml. We
      encountered two different forms of mutable data above: records
      with mutable fields and arrays. We'll now discuss these in more
      detail, along with the other primitive forms of mutable data
      that are available in OCaml.

	<idx>array-like data</idx>
	<idx>data structures/primitive mutable data</idx>
	<idx>mutable data</idx>
	<idx>primitive mutable data/array-like data</idx>
	<idx>imperative programming/primitive mutable data</idx></p>

      <section id="array-like-data" data-type="sect2">
        <h2>Array-Like Data</h2>

        <p>OCaml supports a number of array-like data structures;
        i.e., mutable integer-indexed containers that provide
        constant-time access to their elements. We'll discuss
        several of them in this section.</p>

        <section id="ordinary-arrays" data-type="sect3">
          <h3>Ordinary arrays</h3>

          <p>
	    The <code>array</code> type is used for general-purpose
            polymorphic arrays. The <code>Array</code> module has a
            variety of utility functions for interacting with arrays,
            including a number of mutating operations. These
            include <code>Array.set</code>, for setting an individual
            element, and <code>Array.blit</code>, for efficiently
            copying values from one range of indices to
            another.

	    <idx>values/copying with Array.blit</idx>
	    <idx>elements/setting with Array.set</idx>
	    <idx>Array module/Array.blit</idx>
	    <idx>Array module/Array.set</idx>
	  </p>

          <p>Arrays also come with special syntax for retrieving an
            element from an array:</p>

          <link rel="import" href="code/imperative-programming/array-get.syntax"/>

          <p>and for setting an element in an array:</p>

          <link rel="import" href="code/imperative-programming/array-set.syntax"/>

          <p>
	    Out-of-bounds accesses for arrays (and indeed for all the
            array-like data structures) will lead to an exception
            being thrown.</p>

          <p>
	    Array literals are written using <code>[|</code>
            and <code>|]</code> as delimiters. Thus, <code>[| 1; 2; 3
              |]</code> is a literal integer array.</p>
        </section>

        <section id="strings" data-type="sect3">
          <h3>Strings</h3>

          <p>Strings are essentially byte arrays which are often
          used for textual data. The main advantage of using a
          <code>string</code> in place of a <code>Char.t
          array</code> (a <code>Char.t</code> is an 8-bit
          character) is that the former is considerably more
          space-efficient; an array uses one word—8 bytes on a
          64-bit machine—to store a single entry, whereas strings
          use 1 byte per character.

	  <idx>byte arrays</idx>
	  <idx>strings/vs. Char.t arrays</idx></p>

          <p>Strings also come with their own syntax for getting
          and setting values:</p>
          <link rel="import" href="code/imperative-programming/string.syntax"/>

          <p>And string literals are bounded by quotes. There's
          also a module <code>String</code> where you'll find
          useful functions for working with strings.</p>
        </section>

        <section id="bigarrays" data-type="sect3">
          <h3>Bigarrays</h3>

          <p>A <code>Bigarray.t</code> is a handle to a block of
          memory stored outside of the OCaml heap. These are mostly
          useful for interacting with C or Fortran libraries, and
          are discussed in <a href="20-runtime-memory-layout.html#memory-representation-of-values" data-type="xref">Memory Representation Of Values</a>.
          Bigarrays too have their own getting and setting
          syntax:

	    <idx>bigarrays</idx></p>

          <link rel="import" href="code/imperative-programming/bigarray.syntax"/>
        </section>
      </section>

      <section id="mutable-record-and-object-fields-and-ref-cells" data-type="sect2">
        <h2>Mutable Record and Object Fields and Ref Cells</h2>

        <p>As we've seen, records are immutable by default, but
        individual record fields can be declared as mutable. These
        mutable fields can be set using the <code>&lt;-</code>
        operator, i.e., <code>record.field &lt;-
        expr</code>.

	  <idx>fields/mutability of</idx></p>

        <p>As we'll see in <a href="11-objects.html#objects" data-type="xref">Objects</a>, fields of an object can
        similarly be declared as mutable, and can then be modified
        in much the same way as record fields.

	  <idx>primitive mutable data/record/object fields and ref cells</idx></p>

        <section id="ref-cells" data-type="sect3">
          <h3>Ref cells</h3>

          <p>Variables in OCaml are never mutable—they can refer to
          mutable data, but what the variable points to can't be
          changed. Sometimes, though, you want to do exactly what
          you would do with a mutable variable in another language:
          define a single, mutable value. In OCaml this is
          typically achieved using a <code>ref</code>, which is
          essentially a container with a single mutable polymorphic
          field.

	    <idx>ref cells</idx></p>

          <p>The definition for the <code>ref</code> type is as
          follows:</p>
          <link rel="import" href="code/imperative-programming/ref.mlt" part="1"/>

          <p>The standard library defines the following operators
          for working with <code>ref</code>s.</p>

          <dl>
            <dt><code>ref expr</code></dt>

            <dd>
              <p>Constructs a reference cell containing the value
              defined by the expression <code>expr</code>.</p>
            </dd>

            <dt><code>!refcell</code></dt>

            <dd>
              <p>Returns the contents of the reference cell.</p>
            </dd>

            <dt><code>refcell := expr</code></dt>

            <dd>
              <p>Replaces the contents of the reference cell.</p>
            </dd>
          </dl>

          <p>You can see these in action:</p>
          <link rel="import" href="code/imperative-programming/ref.mlt" part="3"/>

          <p>The preceding are just ordinary OCaml functions, which
          could be defined as follows:</p>
          <link rel="import" href="code/imperative-programming/ref.mlt" part="2"/>
        </section>
      </section>

      <section id="foreign-functions" data-type="sect2">
        <h2>Foreign Functions</h2>

        <p>Another source of imperative operations in OCaml is
        resources that come from interfacing with external
        libraries through OCaml's foreign function interface (FFI).
        The FFI opens OCaml up to imperative constructs that are
        exported by system calls or other external libraries. Many
        of these come built in, like access to the
        <code>write</code> system call or to the
        <code>clock</code>, while others come from user libraries,
        like LAPACK bindings. OCaml's FFI is discussed in more
        detail in <a href="19-foreign-function-interface.html#foreign-function-interface" data-type="xref">Foreign Function
        Interface</a>.

	<idx>libraries/interfacing with external</idx>
	<idx>external libraries/interfacing with</idx>
	<idx>LAPACK bindings</idx>
	<idx>foreign function interface (FFI)/imperative operations and</idx>
	<idx>primitive mutable data/foreign functions</idx></p>
      </section>
    </section>

    <section id="for-and-while-loops-1" data-type="sect1">
      <h1>for and while Loops</h1>

      <p>OCaml provides support for traditional imperative looping
      constructs, in particular, <code>for</code> and
      <code>while</code> loops. Neither of these constructs is
      strictly necessary, since they can be simulated with
      recursive functions. Nonetheless, explicit <code>for</code>
      and <code>while</code> loops are both more concise and more
      idiomatic when programming imperatively.

      <idx>looping constructs</idx>
      <idx>while loops</idx>
      <idx>for loops</idx></p>

      <p>The <code>for</code> loop is the simpler of the two.
      Indeed, we've already seen the <code>for</code> loop in
      action—the <code>iter</code> function in
      <code>Dictionary</code> is built using it. Here's a simple
      example of <code>for</code>:</p>

      <link rel="import" href="code/imperative-programming/for.mlt" part="1"/>

      <p>As you can see, the upper and lower bounds are inclusive.
      We can also use <code>downto</code> to iterate in the other
      direction:</p>
      <link rel="import" href="code/imperative-programming/for.mlt" part="2"/>

      <p>Note that the loop variable of a <code>for</code> loop,
      <code>i</code> in this case, is immutable in the scope of the
      loop and is also local to the loop, i.e., it can't be
      referenced outside of the loop.</p>

      <p>OCaml also supports <code>while</code> loops, which
      include a condition and a body. The loop first evaluates the
      condition, and then, if it evaluates to true, evaluates the
      body and starts the loop again. Here's a simple example of a
      function for reversing an array in place:</p>
      <link rel="import" href="code/imperative-programming/for.mlt" part="3"/>

      <p>In the preceding example, we used <code>incr</code> and
      <code>decr</code>, which are built-in functions for
      incrementing and decrementing an <code>int ref</code> by one,
      respectively.</p>
    </section>

    <section id="example-doubly-linked-lists" data-type="sect1">
      <h1>Example: Doubly Linked Lists</h1>

      <p>Another common imperative data structure is the doubly
      linked list. Doubly linked lists can be traversed in both
      directions, and elements can be added and removed from the
      list in constant time. Core defines a doubly linked list (the
      module is called <code>Doubly_linked</code>), but we'll
      define our own linked list library as an
      illustration.

	<idx>lists/doubly-linked lists</idx>
	<idx>doubly-linked lists</idx>
	<idx id="IPdoublink">imperative programming/doubly-linked lists</idx></p>

      <p>Here's the <code>mli</code> of the module we'll build:</p>
      <link rel="import" href="code/imperative-programming/dlist.mli"/>

      <p>Note that there are two types defined here: <code>'a
      t</code>, the type of a list; and <code>'a element</code>,
      the type of an element. Elements act as pointers to the
      interior of a list and allow us to navigate the list and give
      us a point at which to apply mutating operations.</p>

      <p>Now let's look at the implementation. We'll start by
      defining <code>'a element</code> and <code>'a t</code>:</p>
      <link rel="import" href="code/imperative-programming/dlist.ml" part="1"/>

      <p>An <code>'a element</code> is a record containing the
      value to be stored in that node as well as optional (and
      mutable) fields pointing to the previous and next elements.
      At the beginning of the list, the <code>prev</code> field is
      <code>None</code>, and at the end of the list, the
      <code>next</code> field is <code>None</code>.</p>

      <p>The type of the list itself, <code>'a t</code>, is a
      mutable reference to an optional <code>element</code>. This
      reference is <code>None</code> if the list is empty, and
      <code>Some</code> otherwise.</p>

      <p>Now we can define a few basic functions that operate on
      lists and elements:</p>
      <link rel="import" href="code/imperative-programming/dlist.ml" part="2"/>

      <p>These all follow relatively straightforwardly from our
      type definitions.</p>

      <div data-type="note">
        <h1>Cyclic Data Structures</h1>

        <p>Doubly linked lists are a cyclic data structure, meaning
        that it is possible to follow a nontrivial sequence of
        pointers that closes in on itself. In general, building
        cyclic data structures requires the use of side effects.
        This is done by constructing the data elements first, and
        then adding cycles using assignment afterward.

	  <idx>let rec</idx>
	  <idx>data structures/cyclic</idx>
	  <idx>cyclic data structures</idx></p>

        <p>There is an exception to this, though: you can construct
        fixed-size cyclic data structures using <code>let
        rec</code>:</p>
        <link rel="import" href="code/imperative-programming/examples.mlt" part="2"/>

        <p>This approach is quite limited, however. General-purpose
        cyclic data structures require mutation.</p>
      </div>

      <section id="modifying-the-list" data-type="sect2">
        <h2>Modifying the List</h2>

        <p>Now, we'll start considering operations that mutate the
        list, starting with <code>insert_first</code>, which
        inserts an element at the front of the
        list:

	  <idx>elements/inserting in lists</idx></p>

        <link rel="import" href="code/imperative-programming/dlist.ml" part="3"/>

        <p><code>insert_first</code> first defines a new element
        <code>new_elt</code>, and then links it into the list,
        finally setting the list itself to point to
        <code>new_elt</code>. Note that the precedence of a
        <code>match</code> expression is very low, so to separate
        it from the following assignment (<code>t := Some
        new_elt</code>), we surround the match with <code>begin ...
        end</code>. We could have used parentheses for the same
        purpose. Without some kind of bracketing, the final
        assignment would incorrectly become part of the
        <code>None</code> case.

	<idx>elements/defining new</idx></p>

        <p>We can use <code>insert_after</code> to insert elements
        later in the list. <code>insert_after</code> takes as
        arguments both an <code>element</code> after which to
        insert the new node and a value to insert:</p>
        <link rel="import" href="code/imperative-programming/dlist.ml" part="4"/>

        <p>Finally, we need a <code>remove</code> function:</p>
        <link rel="import" href="code/imperative-programming/dlist.ml" part="5"/>

        <p>Note that the preceding code is careful to change the
        <code>prev</code> pointer of the following element and the
        <code>next</code> pointer of the previous element, if they
        exist. If there's no previous element, then the list
        pointer itself is updated. In any case, the next and
        previous pointers of the element itself are set to
        <code>None</code>.</p>

        <p>These functions are more fragile than they may seem. In
        particular, misuse of the interface may lead to corrupted
        data. For example, double-removing an element will cause
        the main list reference to be set to <code>None</code>,
        thus emptying the list. Similar problems arise from
        removing an element from a list it doesn't belong to.</p>

        <p>This shouldn't be a big surprise. Complex imperative
        data structures can be quite tricky, considerably trickier
        than their pure equivalents. The issues described
        previously can be dealt with by more careful error
        detection, and such error correction is taken care of in
        modules like Core's <code>Doubly_linked</code>. You should
        use imperative data structures from a well-designed library
        when you can. And when you can't, you should make sure to
        put great care into your error handling.

	  <idx>imperative programming/drawbacks of</idx>
	  <idx>Doubly-linked module</idx>
	  <idx>error handling/and imperative data structures</idx></p>
      </section>

      <section id="iteration-functions" data-type="sect2">
        <h2>Iteration Functions</h2>

        <p>When defining containers like lists, dictionaries, and
        trees, you'll typically want to define a set of iteration
        functions like <code>iter</code>, <code>map</code>, and
        <code>fold</code>, which let you concisely express common
        iteration patterns.

	<idx>functions/iteration functions</idx>
	<idx>iteration functions</idx></p>

        <p><code>Dlist</code> has two such iterators:
        <code>iter</code>, the goal of which is to call a
        <code>unit</code>-producing function on every element of
        the list, in order; and <code>find_el</code>, which runs a
        provided test function on each values stored in the list,
        returning the first <code>element</code> that passes the
        test. Both <code>iter</code> and <code>find_el</code> are
        implemented using simple recursive loops that use
        <code>next</code> to walk from element to element and
        <code>value</code> to extract the element from a given
        node:</p>
        <link rel="import" href="code/imperative-programming/dlist.ml" part="6"/>

        <p>This completes our implementation, but there's still
        considerably more work to be done to make a really usable
        doubly linked list. As mentioned earlier, you're probably
        better off using something like Core's
        <code>Doubly_linked</code> module that has a more complete
        interface and has more of the tricky corner cases worked
        out. Nonetheless, this example should serve to demonstrate
        some of the techniques you can use to build nontrivial
        imperative data structure in OCaml, as well as some of the
        pitfalls.<a data-type="indexterm" data-startref="IPdoublink">&nbsp;</a></p>
      </section>
    </section>

    <section id="laziness-and-other-benign-effects" data-type="sect1">
      <h1>Laziness and Other Benign Effects</h1>

      <p>
	There are many instances where you basically want to program
	in a pure style, but you want to make limited use of side
	effects to improve the performance of your code. Such side
	effects are sometimes called <em>benign effects</em>, and they
	are a useful way of leveraging OCaml's imperative features
	while still maintaining most of the benefits of pure
	programming.

	<idx>lazy keyword</idx>
	<idx>side effects</idx>
	<idx>laziness</idx>
	<idx>benign effects/laziness</idx>
	<idx>imperative programming/benign effects and</idx>
      </p>

      <p>
	One of the simplest benign effects is <em>laziness</em>. A
	lazy value is one that is not computed until it is actually
	needed. In OCaml, lazy values are created using
	the <code>lazy</code> keyword, which can be used to convert any
	expression of type <code>s</code> into a lazy value of
	type <code>s Lazy.t</code>. The evaluation of that expression is
	delayed until forced with <code>Lazy.force</code>:</p>

      <link rel="import" href="code/imperative-programming/lazy.mlt" part="1"/>

      <p>You can see from the <code>print</code> statement that the
      actual computation was performed only once, and only
      after <code>force</code> had been called.</p>

      <p>To better understand how laziness works, let's walk through
      the implementation of our own lazy type. We'll start by
      declaring types to represent a lazy value:</p>

      <link rel="import" href="code/imperative-programming/lazy.mlt" part="2"/>

      <p>A <code>lazy_state</code> represents the possible states of a
      lazy value. A lazy value is <code>Delayed</code> before it has
      been run, where <code>Delayed</code> holds a function for
      computing the value in question. A lazy value is in
      the <code>Value</code> state when it has been forced and the
      computation ended normally. The <code>Exn</code> case is for
      when the lazy value has been forced, but the computation ended
      with an exception. A lazy value is simply a <code>ref</code>
      containing a <code>lazy_state</code>, where the <code>ref</code>
      makes it possible to change from being in
      the <code>Delayed</code> state to being in
      the <code>Value</code> or <code>Exn</code> states.</p>

      <p>
	We can create a lazy value from a thunk, i.e., a function that
	takes a unit argument. Wrapping an expression in a thunk is
	another way to suspend the computation of an expression:

	<idx>thunks</idx>
      </p>

      <link rel="import" href="code/imperative-programming/lazy.mlt" part="3"/>

      <p>Now we just need a way to force a lazy value. The
      following function does just that:</p>

      <link rel="import" href="code/imperative-programming/lazy.mlt" part="4"/>

      <p>Which we can use in the same way we used
	<code>Lazy.force</code>:</p>

      <link rel="import" href="code/imperative-programming/lazy.mlt" part="5"/>

      <p>
	The main user-visible difference between our
	implementation of laziness and the built-in version is
	syntax. Rather than writing <code>create_lazy (fun () -&gt;
	  sqrt 16.)</code>, we can (with the built-in
	<code>lazy</code>) just write <code>lazy (sqrt
	16.)</code>.</p>

      <section id="memoization-and-dynamic-programming" data-type="sect2">
        <h2>Memoization and Dynamic Programming</h2>

        <p>
	  Another benign effect is <em>memoization</em>. A memoized
          function remembers the result of previous invocations of the
          function so that they can be returned without further
          computation when the same arguments are presented again.

	  <idx>memoization/of function</idx>
	  <idx id="BEmem">benign effects/memoization</idx>
	</p>

        <p>
	  Here's a function that takes as an argument an arbitrary
          single-argument function and returns a memoized version of
          that function. Here we'll use Core's <code>Hashtbl</code>
          module, rather than our toy <code>Dictionary</code>:</p>

        <link rel="import" href="code/imperative-programming/memo.mlt" part="1"/>

        <p>
	  The preceding code is a bit tricky. <code>memoize</code>
          takes as its argument a function <code>f</code> and then
          allocates a polymorphic hash table
          (called <code>memo_table</code>), and returns a new function
          which is the memoized version of <code>f</code>. When
          called, this new function
          uses <code>Hashtbl.find_or_add</code> to try to find a value
          in the <code>memo_table</code>, and if it fails, to
          call <code>f</code> and store the result. Note
          that <code>memo_table</code> is referred to by the function,
          and so won't be collected until the function returned
          by <code>memoize</code> is itself collected.

	  <idx>memoization/benefits and drawbacks of</idx></p>

        <p>
	  Memoization can be useful whenever you have a function that
          is expensive to recompute and you don't mind caching old
          values indefinitely. One important caution: a memoized
          function by its nature leaks memory. As long as you hold on
          to the memoized function, you're holding every result it has
          returned thus far.</p>

        <p>
	  Memoization is also useful for efficiently implementing some
          recursive algorithms. One good example is the algorithm for
          computing the <em>edit distance</em> (also called the
          Levenshtein distance) between two strings. The edit distance
          is the number of single-character changes (including letter
          switches, insertions, and deletions) required
          to <span class="keep-together">convert</span> one string to
          the other. This kind of distance metric can be useful for a
          variety of approximate string-matching problems, like
          spellcheckers.

	  <idx>string matching</idx>
	  <idx>Levenshtein distance</idx>
	  <idx>edit distance</idx></p>

        <p>
	  Consider the following code for computing the edit
          distance. Understanding the algorithm isn't important here,
          but you should pay attention to the structure of the
          recursive calls:

	  <idx>memoization/example of</idx></p>

        <link rel="import" href="code/imperative-programming/memo.mlt" part="2"/>

        <p>The thing to note is that if you call <code>edit_distance
        "OCaml" "ocaml"</code>, then that will in turn dispatch the
        following calls:</p>

        <figure style="float: 0">
          <img src="images/imperative-programming/edit_distance.png"/>
        </figure>

        <p>And these calls will in turn dispatch other calls:</p>

        <figure style="float: 0">
          <img src="images/imperative-programming/edit_distance2.png"/>
        </figure>

        <p>
	  As you can see, some of these calls are repeats. For
          example, there are two different calls to <code>edit_distance
            "OCam" "oca"</code>. The number of redundant calls grows
          exponentially with the size of the strings, meaning that our
          implementation of <code>edit_distance</code> is brutally
          slow for large strings. We can see this by writing a small
          timing function, using the <code>Mtime</code> package.</p>

        <link rel="import" href="code/imperative-programming/memo.mlt" part="3"/>

        <p>And now we can use this to try out some examples:</p>

        <link rel="import" href="code/imperative-programming/memo.mlt" part="4"/>

        <p>Just those few extra characters made it thousands of
          times slower!</p>

        <p>
	  Memoization would be a huge help here, but to fix the
          problem, we need to memoize the calls
          that <code>edit_distance</code> makes to itself.  Such
          recursive memoization is closely related to a common
          algorithmic technique called <em>dynamic programming</em>,
          except that with dynamic programming, you do the necessary
          sub-computations bottom-up, in anticipation of needing them.
          With recursive memoization, you go top-down, only doing a
          sub-computation when you discover that you need it.

	  <idx>memoization/recursive</idx>
	  <idx>dynamic programming</idx>
	</p>

        <p>
	  To see how to do this, let's step away
          from <code>edit_distance</code> and instead consider a much
          simpler example: computing the <em>n</em>th element of the
          Fibonacci sequence. The Fibonacci sequence by definition
          starts out with two <code>1</code>s, with every subsequent
          element being the sum of the previous two. The classic
          recursive definition of Fibonacci is as follows:
	</p>

	<link rel="import" href="code/imperative-programming/fib.mlt" part="1"/>

        <p>
	  This is, however, exponentially slow, for the same reason
          that <code>edit_distance</code> was slow: we end up making
          many redundant calls to <code>fib</code>. It shows up quite
          dramatically in the performance:</p>

        <link rel="import" href="code/imperative-programming/fib.mlt" part="2"/>

        <p>
	  As you can see, <code>fib 40</code> takes thousands of
          times longer to compute than <code>fib 20</code>.</p>

        <p>
	  So, how can we use memoization to make this faster? The
          tricky bit is that we need to insert the memoization before
          the recursive calls within <code>fib</code>. We can't just
          define <code>fib</code> in the ordinary way and memoize it
          after the fact and expect the first call to
          <code>fib</code> to be improved.</p>

        <link rel="import" href="code/imperative-programming/fib.mlt" part="3"/>

        <p>
	  In order to make <code>fib</code> fast, our first step will
          be to rewrite <code>fib</code> in a way that unwinds the
          recursion. The following version expects as its first
          argument a function (called <code>fib</code>) that will be
          called in lieu of the usual recursive call.</p>

        <link rel="import" href="code/imperative-programming/fib.mlt" part="4"/>

        <p>
	  We can now turn this back into an ordinary Fibonacci
          function by tying the recursive knot:</p>

        <link rel="import" href="code/imperative-programming/fib.mlt" part="5"/>

        <p>
	  We can even write a polymorphic function that we'll call
          <code>make_rec</code> that can tie the recursive knot for
          any function of this form:</p>

        <link rel="import" href="code/imperative-programming/fib.mlt" part="6"/>

        <p>
	  This is a pretty strange piece of code, and it may take
          a few moments of thought to figure out what's going on.
          Like <code>fib_norec</code>, the function
          <code>f_norec</code> passed into <code>make_rec</code> is a
          function that isn't recursive but takes as an argument a
          function that it will call. What <code>make_rec</code> does
          is to essentially feed <code>f_norec</code> to itself, thus
          making it a true recursive function.</p>

        <p>
	  This is clever enough, but all we've really done is find a
          new way to implement the same old slow Fibonacci
          function. To make it faster, we need a variant
          of <code>make_rec</code> that inserts memoization when it
          ties the recursive knot. We'll call that
          function <code>memo_rec</code>:</p>

        <link rel="import" href="code/imperative-programming/fib.mlt" part="7"/>

        <p>
	  Note that <code>memo_rec</code> has the same signature
          as <code>make_rec</code>.</p>

        <p>
	  We're using the reference here as a way of tying the
          recursive knot without using a <code>let rec</code>, which
          for reasons we'll describe later wouldn't work here.</p>

        <p>
	  Using <code>memo_rec</code>, we can now build an
          efficient version of <code>fib</code>:</p>

        <link rel="import" href="code/imperative-programming/fib.mlt" part="8"/>

        <p>
	  And as you can see, the exponential time complexity is now
          gone.</p>

        <p>
	  The memory behavior here is important. If you look back at
          the definition of <code>memo_rec</code>, you'll see that the
          call <code>memo_rec fib_norec</code> does not trigger a call
          to <code>memoize</code>. Only when <code>fib</code> is
          called and thereby the final argument
          to <code>memo_rec</code> is presented
          does <code>memoize</code> get called. The result of that
          call falls out of scope when the <code>fib</code> call
          returns, and so calling <code>memo_rec</code> on a function
          does not create a memory leak—the memoization table is
          collected after the computation completes.</p>

        <p>
	  We can use <code>memo_rec</code> as part of a single
          declaration that makes this look like it's little more than
          a special form of <code>let rec</code>:</p>

        <link rel="import" href="code/imperative-programming/fib.mlt" part="9"/>

        <p>
	  Memoization is overkill for implementing Fibonacci, and
          indeed, the <code>fib</code> defined above is not especially
          efficient, allocating space linear in the number passed in
          to <code>fib</code>. It's easy enough to write a Fibonacci
          function that takes a constant amount of space.</p>

        <p>
	  But memoization is a good approach for
          optimizing <code>edit_distance</code>, and we can apply the
          same approach we used on <code>fib</code> here. We will need
          to change <code>edit_distance</code> to take a pair of
          strings as a single argument, since <code>memo_rec</code>
          only works on single-argument functions. (We can always
          recover the original interface with a wrapper function.)
          With just that change and the addition of
          the <code>memo_rec</code> call, we can get a memoized
          version of <code>edit_distance</code>:</p>

        <link rel="import" href="code/imperative-programming/memo.mlt" part="6"/>

        <p>
	  This new version of <code>edit_distance</code> is much more
          efficient than the one we started with; the following call
          is many thousands of times faster than it was without
          memoization:</p>

        <link rel="import" href="code/imperative-programming/memo.mlt" part="7"/>

        <div class="allow_break" data-type="note">
          <h1>Limitations of let rec</h1>

          <p>
	    You might wonder why we didn't tie the recursive knot
            in <code>memo_rec</code> using <code>let rec</code>, as
            we did for <code>make_rec</code> earlier. Here's code
            that tries to do just that:

	    <idx>let rec</idx></p>

          <link rel="import" href="code/imperative-programming/letrec.mlt" part="1"/>

          <p>
	    OCaml rejects the definition because OCaml, as a
            strict language, has limits on what it can put on the
            righthand side of a <code>let rec</code>. In particular,
            imagine how the following code snippet would be
            compiled:</p>

          <link rel="import" href="code/imperative-programming/let_rec.ml"/>

          <p>
	    Note that <code>x</code> is an ordinary value, not a
            function. As such, it's not clear how this definition
            should be handled by the compiler. You could imagine it
            compiling down to an infinite loop, but <code>x</code> is
            of type <code>int</code>, and there's no <code>int</code>
            that corresponds to an infinite loop. As such, this
            construct is effectively impossible to compile.</p>

          <p>
	    To avoid such impossible cases, the compiler only allows
            three possible constructs to show up on the righthand side
            of a <code>let rec</code>: a function definition, a
            constructor, or the lazy keyword. This excludes some
            reasonable things, like our definition
            of <code>memo_rec</code>, but it also blocks things that
            don't make sense, like our definition
            of <code>x</code>.</p>

          <p>
	    It's worth noting that these restrictions don't show
            up in a lazy language like Haskell. Indeed, we can make
            something like our definition of <code>x</code> work if
            we use OCaml's laziness:</p>

          <link rel="import" href="code/imperative-programming/letrec.mlt" part="2"/>

          <p>
	    Of course, actually trying to compute this will fail.
            OCaml's <code>lazy</code> throws an exception when a lazy
            value tries to force itself as part of its own
            evaluation.</p>

          <link rel="import" href="code/imperative-programming/letrec.mlt" part="3"/>

          <p>
	    But we can also create useful recursive definitions
            with <code>lazy</code>. In particular, we can use laziness
            to make our definition of <code>memo_rec</code> work
            without explicit mutation:</p>

          <link rel="import" href="code/imperative-programming/letrec.mlt" part="5"/>

          <p>
	    Laziness is more constrained than explicit mutation,
            and so in some cases can lead to code whose behavior is
            easier to think about.

	    <a data-type="indexterm" data-startref="BEmem">&nbsp;</a></p>
        </div>
      </section>
    </section>

    <section id="input-and-output" data-type="sect1">
      <h1>Input and Output</h1>

      <p>
	Imperative programming is about more than modifying
	in-memory data structures. Any function that doesn't boil
	down to a deterministic transformation from its arguments to
	its return value is imperative in nature. That includes not
	only things that mutate your program's data, but also
	operations that interact with the world outside of your
	program. An important example of this kind of interaction is
	I/O, i.e., operations for reading or writing data to things
	like files, terminal input and output, and network
	sockets.

	<idx>I/O (input/output) operations/terminal I/O</idx>
	<idx id="IPinpout">imperative programming/input and output</idx>
      </p>

      <p>
	There are multiple I/O libraries in OCaml. In this section
	we'll discuss OCaml's buffered I/O library that can be used
	through the <code>In_channel</code> and
	<code>Out_channel</code> modules in Core. Other I/O
	primitives are also available through the <code>Unix</code>
	module in Core as well as <code>Async</code>, the
	asynchronous I/O library that is covered in
	<a href="18-concurrent-programming.html#concurrent-programming-with-async" data-type="xref">Concurrent Programming With Async</a>.
	Most of the functionality in Core's <code>In_channel</code>
	and <code>Out_channel</code> (and in Core's <code>Unix</code>
	module) derives from the standard library, but we'll use
	Core's interfaces here.</p>

      <section id="terminal-io" data-type="sect2">
        <h2>Terminal I/O</h2>

        <p>
	  OCaml's buffered I/O library is organized around two
          types: <code>in_channel</code>, for channels you read from,
          and <code>out_channel</code>, for channels you write to.
          The <code>In_channel</code> and <code>Out_channel</code>
          modules only have direct support for channels corresponding
          to files and terminals; other kinds of channels can be
          created through the <code>Unix</code> module.

          <idx>Out_channel module/Out_channel.stderr</idx>
          <idx>Out_channel module/Out_channel.stdout</idx>
          <idx>In_channel module</idx>
	</p>

        <p>
	  We'll start our discussion of I/O by focusing on the
          terminal. Following the UNIX model, communication with the
          terminal is organized around three channels, which
          correspond to the three standard file descriptors in
          Unix:</p>

        <dl>
          <dt><code>In_channel.stdin</code></dt>

          <dd><p>
	      The "standard input" channel. By default, input
              comes from the terminal, which handles keyboard
              input.</p>
          </dd>

          <dt><code>Out_channel.stdout</code></dt>

          <dd><p>
	      The "standard output" channel. By default, output
              written to <code>stdout</code> appears on the user
              terminal.</p>
          </dd>

          <dt><code>Out_channel.stderr</code></dt>

          <dd>
            <p>The "standard error" channel. This is similar to
            <code>stdout</code> but is intended for error
            messages.</p>
          </dd>
        </dl>

        <p>
	  The values <code>stdin</code>, <code>stdout</code>,
          and <code>stderr</code> are useful enough that they are also
          available in the global namespace directly, without having
          to go through the <code>In_channel</code>
          and <code>Out_channel</code> modules.</p>

        <p>
	  Let's see this in action in a simple interactive
          application. The following
          program, <code>time_converter</code>, prompts the user for a
          time zone, and then prints out the current time in that time
          zone. Here, we use Core's <code>Zone</code> module for
          looking up a time zone, and the <code>Time</code> module for
          computing the current time and printing it out in the time
          zone in question:</p>

        <link rel="import" href="code/imperative-programming/time_converter/time_converter.ml"/>

        <p>
	  We can build this program
	  using <span class="command"><em>jbuilder</em></span> and
	  run it. You'll see that it prompts you for input, as
	  follows:</p>

        <link rel="import" href="code/imperative-programming/time_converter/time_converter.rawsh"/>

        <p>
	  You can then type in the name of a time zone and hit
          Return, and it will print out the current time in the time
          zone in question:</p>

        <link rel="import" href="code/imperative-programming/time_converter2.rawsh"/>

        <p>We called <code>Out_channel.flush</code> on
        <code>stdout</code> because <code>out_channel</code>s are
        buffered, which is to say that OCaml doesn't immediately do
        a write every time you call <code>output_string</code>.
        Instead, writes are buffered until either enough has been
        written to trigger the flushing of the buffers, or until a
        flush is explicitly requested. This greatly increases the
        efficiency of the writing process by reducing the number of
        system calls.</p>

        <p>Note that <code>In_channel.input_line</code> returns a
        <code>string option</code>, with <code>None</code>
        indicating that the input stream has ended (i.e., an
        end-of-file condition).
        <code>Out_channel.output_string</code> is used to print the
        final output, and <code>Out_channel.flush</code> is called
        to flush that output to the screen. The final flush is not
        technically required, since the program ends after that
        instruction, at which point all remaining output will be
        flushed anyway, but the explicit flush is nonetheless good
        practice.</p>
      </section>

      <section id="formatted-output-with-printf" data-type="sect2">
        <h2>Formatted Output with printf</h2>

        <p>Generating output with functions like
        <code>Out_channel.output_string</code> is simple and easy
        to understand, but can be a bit verbose. OCaml also
        supports formatted output using the <code>printf</code>
        function, which is modeled after <code>printf</code> in the
        C standard library. <code>printf</code> takes a <em>format
        string</em> that describes what to print and how to format
        it, as well as arguments to be printed, as determined by
        the formatting directives embedded in the format string.
        So, for example, we can write:

	<idx>strings/format strings</idx>
	<idx>format strings</idx>
	<idx>printf function</idx>
	<idx>I/O (input/output) operations/formatted output</idx></p>

        <link rel="import" href="code/imperative-programming/printf.mlt" part="1"/>

        <p>Unlike C's <code>printf</code>, the <code>printf</code>
        in OCaml is type-safe. In particular, if we provide an
        argument whose type doesn't match what's presented in the
        format string, we'll get a type error:</p>
        <link rel="import" href="code/imperative-programming/printf.mlt" part="2"/>

        <aside data-type="sidebar">
          <h5>Understanding Format Strings</h5>

          <p>The format strings used by <code>printf</code> turn
          out to be quite different from ordinary strings. This
          difference ties to the fact that OCaml format strings,
          unlike their equivalent in C, are type-safe. In
          particular, the compiler checks that the types referred
          to by the format string match the types of the rest of
          the arguments passed to <code>printf</code>.</p>

          <p>To check this, OCaml needs to analyze the contents of
          the format string at compile time, which means the format
          string needs to be available as a string literal at
          compile time. Indeed, if you try to pass an ordinary
          string to <code>printf</code>, the compiler will
          complain:</p>

          <link rel="import" href="code/imperative-programming/printf.mlt" part="3"/>

          <p>
	    If OCaml infers that a given string literal is a format
            string, then it parses it at compile time as such,
            choosing its type in accordance with the formatting
            directives it finds. Thus, if we add a type annotation
            indicating that the string we're defining is actually a
            format string, it will be interpreted as such.  (Here, we
            open the CamlinternalFormatBasics so that the
            representation of the format string that's printed out
            won't fill the whole page.)</p>

          <link rel="import" href="code/imperative-programming/printf.mlt" part="4"/>

          <p>
	    And accordingly, we can pass it to
            <code>printf</code>:</p>

          <link rel="import" href="code/imperative-programming/printf.mlt" part="5"/>

          <p>
	    If this looks different from everything else you've seen
            so far, that's because it is. This is really a special
            case in the type system.  Most of the time, you don't need
            to know about this special handling of format strings—you
            can just use <code>printf</code> and not worry about the
            details. But it's useful to keep the broad outlines of the
            story in the back of your head.</p>
        </aside>

        <p>
	  Now let's see how we can rewrite our time conversion
          program to be a little more concise using
          <code>printf</code>:</p>

        <link rel="import" href="code/imperative-programming/time_converter2.ml"/>

        <p>
	  In the preceding example, we've used only two formatting
          directives: <code>%s</code>, for including a string,
          and <code>%!</code> which causes <code>printf</code> to
          flush the channel.</p>

        <p>
	  <code>printf</code>'s formatting directives offer a
          significant amount of control, allowing you to specify
          things like:

	  <idx>binary numbers, formatting with printf</idx>
	  <idx>hex numbers, formatting with printf</idx>
	  <idx>decimals, formatting with printf</idx>
	  <idx>alignment, formatting with printf</idx></p>

        <ul>
          <li> <p>Alignment and padding</p> </li>

          <li> <p>Escaping rules for strings</p> </li>

          <li> <p>Whether numbers should be formatted in decimal, hex,
            or binary</p> </li>

          <li> <p>Precision of float conversions</p> </li>
        </ul>

        <p>There are also <code>printf</code>-style functions that
        target outputs other than <code>stdout</code>,
        including:

	  <idx>sprintf function</idx>
	  <idx>fprintf function</idx>
	  <idx>eprintf function</idx></p>

        <ul>
          <li>
            <p><code>eprintf</code>, which prints to
            <code>stderr</code></p>
          </li>

          <li>
            <p><code>fprintf</code>, which prints to an arbitrary
            <code>out_channel</code></p>
          </li>

          <li>
            <p><code>sprintf</code>, which returns a formatted
            string</p>
          </li>
        </ul>

        <p>All of this, and a good deal more, is described in the
        API documentation for the <code>Printf</code> module in the
        OCaml Manual.</p>
      </section>

      <section id="file-io" data-type="sect2">
        <h2>File I/O</h2>

        <p>Another common use of <code>in_channel</code>s and
        <code>out_channel</code>s is for working with files. Here
        are a couple of functions—one that creates a file full of
        numbers, and the other that reads in such a file and
        returns the sum of those numbers:

	<idx>files/file I/O</idx>
	<idx>I/O (input/output) operations/file I/O</idx></p>

        <link rel="import" href="code/imperative-programming/file.mlt" part="1"/>

        <p>For both of these functions, we followed the same basic
        sequence: we first create the channel, then use the
        channel, and finally close the channel. The closing of the
        channel is important, since without it, we won't release
        resources associated with the file back to the operating
        system.</p>

        <p>One problem with the preceding code is that if it throws
        an exception in the middle of its work, it won't actually
        close the file. If we try to read a file that doesn't
        actually contain numbers, we'll see such an error:</p>
        <link rel="import" href="code/imperative-programming/file.mlt" part="2"/>

        <p>And if we do this over and over in a loop, we'll
        eventually run out of file descriptors:</p>

        <link rel="import" href="code/imperative-programming/file.mlt" part="3"/>

        <p>And now, you'll need to restart your toplevel if you
        want to open any more files!</p>

        <p>To avoid this, we need to make sure that our code cleans
        up after itself. We can do this using the
        <code>protect</code> function described in <a href="07-error-handling.html#error-handling" data-type="xref">Error Handling</a>, as follows:</p>
        <link rel="import" href="code/imperative-programming/file2.mlt" part="1"/>

        <p>And now, the file descriptor leak is gone:</p>

        <link rel="import" href="code/imperative-programming/file2.mlt" part="2"/>

        <p>
	  This is really an example of a more general issue with
          imperative programming and exceptions. If you're changing the
          internal state of your program and you're interrupted by an
          exception, you need to consider quite carefully if it's
          safe to continue working from your current state.</p>

        <p>
	  <code>In_channel</code> has functions that automate the
          handling of some of these details. For
          example, <code>In_channel.with_file</code> takes a filename
          and a function for processing data from
          an <code>in_channel</code> and takes care of the bookkeeping
          associated with opening and closing the file. We can
          rewrite <code>sum_file</code> using this function, as shown
          here:</p>

        <link rel="import" href="code/imperative-programming/file2.mlt" part="3"/>

        <p>Another misfeature of our implementation of
        <code>sum_file</code> is that we read the entire file into
        memory before processing it. For a large file, it's more
        efficient to process a line at a time. You can use the
        <code>In_channel.fold_lines</code> function to do just
        that:</p>
        <link rel="import" href="code/imperative-programming/file2.mlt" part="4"/>

        <p>This is just a taste of the functionality of
        <code>In_channel</code> and <code>Out_channel</code>. To
        get a fuller understanding, you should review the API
        documentation for those modules.<a data-type="indexterm" data-startref="IPinpout">&nbsp;</a></p>
      </section>
    </section>

    <section id="order-of-evaluation" data-type="sect1">
      <h1>Order of Evaluation</h1>

      <p>
	The order in which expressions are evaluated is an important
	part of the definition of a programming language, and it is
	particularly important when programming imperatively. Most
	programming languages you're likely to have encountered
	are <em>strict</em>, and OCaml is too. In a strict language,
	when you bind an identifier to the result of some expression,
	the expression is evaluated before the variable is
	bound. Similarly, if you call a function on a set of arguments,
	those arguments are evaluated before they are passed to the
	function.

	<idx>strict evaluation</idx>
	<idx>expressions, order of evaluation</idx>
	<idx>evaluation, order of</idx>
	<idx>order of evaluation</idx>
	<idx>imperative programming/order of evaluation</idx></p>

      <p>
	Consider the following simple example. Here, we have a
	collection of angles, and we want to determine if any of them
	have a negative <code>sin</code>. The following snippet of
	code would answer that question:</p>

      <link rel="import" href="code/imperative-programming/order.mlt" part="1"/>

      <p>
	In some sense, we don't really need to compute the <code>sin
	128.</code> because <code>sin 75.</code> is negative, so we
	could know the answer before even computing <code>sin
	128.</code>.</p>

      <p>
	It doesn't have to be this way. Using the <code>lazy</code>
	keyword, we can write the original computation so
	that <code>sin 128.</code> won't ever be computed:</p>

      <link rel="import" href="code/imperative-programming/order.mlt" part="2"/>

      <p>We can confirm that fact by a few well-placed
      <code>printf</code>s:</p>

      <link rel="import" href="code/imperative-programming/order.mlt" part="3"/>

      <p>
	OCaml is strict by default for a good reason: lazy evaluation
	and imperative programming generally don't mix well because
	laziness makes it harder to reason about when a given side
	effect is going to occur. Understanding the order of side
	effects is essential to reasoning about the behavior of an
	imperative program.</p>

      <p>
	Because OCaml is strict, we know that expressions that are
	bound by a sequence of <code>let</code> bindings will be
	evaluated in the order that they're defined. But what about
	the evaluation order within a single expression? Officially,
	the answer is that evaluation order within an expression is
	undefined. In practice, OCaml has only one compiler, and that
	behavior is a kind of <em>de facto</em> standard. Unfortunately, the
	evaluation order in this case is often the opposite of what
	one might expect.</p>

      <p>Consider the following example:</p>

      <link rel="import" href="code/imperative-programming/order.mlt" part="4"/>

      <p>
	Here, you can see that the subexpression that came last was
	actually evaluated first! This is generally the case for many
	different kinds of expressions. If you want to make sure of
	the evaluation order of different subexpressions, you should
	express them as a series of <code>let</code> bindings.</p>
    </section>

    <section id="side-effects-and-weak-polymorphism" data-type="sect1">
      <h1>Side Effects and Weak Polymorphism</h1>

      <p>Consider the following simple, imperative function:

	<idx>polymorphism/weak polymorphism</idx>
	<idx>weak polymorphism</idx>
	<idx>side effects</idx>
	<idx id="IPsideweak">
	  imperative programming/side effects/weak polymorphism
	</idx>
      </p>

      <link rel="import" href="code/imperative-programming/weak.mlt" part="1"/>

      <p><code>remember</code> simply caches the first value that's
      passed to it, returning that value on every call. That's
      because <code>cache</code> is created and initialized once
      and is shared across invocations of
      <code>remember</code>.</p>

      <p><code>remember</code> is not a terribly useful function,
      but it raises an interesting question: what is its type?</p>

      <p>On its first call, <code>remember</code> returns the same
      value it's passed, which means its input type and return type
      should match. Accordingly, <code>remember</code> should have
      type <code>t -&gt; t</code> for some type <code>t</code>.
      There's nothing about <code>remember</code> that ties the
      choice of <code>t</code> to any particular type, so you might
      expect OCaml to generalize, replacing <code>t</code> with a
      polymorphic type variable. It's this kind of generalization
      that gives us polymorphic types in the first place. The
      identity function, as an example, gets a polymorphic type in
      this way:</p>

      <link rel="import" href="code/imperative-programming/weak.mlt" part="2"/>

      <p>
	As you can see, the polymorphic type of <code>identity</code>
	lets it operate on values with different types.</p>

      <p>
	This is not what happens with <code>remember</code>, though.
	As you can see from the above examples, the type that OCaml
	infers for <code>remember</code> looks almost, but not quite,
	like the type of the identity function. Here it is again:</p>

      <link rel="import" href="code/imperative-programming/remember_type.ml"/>

      <p>The underscore in the type variable <code>'_a</code> tells
      us that the variable is only <em>weakly polymorphic</em>,
      which is to say that it can be used with any <em>single</em>
      type. That makes sense because, unlike <code>identity</code>,
      <code>remember</code> always returns the value it was passed
      on its first invocation, which means its return value must
      always have the same type.

      <idx>type variables</idx></p>

      <p>OCaml will convert a weakly polymorphic variable to a
      concrete type as soon as it gets a clue as to what concrete
      type it is to be used as:</p>

      <link rel="import" href="code/imperative-programming/weak.mlt" part="3"/>

      <p>Note that the type of <code>remember</code> was settled by
      the definition of <code>remember_three</code>, even though
      <code>remember_three</code> was never called!</p>

      <section id="the-value-restriction" data-type="sect2">
        <h2>The Value Restriction</h2>

        <p>
	  So, when does the compiler infer weakly polymorphic types?
          As we've seen, we need weakly polymorphic types when a value
          of unknown type is stored in a persistent mutable
          cell. Because the type system isn't precise enough to
          determine all cases where this might happen, OCaml uses a
          rough rule to flag cases that don't introduce any persistent
          mutable cells, and to only infer polymorphic types in those
          cases. This rule is called <em>the value restriction</em>.

	  <idx>value restriction</idx></p>

        <p>
	  The core of the value restriction is the observation that
          some kinds of expressions, which we'll refer to
          as <em>simple values</em>, by their nature can't introduce
          persistent mutable cells, including:</p>

        <ul>
          <li>
            <p>Constants (i.e., things like integer and
            floating-point literals)</p>
          </li>

          <li>
            <p>Constructors that only contain other simple
            values</p>
          </li>

          <li>
            <p>Function declarations, i.e., expressions that begin
            with <code>fun</code> or <code>function</code>, or the
            equivalent let binding, <code>let f x = ...</code></p>
          </li>

          <li>
            <p><code>let</code> bindings of the form
            <code>let</code> <em><code>var</code></em>
            <code>=</code> <em><code>expr1</code></em>
            <code>in</code> <em><code>expr2</code></em>, where both
            <em><code>expr1</code></em> and
            <em><code>expr2</code></em> are simple values</p>
          </li>
        </ul>

        <p>Thus, the following expression is a simple value, and as
        a result, the types of values contained within it are
        allowed to be polymorphic:</p>
        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="1"/>

        <p>But, if we write down an expression that isn't a simple
        value by the preceding definition, we'll get different
        results. For example, consider what happens if we try to
        memoize the function defined previously.</p>

        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="2"/>

        <p>
	  The memoized version of the function does in fact need to be
          restricted to a single type because it uses mutable state
          behind the scenes to cache values returned by previous
          invocations of the function. But OCaml would make the same
          determination even if the function in question did no such
          thing. Consider this example:</p>

        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="3"/>

        <p>It would be safe to infer a fully polymorphic variable
        here, but because OCaml's type system doesn't distinguish
        between pure and impure functions, it can't separate those
        two cases.</p>

        <p>The value restriction doesn't require that there is no
        mutable state, only that there is no <em>persistent</em>
        mutable state that could share values between uses of the
        same function. Thus, a function that produces a fresh
        reference every time it's called can have a fully
        polymorphic type:</p>
        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="4"/>

        <p>But a function that has a mutable cache that persists
        across calls, like <code>memoize</code>, can only be weakly
        polymorphic.</p>
      </section>

      <section id="partial-application-and-the-value-restriction" data-type="sect2">
        <h2>Partial Application and the Value Restriction</h2>

        <p>Most of the time, when the value restriction kicks in,
        it's for a good reason, i.e., it's because the value in
        question can actually only safely be used with a single
        type. But sometimes, the value restriction kicks in when
        you don't want it. The most common such case is partially
        applied functions. A partially applied function, like any
        function application, is not a simple value, and as such,
        functions created by partial application are sometimes less
        general than you might expect.

	  <idx>partial application</idx></p>

        <p>Consider the <code>List.init</code> function, which is
        used for creating lists where each element is created by
        calling a function on the index of that element:</p>
        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="5"/>

        <p>Imagine we wanted to create a specialized version of
        <code>List.init</code> that always created lists of length
        10. We could do that using partial application, as
        follows:</p>
        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="6"/>

        <p>As you can see, we now infer a weakly polymorphic type
        for the resulting function. That's because there's nothing
        that guarantees that <code>List.init</code> isn't creating
        a persistent <code>ref</code> somewhere inside of it that
        would be shared across multiple calls to
        <code>list_init_10</code>. We can eliminate this
        possibility, and at the same time get the compiler to infer
        a polymorphic type, by avoiding partial application:</p>
        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="7"/>

        <p>This transformation is referred to as <em>eta
        expansion</em> and is often useful to resolve problems that
        arise from the value restriction.</p>
      </section>

      <section id="relaxing-the-value-restriction" data-type="sect2">
        <h2>Relaxing the Value Restriction</h2>

        <p>OCaml is actually a little better at inferring
        polymorphic types than was suggested previously. The value
        restriction as we described it is basically a syntactic
        check: you can do a few operations that count as simple
        values, and anything that's a simple value can be
        generalized.</p>

        <p>But OCaml actually has a relaxed version of the value
        restriction that can make use of type information to allow
        polymorphic types for things that are not simple
        values.</p>

        <p>For example, we saw that a function application, even a
        simple application of the identity function, is not a
        simple value and thus can turn a polymorphic value into a
        weakly polymorphic one:</p>

        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="8"/>

        <p>But that's not always the case. When the type of the
        returned value is immutable, then OCaml can typically infer
        a fully polymorphic type:</p>

        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="9"/>

        <p>On the other hand, if the returned type is mutable, then
        the result will be weakly polymorphic:</p>

	<link rel="import" href="code/imperative-programming/value_restriction.mlt" part="10"/>

        <p>
	  A more important example of this comes up when defining
          abstract data types. Consider the following simple data
          structure for an immutable list type that supports
          constant-time concatenation:</p>

        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="11"/>

        <p>The details of the implementation don't matter so much, but
        it's important to note that a <code>Concat_list.t</code> is
        unquestionably an immutable value. However, when it comes to
        the value restriction, OCaml treats it as if it were
        mutable:</p>

        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="12"/>

        <p>
	  The issue here is that the signature, by virtue of being
          abstract, has obscured the fact that
          <code>Concat_list.t</code> is in fact an immutable data
          type. We can resolve this in one of two ways: either by
          making the type concrete (i.e., exposing the implementation
          in the <code>mli</code>), which is often not desirable; or
          by marking the type variable in question as
          <em>covariant</em>. We'll learn more about covariance and
          contravariance in <a href="11-objects.html#objects" data-type="xref">Objects</a>, but for now, you can think of
          it as an annotation that can be put in the interface of a
          pure data structure.

	  <idx>datatypes/covariant</idx></p>

        <p>
	  In particular, if we replace <code>type 'a t</code> in
          the interface with <code>type +'a t</code>, that will make
          it explicit in the interface that the data structure
          doesn't contain any persistent references to values of type
          <code>'a</code>, at which point, OCaml can infer
          polymorphic types for expressions of this type that are not
          simple values:</p>

        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="13"/>

        <p>Now, we can apply the identity function to
        <code>Concat_list.empty</code> without without losing any
        polymorphism:</p>

        <link rel="import" href="code/imperative-programming/value_restriction.mlt" part="14"/>
      </section>
    </section>

    <section id="summary" data-type="sect1">
      <h1>Summary</h1>

      <p>This chapter has covered quite a lot of ground,
      including:

	<idx>imperative programming/overview of</idx></p>

      <ul>
        <li>
          <p>Discussing the building blocks of mutable data
          structures as well as the basic imperative constructs
          like <code>for</code> loops, <code>while</code> loops,
          and the sequencing operator <code>;</code></p>
        </li>

        <li>
          <p>Walking through the implementation of a couple of
          classic imperative data structures</p>
        </li>

        <li>
          <p>Discussing so-called benign effects like memoization
          and laziness</p>
        </li>

        <li>
          <p>Covering OCaml's API for blocking I/O</p>
        </li>

        <li>
          <p>Discussing how language-level issues like order of
          evaluation and weak polymorphism interact with OCaml's
          imperative features</p>
        </li>
      </ul>

      <p>The scope and sophistication of the material here is an
      indication of the importance of OCaml's imperative features.
      The fact that OCaml defaults to immutability shouldn't
      obscure the fact that imperative programming is a fundamental
      part of building any serious application, and that if you
      want to be an effective OCaml programmer, you need to
      understand OCaml's approach to imperative
      programming.<a data-type="indexterm" data-startref="PROGimper">&nbsp;</a></p>
    </section>
  </section>
</body>
</html>
