File "spike.mly", line 583, characters 7-14:
Warning: the token TOK_AND is unused.
File "spike.mly", line 619, characters 7-17:
Warning: the token TOK_CRITIC is unused.
File "spike.mly", line 635, characters 7-20:
Warning: the token TOK_REDUCTION is unused.
File "spike.mly", line 678, characters 16-26:
Warning: the token TOK_STRING is unused.
%{

open Values
open Context
open Critical_context_set
open Diverse
open Io
open Dicos
open Symbols
open Terms
open Terms_parser
open Order
open Literals
open Clauses
open Dummies
open Strategies
open Test_sets
open Shell
open Extract

let introduce_var_exist c =
  let rec fn_term lv t =
    match t#content with
	Var_exist _ -> t
      | Var_univ (i, s) -> if List.mem (i, s, true) lv then t else new term (Var_exist (i, s))
      | Term (i, l, s) -> new term (Term (i, List.map (fn_term lv) l, s))
  in
  let fn_lit lv lit =
    match lit#content with
	Lit_rule (t1, t2) -> new literal (Lit_rule ((fn_term lv t1), (fn_term lv t2)))
      | Lit_equal (t1, t2) -> new literal (Lit_equal ((fn_term lv t1), (fn_term lv t2)))
      |	Lit_diff (t1, t2) -> new literal (Lit_diff ((fn_term lv t1), (fn_term lv t2)))
  in
  let (x, y, c') = c in
  let (n, p) = c'#content in
  let var_lhs = (c'#lefthand_side)#variables in
  let n' = List.map (fn_lit var_lhs) n in
  let p' = List.map (fn_lit var_lhs) p in
  let new_c' = new clause (n', p') [] ("",0,([],[])) in
  (x, y, new_c')

(* If no ordering is specified in the specification file, we use a total ordering based on symbol codes *)
let default_fill_order_dico () =
  let fn c =
    let ldef_symb = all_nonvariable_symbols c in
    let lhs,rhs = c#both_sides in
    let lhs_head_symbol =
      try
	(match lhs#content with
	    Term (f, _, _) -> f
	  | Var_exist _| Var_univ _ -> failwith "default_fill_order_dico"
	)
      with Not_Horn -> failwith "default_fill_order_dico"
    in
    let r_cond_symb = try
      remove_el ( = ) lhs_head_symbol ldef_symb
    with Failure "remove_el" -> failwith "default_fill_order_dico"
    in
    let () = if !debug_mode then
      let () = buffered_output c#string in
      let () = print_string "\n" in
      let () = print_int lhs_head_symbol in
      let () = print_string "\n" in
      let () = print_list ", " print_int r_cond_symb in
      let () = print_string "\n" in
      let () = flush stdout in
	()
    in

    let is_orientable =
      try
	let rhs_head_symbol =
	  try
	    (match rhs#content with
		 Term (f, _, _) -> f
	       | Var_exist _| Var_univ _ -> failwith "variable"
	    )
	  with Not_Horn -> failwith "default_fill_order_dico"
	in
	  not (List.mem lhs_head_symbol (try dico_order#find rhs_head_symbol with Not_found -> []))
      with Failure "variable" -> true
    in
      if is_orientable then
	List.iter (dico_order#add_couple lhs_head_symbol) r_cond_symb
  in
  let () = buffered_output "Setting default greater order for symbols" in
  let () = flush stdout in
  let axioms = List.map (fun (_, _, x) -> x) !yy_axioms in
  let () = if !debug_mode then
    let () = print_string "\n Current axioms :" in
    let () = print_clause_list axioms in
    let () = print_dico_const_string () in
      ()
  in
  let _ = List.iter fn axioms in
  let () =
    try
      dico_order#merge_equivalence_relation dico_equivalence ;
    with (Failure "rehash") ->
      parse_failwith "there are incompatibilities between the order and equivalence relations"
  in
  if !debug_mode then
    let () = print_dico_order () in
    let () = print_dico_equivalence () in
    ()

let share_variables s s' =
  let rec fn s =
    match s with
	Def_sort _ -> []
      | Abstr_sort0 str -> [str]
      | Abstr_sort1 (_, sort) -> fn sort
      | Abstr_sort2 (_, s1, s2) -> (fn s1) @ (fn s2)
  in
  let lvar_s = fn s in
  let lvar_s' = fn s' in
  List.exists (fun x -> List.mem x lvar_s) lvar_s'


  (* to be continued  *)



(* Parse a positive integer *)
let parse_positive_int s =
  let i =
    try int_of_string s
    with (Failure "int_of_string") -> parse_failwith "not a positive integer"
  in if i < 0
  then parse_failwith "not a positive integer"
  else i

(* Get sort id from string *)
let find_sort_id s =
  try dico_sort_string#find_key s
  with Failure "find_key" ->
    if not (* !specif_paramete
rized  *) true
    then parse_failwith ("unknown sort \"" ^ s ^ "\"")
    else
      let () = if !debug_mode then print_string ("\nWARNING: the sort " ^ s ^ " is parameterized") in
      Abstr_sort0 s


(* Get symbol id from string *)
let find_symbol_id s =
  try dico_const_string#find_key s
  with Failure "find_key" -> parse_failwith ("undefined symbol \"" ^ s ^ "\"")

  (* Provided an integer reference i, a value, and a (int, _) dictionary, we add the couple
     (i, v) if v is not already t here and increment i (decrement if negative), do nothing otherwise.
     Returns key *)
let selective_add d i v =
  try d#find_key v with
    Failure "find_key" -> let n = !i in d#add n v; if n >= 0 then incr i else decr i; n
;;

let selective_add_sort d i v =
  try d#find_key v with
    Failure "find_key" -> let n = !i in d#add (Def_sort n) v; if n >= 0 then incr i else decr i; Def_sort n
;;


  (* tests if there is a parameterized sort in the clause content c  *)
let test_well_founded_cl c =
  let fn_sort s =
    match s with
	Def_sort _ -> true
      | Abstr_sort0 _| Abstr_sort1 _ | Abstr_sort2 _ -> let () = buffered_output ("\nThe sort " ^ (sprint_sort s) ^ " is parameterized") in false
  in
  let fn_term t =
    match t#content with
	Var_exist (_, s) | Var_univ (_, s) -> fn_sort s
      | Term (_, _, s) -> fn_sort s
  in
  let fn_lit l =
    match l#content with
	Lit_rule (t1, t2) -> (fn_term t1) && (fn_term t2)
      | Lit_equal (t1, t2) -> (fn_term t1) && (fn_term t2)
      | Lit_diff (t1, t2) -> (fn_term t1) && (fn_term t2)
  in
  let (negs, poss) = c in
  List.fold_right (fun x y -> fn_lit x && y) (negs @ poss) true

(*
   * Given:
   * - a counter (either variables or constants)
   * - a string
   * - a list of sorts (might be empty)
   * - a sort
   * updates the dictionaries to create a symbol with the given profile
*)
let process_specif_symbol counter s (l, rs) =
  let sym, l_ar, r_ar = process_underscores s
  in begin
    try
      let _ = dico_const_string#find_key sym
      in parse_failwith ("symbol \"" ^ sym ^ "\" already defined")
    with Failure "find_key" -> ()
  end ;
  if (l_ar + r_ar) <> List.length l
  then parse_failwith ("mismatch between declared arities and profile")
  else () ;
  let v = selective_add dico_const_string counter sym in
  let new_profile = update_profile (rs::l) in
  let sort_v = List.hd new_profile in
  dico_const_profile#add v new_profile ;
  dico_const_sort#add v sort_v ;
  dico_arities#add v (l_ar, r_ar)

let process_function_props list_symb prop =
  let fn id =
      try
	let sym = dico_const_string#find_key id in
    	let l_ar, r_ar = dico_arities#find sym in
    	if ((l_ar = 0 && r_ar = 2) || (l_ar = 1 && r_ar = 1))
    	then dico_properties#add sym prop
    	else parse_failwith ("symbol \"" ^ id ^ "\" has a profile incompatible with its " ^
    	(match prop with Prop_ac -> "AC" | Prop_assoc -> "ASSOC" | Prop_peano -> "") ^ " properties")
      with Failure "find_key" -> parse_failwith ("symbol \"" ^ id ^ "\" is not defined")
	| Not_found -> failwith "raising Not_found in process_function_props"
  in
  let () =  assert (  prop =  Prop_ac or prop = Prop_assoc) in
  let _ = List.map fn list_symb in
  ()



(* Given a string and a status, update the status dictionary accordingly *)
let add_to_status_dico c st =
  try
    let old_st = dico_id_status#find c
    in if old_st = st
    then ()
    else parse_failwith ("attempt to define different statuses to symbol \""
                         ^ (dico_const_string#find c)
                         ^ "\"")
  with Not_found -> dico_id_status#add c st




(* In the case where an explicit type is given to a variable, check that it is compatible with the remaining equation *)
let check_explicit_type v s =
  (* Checks that it is not a functional symbol *)
  let () =
    try
      let _ = dico_const_string#find_key v
      in parse_failwith ("attempting to redefine sort of functional symbol " ^ v)
    with Failure "find_key" -> ()
  and id = code_of_var v
  and sort_id = find_sort_id s in
  try
    let sort_id2 = List.assoc id !yy_tmp_sorts in
    if sort_id <> sort_id2
    then parse_failwith ("conflicting sorts "
                         ^ s
                         ^ " (declared) and "
                         ^ (dico_sort_string#find sort_id2)
                         ^ " (infered) for symbol "
                         ^ v)
    else ()
  with Not_found ->
    yy_tmp_sorts := generic_insert_sorted (id, sort_id) !yy_tmp_sorts

(*
   * The core function: add a new incomplete tree at the first undefined node in "yy_incomplete_tree".
   * This new tree can be either a Variable node, or a new node with at the root the id of the given symbol,
   * and as arguments, as many trees as the left arity picked from the stack yy_terms_stack, and as many
   * Undefined nodes as the right arity
   * If no place can be found (the tree is complete), the whole tree is pushed into the stack, and yy_incomplete_tree
   * becomes the produced tree
   * When the whole term has been parsed, we should have an empty stack and a complete tree
*)
let add_to_incomplete_tree tk =
  let fn1 tk =
    let () = if !debug_mode then (print_string "\n incomplete tree >>>>>  "; print_term_token tk) else () in
    match tk with
	TT_ident s ->
          begin
            try
	      let id = dico_const_string#find_key s in
	      let l_ar, r_ar = dico_arities#find id in
	(* let () = buffered_output ("Popping " ^ (string_of_int l_ar) ^ " elements from stack") ; flush stdout in *)
	      let l_args = pop_n_times l_ar yy_terms_stack in
	      let r_args = list_init r_ar (Undefined: incomplete_tree pointer)
	      in
	      Defined (Iterm (id, l_args @ r_args))
            with Failure "find_key"
	      | Not_found -> let id = code_of_var s in Defined (Ivar id)
          end
      | TT_tree t -> Defined t
  in
  let rec fn h t tk =
    match h with
      Undefined -> (fn1 tk) :: t
    | Defined (Ivar _) -> h :: (fn2 tk t)
    | Defined (Iterm (s', l)) ->
        try
          let l' = fn2 tk l in
          (Defined (Iterm (s', l'))) :: t
        with Failure "fn2" ->
          h :: (fn2 tk t)
  and fn2 tk = function
      [] -> failwith "fn2"
    | h :: t -> fn h t tk
  in
  if incomplete_tree_is_complete !yy_incomplete_tree
  then
    begin
      if !debug_mode then
	buffered_output ("Pushing " ^ (sprint_incomplete_tree_pointer !yy_incomplete_tree) ^ " into stack")
      else () ;
      Stack.push !yy_incomplete_tree yy_terms_stack ;
      yy_incomplete_tree := fn1 tk
    end
  else
    yy_incomplete_tree := List.hd (fn !yy_incomplete_tree [] tk)


let sprint_bool flag = match flag with true -> "True" | false -> "False"

(* We now process a list of identifiers (tokens) *)
let process_term_tokens =
  let rec fn = function
      [] ->
	let empty_stack = Stack.length yy_terms_stack = 0 in
	let complete_tree = incomplete_tree_is_complete !yy_incomplete_tree in
        if  (not empty_stack) or not complete_tree
        then parse_failwith "badly formed term"
        else
          let t = !yy_incomplete_tree in
          let () = yy_incomplete_tree := Undefined in
          t
    | h::t ->
        let () = add_to_incomplete_tree h in
        fn t
  in fn

let is_param_defined_sort s =
  match s with
      Def_sort  _ -> true
    | Abstr_sort0 _| Abstr_sort1 _ | Abstr_sort2 _ -> false


let is_param_sort1 s =
  match s with
      Abstr_sort1 _ -> true
    | Def_sort _| Abstr_sort0 _ | Abstr_sort2 _ -> false

let is_param_sort0 s =
  match s with
      Abstr_sort0 _ -> true
    | Def_sort _| Abstr_sort1 _ | Abstr_sort2 _  -> false

let is_param_sort2 s =
  match s with
      Abstr_sort2 _ -> true
    | Abstr_sort1 _ | Abstr_sort0 _ | Def_sort _  -> false

let get_id_param_sort s =
  match s with
      Abstr_sort1 (i, _) -> i
    | Abstr_sort2 (i, _, _) -> i
    | Def_sort _| Abstr_sort0 _ -> failwith "get_id_param_sort"
	(*
   * Typecheck an incomplete tree, infer type of variables.
   * In one case, we need to delay typechecking: when a literal of the form x = y is present.
   * It means that the actual terms creation must be delayed to the end of the parsing of an axiom / clause.
*)

let rec typecheck_incomplete_tree ps t =
  let () = if !debug_mode then buffered_output ("\nenter typecheck_incomplete_tree: the parameters ps and t are: " ^ ((sprint_param_sort ps) ^ "  " ^ (sprint_incomplete_tree_pointer t)))  in
  match t with
      Undefined -> invalid_arg "typecheck_incomplete_tree"
    | Defined (Ivar x) -> (
        try
          let s' = List.assoc x !yy_tmp_sorts in
          let new_s' =
	    match ps with
		Actual_sort s'' ->
		  (try
		    unify_sorts ps s'
		  with Failure "unify_sorts" ->  parse_failwith ("\nConflicting types: " ^ (sprint_sort s') ^ " and " ^ (sprint_sort s''))
		  )
            | Variable_sort x' -> (* We have a sort for y in x = y ; we update the sort of x_{E} *)
		let l = yy_tmp_equiv_dico#find x' in
		 let () = List.iter (fun v -> yy_tmp_sorts := generic_insert_sorted (v, s') !yy_tmp_sorts) l in
		 let () = yy_tmp_equiv_dico#remove x' in
		 s'
	  in
	  if x < 0 then new term (Var_exist (x, new_s')) else new term (Var_univ (x, new_s'))
        with Not_found ->
          let new_s' = match ps with
	      Actual_sort s'' ->
		let new_s'' = expand_sorts s'' in
		let () = yy_tmp_sorts := generic_insert_sorted (x, new_s'') !yy_tmp_sorts in
		new_s''
            | Variable_sort x' ->
		let () = yy_tmp_equiv_dico#add_couple x x' in (* x has a fresh sort *)
		let () = param_sort_counter := !param_sort_counter + 1 in
		let str = ("'Undefined" ^ (string_of_int !param_sort_counter)) in
		let () = yy_tmp_sorts := generic_insert_sorted (x, Abstr_sort0 str) !yy_tmp_sorts in
		Abstr_sort0 str
	  in
	  if x < 0 then new term (Var_exist (x, new_s')) else new term (Var_univ (x, new_s'))
      )
    | Defined (Iterm (x, l)) ->
        let p =
	  try
	    dico_const_profile#find x
	  with Not_found -> parse_failwith ("constant " ^ (string_of_int x) ^ "not found in dico_const_profile")
        in
	let p' =  update_profile p  in
	let s' = List.hd p'
        and a' = List.tl p' in
        let () = match ps with
            Actual_sort s'' ->
              (try let _ = unify_sorts ps s' in () with Failure "unify_sorts" ->
(* 		let () = if !debug_mode then print_string ("\ncall of unify_sorts in parser.mly:  the list yy_tmp_param_sorts before application is : " ^ *)
(* 		(List.fold_right (fun (x, s) y -> (x ^ " has associated the sort " ^ (sprint_sort s) ^ ", " ^ y)) !yy_tmp_param_sorts "")) else () in  *)
		parse_failwith ("\n Error: sort " ^ (sprint_sort s'') ^ " is not unifiable with " ^ (sprint_sort s')) )
          | Variable_sort x' ->
              try
                let new_x' = yy_tmp_equiv_dico#find x' in
                List.iter (fun v -> yy_tmp_sorts := generic_insert_sorted (v, s') !yy_tmp_sorts) new_x';
                yy_tmp_equiv_dico#remove x'
              with Not_found ->
                yy_tmp_sorts := generic_insert_sorted (x', s') !yy_tmp_sorts
        in
	let new_s' = unify_sorts ps s' in
        let a'' = List.map (fun v -> Actual_sort v) a' in
        let terms_l = List.map2 typecheck_incomplete_tree a'' l in
	new term (Term (x, terms_l, new_s'))

let term_with_new_sort t s =
  match t#content with
      Var_exist (i, _) -> new term (Var_exist (i, s))
    | Var_univ (i, _) -> new term (Var_univ (i, s))
    | Term (i, l, _) -> new term (Term (i, l, s))

let literal_of_incomplete_terms lit =
  let x, x', tlit = lit in
  let new_tx = x#expand_sorts in
  let new_tx' = x'#expand_sorts in
  let s = try unify_sorts (Actual_sort new_tx#sort) new_tx'#sort with Failure "unify_sorts" -> failwith "literal_of_incomplete_terms" in
  let t = term_with_new_sort new_tx s in
  let t' = term_with_new_sort new_tx' s in
  let () = if !debug_mode then ((print_detailed_term t); (print_detailed_term t')) in
  match tlit with
      Lit_equal (_, _) -> new literal (Lit_equal (t, t'))
    | Lit_rule (_, _) -> new literal (Lit_rule (t, t'))
    | Lit_diff (_, _) -> new literal (Lit_diff (t, t'))

(* Table of oracles (string, boolean reference) *)
let oracles_table = Hashtbl.create 13

let _ = List.iter (fun (kwd, tok) -> Hashtbl.add oracles_table kwd tok)
    [ ("system_is_sufficiently_complete",               system_is_sufficiently_complete) ;
      ("system_is_strongly_sufficiently_complete",      system_is_strongly_sufficiently_complete) ;
      ("system_is_ground_convergent",                   system_is_ground_convergent) ]

(* Table of tests (string, () -> ()) *)
let tests_table = Hashtbl.create 13
let _ = List.iter (fun (kwd, tok) -> Hashtbl.add tests_table kwd tok)
    [ ("do_sufficient_completeness_test",               sufficient_completeness_test) ;
      ("do_strongly_sufficient_completeness_test",      strongly_sufficient_completeness_test) ;
      ("do_ground_convergence_test",                    ground_convergence_test) ]
;;

(* returns a list of clauses by deleting the min and max symbols from c *)

let del_minmax c =
  let rec delt_minmax t =
    match t#content with
      | Var_univ _ | Var_exist _ -> [([], t)]
      | Term (f, l, s) ->
	  let  megamix12 =
	    megamix (List.fold_right (fun t lres -> (delt_minmax t) :: lres) l [])
	  in
	  let res = List.fold_right (
	    fun l1'  lres ->
	      if f == id_symbol_min || f == id_symbol_max then
		(* let _ = buffered_output ("Here delt_minmax is " ^ (dico_const_string#find f) ^ " and value is " ^ (string_of_int f)) in *)
		let (l1, t1) = List.hd l1' in
		let (l2, t2) = List.hd (List.tl l1') in
		let tless = new term (Term (id_symbol_less, [t1;t2], id_sort_bool)) in
		let tge = new term (Term (id_symbol_geq, [t1;t2], id_sort_bool)) in
		let litless = new literal (Lit_equal (tless, new term (Term (id_symbol_true, [], id_sort_bool)))) in
		let litge = new literal (Lit_equal (tge, new term (Term (id_symbol_true, [], id_sort_bool)))) in
		if f == id_symbol_min then (litless :: (l1@l2), t1) :: ((litge:: (l1@l2), t2) :: lres)
		else if f == id_symbol_max then (litless:: (l1@l2), t2) :: ((litge:: (l1@l2), t1) :: lres)
		else ((l1@l2), new term (Term (f, [t1;t2], s))) :: lres
		else
		  let nl, l' =  (List.fold_right (fun (l1,t) (ll, lt) -> (l1 @ ll, t::lt)) l1' ([],[])) in
		  (nl, new term (Term (f, l',s))) :: lres
	  )  megamix12 []
	  in
	  if res == [] then [([], t)] else res

  in
  let dellit_minmax lit =
       match lit#content with
	 | Lit_equal (tl, tr) ->
	   let tl' = delt_minmax tl in
	   let tr' = delt_minmax tr in
	   let megamix12 = megamix [tl'; tr'] in
	   List.fold_right (fun l lres ->
	     let (l1, t1) = List.hd l in
	     let (l2, t2) = List.hd (List.tl l) in
	     [(l1@l2), new literal (Lit_equal (t1, t2))] @ lres) megamix12 []
	 | Lit_rule (tl, tr) ->
	   let tl' = delt_minmax tl in
	   let tr' = delt_minmax tr in
	   let megamix12 = megamix [tl'; tr'] in
	   List.fold_right (fun l lres ->
	     let (l1, t1) = List.hd l in
	     let (l2, t2) = List.hd (List.tl l) in
	     [(l1@l2), new literal (Lit_rule (t1, t2))] @ lres) megamix12 []
	 | Lit_diff (tl, tr) ->
	   let tl' = delt_minmax tl in
	   let tr' = delt_minmax tr in
	   let megamix12 = megamix [tl'; tr'] in
	   List.fold_right (fun l lres ->
	     let (l1, t1) = List.hd l in
	     let (l2, t2) = List.hd (List.tl l) in
	     [(l1@l2), new literal (Lit_diff (t1, t2))] @ lres) megamix12 []
  in
  let rec split_f l l' len =
    if len == 0 then (l, l')
    else
      try
	let l1 = List.hd l' in
	split_f (l1::l) (List.tl l') (len - 1)
      with Failure "hd" ->
	failwith "split_f"
  in
  let lnegs = c#negative_lits in
  let len_nlits = List.length lnegs in
  let lpos = c#positive_lits in
  let nlits_mm = List.map (fun l -> (dellit_minmax l)) lnegs in
  let npos_mm = List.map (fun l -> (dellit_minmax l)) lpos in
  let mm = megamix (nlits_mm @ npos_mm) in
    (* if nlits_mm == [] then npos_mm  *)
    (* else if npos_mm == [] then nlits_mm  *)
    (* else megamix (nlits_mm @ npos_mm) in *)
  List.map (fun ll ->
    let (ln', lp') = split_f [] ll len_nlits in
    let (ln1, ln) = List.fold_right (fun (lnegs, lit) (lln, llits) -> (lnegs @ lln, lit :: llits)) ln' ([],[])  in
    let (lp1, lp) = List.fold_right (fun (lposs, lit) (llp, llits) -> (lposs @ llp, lit :: llits)) lp' ([],[])  in
    let nlneg = lp1 @ ln1 @ ln in
    let nlpos = lp in
    let nlneg' = expand_sorts_list nlneg in
    let nlpos' = expand_sorts_list nlpos in
    let () = if not !specif_parameterized && not (test_well_founded_cl (nlneg', nlpos')) then
      failwith "clause3: undefined types"
    in
    new clause (nlneg', nlpos') [] ("",0,([],[]))
    (* c#build nlneg' nlpos' *)
  ) mm
    %}
%start get_term
%start list_of_systems
%start reasoning_module
%start specif
%start specif_clausal_position
%start specif_clause2
%start specif_literal_position_in_clause
%start specif_positive_int
%start specif_shell_command
%start specif_substitution
%start specif_term
%start strategy_term
%token TOK_AC
%token TOK_AC_SUBSUMES
%token TOK_ADDPREMISE
%token TOK_AND
%token TOK_AROBAT
%token TOK_ARROW
%token TOK_ASSOC
%token TOK_AUGMENTATION
%token TOK_AUGMENTATION_STRATEGY
%token TOK_AUTO_SIMPLIFICATION
%token TOK_AXIOMS
%token TOK_CLOSE_SUBSTITUTION
%token TOK_COLUMN
%token TOK_COMA
%token TOK_COMPARE
%token TOK_COMPLEMENT
%token TOK_COMPLETE_TERMS
%token TOK_CONGRUENCE_CLOSURE
%token TOK_CONJECTURES
%token TOK_CONSTRUCTORS
%token TOK_CONTEXTUAL_REWRITING
%token TOK_CRITIC
%token TOK_CRITICAL_CONTEXT_SETS
%token TOK_DELETE
%token TOK_DIFF
%token TOK_ELIMINATE_REDUNDANT_LITERAL
%token TOK_ELIMINATE_TRIVIAL_LITERAL
%token TOK_EOF
%token TOK_EQUAL
%token TOK_EQUATIONAL_REWRITING
%token TOK_EQUIV
%token TOK_EXTRACT
%token TOK_FUNCTIONS
%token TOK_FUNCTION_PROPS
%token TOK_GENERATE
%token TOK_GENERATE_EQ
%token TOK_GENERATE_OBS
%token TOK_GOTO
%token TOK_GREATER
%token TOK_HYPOTHESES
%token TOK_ID
%token <string> TOK_IDENT
%token TOK_IMPLIES
%token TOK_IND_PRIORITIES
%token TOK_LBRACKET
%token TOK_LEFTRIGHT
%token TOK_LEMMAS
%token TOK_LPAR
%token TOK_MATCH
%token TOK_MAX_COMPARE
%token TOK_MULTISET
%token TOK_NEGATIVE_CLASH
%token TOK_NEGATIVE_DECOMPOSITION
%token TOK_NORM
%token TOK_NULLARY_SORTS
%token TOK_OBS_SORTS
%token TOK_ON
%token TOK_OPEN_SUBSTITUTION
%token TOK_OR
%token TOK_PARTIAL_CASE_REWRITING
%token TOK_POSITIVE_CLASH
%token TOK_POSITIVE_DECOMPOSITION
%token TOK_PRINT_CAML
%token TOK_PRINT_GOALS
%token TOK_PRINT_GOALS_HISTORY
%token TOK_PRIORITIES
%token TOK_PROPERTIES
%token TOK_QUESTION_MARK
%token TOK_RBRACKET
%token TOK_REDUCTION
%token TOK_REPEAT
%token TOK_REPEAT_PLUS
%token TOK_REWRITING
%token TOK_RIGHTLEFT
%token TOK_RPAR
%token TOK_RPOCOMPARE
%token TOK_SATURATE
%token TOK_SEMICOLUMN
%token TOK_SIMPLIFY
%token TOK_SORTS
%token TOK_SPECIF
%token TOK_START_WITH
%token TOK_STATUS
%token TOK_STOP_ON_CLAUSE
%token TOK_STRATEGIES
%token <string> TOK_STRING
%token TOK_SUBSUMPTION
%token TOK_TAUTOLOGY
%token TOK_TEST_SETS
%token TOK_TOTAL_CASE_REWRITING
%token TOK_TRY
%token TOK_USE
%type < Terms.term > get_term
%type < Clauses.which_system list > list_of_systems
%type < Strategies.reasoning_module > reasoning_module
%type < Strategies.problem_token Queue.t > specif
%type < Dummies.position_argument > specif_clausal_position
%type < Clauses.peano_context Clauses.clause > specif_clause2
%type < Dummies.position_argument > specif_literal_position_in_clause
%type < int > specif_positive_int
%type < Dummies.shell_commands > specif_shell_command
%type < (Symbols.var * Terms.term) list > specif_substitution
%type < Terms_parser.term_token list > specif_term
%type < Strategies.strategy > strategy_term
%%

specif:
  _1 = spec_fields _2 = spec_ordering _3 = spec_prop _4 = spec_problem _5 = TOK_EOF
    {  ( yy_queue )}
| _1 = spec_fields _2 = spec_ordering _3 = spec_prop _4 = TOK_EOF
    {  (
    let q = Queue.create ()
    in let () = Queue.add (Message_token "Correct specification") q
    in q
  )}

spec_fields:
  _1 = opt_specif_name _2 = opt_specif_use _3 = opt_specif_sorts _4 = opt_specif_obs_sorts _5 = opt_specif_constructors _6 = opt_specif_functions _7 = opt_specif_axioms
    {  (
  update_dico_free_constructors () ;
    if !free_constructors
    then buffered_output "All constructors are free"
    else () ;
    all_defined_functions := List.map (fun x -> - x) (List.tl (list_create (- !function_counter))) ;
    all_constructors := list_create !constructor_counter
(*     default_fill_order_dico_cc (); *)
  )}

spec_ordering:
  _1 = opt_specif_greater _2 = opt_specif_equivs _3 = opt_specif_status _4 = opt_specif_test_sets _5 = opt_specif_nullary_sorts _6 = opt_specif_function_props
    {  (
    let () = determine_ac_category () in
    (* Orient axioms *)
    let rec fn = function
      	[] -> []
      | (f, l, c)::t ->
          try
            let c' = c#orient in
            let () = buffered_output ("\t" ^ c'#string) in
            (f, l, c')::fn t
          with (Failure "orient") ->
            parsed_gfile := f ;
            linenumber := l ;
	    let concl = List.hd ((fun (_, p) -> p) c#content) in
	    match concl#content with
		Lit_equal _
	      | Lit_rule _ ->
      		  let c' = c#force_orientation in
		  let () = buffered_output ("\t" ^ c'#string) in
		  (* let () = broken_order := true in  *)
		  let () = buffered_output ("\nWARNING: the axiom [" ^ (string_of_int c#number) ^ "] is not orientable in a rewrite rule using the current order") in
		  (f, l, c')::fn t

	      | Lit_diff _ -> parse_failwith ("The axiom [" ^ (string_of_int c#number) ^ "] is not orientable")
    in
    buffered_output "Orienting axioms" ;
(*     if !use_order *)
(*     then *)
    let l = fn !yy_axioms
    in let () = yy_axioms := l in
(*     else *)
(*       () ; *)
    rewrite_system#init (List.map (fun (_, _, x) -> x) !yy_axioms) ;

(*    print_clause_list rewrite_system#content ;*)
(*     buffered_output "\nThe current order is :"; *)
    print_dico_order ();
    print_dico_equivalence ();
    buffered_output ("Computing nullary sorts") ;
    flush stdout ;
    update_dico_sort_nullarity () ;

    buffered_output ("Computing nullary individuals") ;
    flush stdout ;
    update_dico_nullary_individuals () ;

    if !observational_proof then
      begin
	buffered_output ("Using test-sets version " ^ (string_of_int !test_set_version)) ;
	buffered_output "Computing test sets" ;
	if List.length !yy_axioms > 0
	then !compute_test_set () ;
	!print_dico_test_set () ;

	compute_critical_context_set ();
      end;

(*     buffered_output ("Using test-sets version " ^ (string_of_int !test_set_version)) ; *)
(*     buffered_output "Computing test sets" ; *)
(*     if (List.length !yy_axioms > 0) && (not !int_specif_defined) (* the int sort cannot be computed with the test set version 0 in "int" theory *) *)
(*     then !compute_test_set ()  *)
(*     else if (!int_specif_defined) then *)
(*       rewrite_system#compute_induction_positions_v0        *)
(*     else (); *)
    if !boolean_specification
    then buffered_output "We have a boolean specification"
    else buffered_output "We do not have a boolean specification" ;
)}

spec_prop:
  _1 = opt_specif_properties _2 = opt_specif_priorities _3 = opt_specif_critical_context_sets
    {  ( )}

spec_problem:
  _1 = spec_problem_field
    {  ( [_1] )}
| _1 = spec_problem _2 = spec_problem_field
    {  ( _1 @ [_2] )}

spec_problem_field:
  _1 = specif_lemmas
    {  ( )}
| _1 = specif_conjectures
    {  ( )}
| _1 = specif_hypotheses
    {  ( )}
| _1 = specif_complete_terms
    {  ( )}
| _1 = specif_ind_priorities
    {  ( )}
| _1 = specif_strategies
    {  ( )}
| _1 = specif_startpoint
    {  ( )}
| _1 = specif_augmentation
    {  ( )}
| _1 = specif_norm
    {  ( )}
| _1 = specif_rpocompare
    {  ( )}
| _1 = specif_compare
    {  ( )}
| _1 = specif_max_compare
    {  ( )}
| _1 = specif_stop_on_clause
    {  ( )}
| _1 = specif_extract
    {  ( )}
| _1 = specif_match
    {  ( )}
| _1 = specif_ac_subsumes
    {  ( )}
| _1 = print_caml
    {  ( )}

opt_specif_name:
  _1 = TOK_SPECIF _2 = TOK_COLUMN _3 = TOK_IDENT
    {  ( spec_name := _3 )}
| _1 = TOK_SPECIF _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

opt_specif_use:
  _1 = TOK_USE _2 = TOK_COLUMN _3 = list_of_idents _4 = TOK_SEMICOLUMN
    {  (
    let rec fn = function
      [] -> ()
    | h::_ ->
        try
          add_predefined_specif h
        with (Failure "add_predefined_specif") ->
          parse_failwith ("\"" ^ h ^ "\" is not a valid predefined specification") in
    fn _3 )}
| _1 = TOK_USE _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

list_of_idents:
  _1 = TOK_IDENT
    {  ( [ _1 ] )}
| _1 = list_of_idents _2 = TOK_IDENT
    {  ( _1 @ [ _2 ] )}

opt_specif_sorts:
  _1 = TOK_SORTS _2 = TOK_COLUMN _3 = get_list_of_sorts _4 = TOK_SEMICOLUMN
    {  ( buffered_output "\nSuccessfully parsed sorts" ;
    flush stdout )}
| _1 = TOK_SORTS _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

get_list_of_sorts:
  _1 = TOK_IDENT
    {  ( selective_add_sort dico_sort_string sort_counter _1 )}
| _1 = get_list_of_sorts _2 = TOK_IDENT
    {  ( selective_add_sort dico_sort_string sort_counter _2 )}

opt_specif_constructors:
  _1 = TOK_CONSTRUCTORS _2 = TOK_COLUMN _3 = list_of_constructors
    {  ( buffered_output "\nSuccessfully parsed constructors" ;
    flush stdout )}
| _1 = TOK_CONSTRUCTORS _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

opt_specif_obs_sorts:
  _1 = TOK_OBS_SORTS _2 = TOK_COLUMN _3 = get_list_of_obs_sorts _4 = TOK_SEMICOLUMN
    {  ( buffered_output "Successfully parsed observable sorts" ;
    flush stdout )}
| _1 = TOK_OBS_SORTS _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

get_list_of_obs_sorts:
  _1 = TOK_IDENT
    {  ( try
     let () = observational_proof := true in
     let k = (try (dico_sort_string#find_key _1) with Failure "find_key" -> failwith "get_list_of_obs_sorts") in
     match k with
	 Def_sort i ->
	   let ref_i = ref i in
	   selective_add_sort dico_obs_sort ref_i (*obs_sort_counter*) _1
       | Abstr_sort0 _| Abstr_sort1 _ | Abstr_sort2 _  -> failwith "get_list_of_obs_sorts"
     with Not_found ->
       selective_add_sort dico_sort_string sort_counter _1
     )}
| _1 = get_list_of_obs_sorts _2 = TOK_IDENT
    {  (
    try
     let k = (try (dico_sort_string#find_key _2) with Failure "find_key" -> failwith "get_list_of_obs_sorts") in
     match k with
	 Def_sort i ->
	   let ref_i = ref i in
	   selective_add_sort dico_obs_sort ref_i (*obs_sort_counter*) _2
       |  Abstr_sort0 _| Abstr_sort1 _| Abstr_sort2 _  -> failwith "get_list_of_obs_sorts"

    with Not_found ->
     selective_add_sort dico_sort_string sort_counter _2

(*    let a = selective_add dico_sort_string sort_counter $2 in
    selective_add dico_obs_sort obs_sort_counter $2*))}

list_of_constructors:
  _1 = specif_constructor
    {  ( )}
| _1 = list_of_constructors _2 = specif_constructor
    {  ( )}

specif_constructor:
  _1 = TOK_IDENT _2 = TOK_COLUMN _3 = specif_profile
    {  (process_specif_symbol constructor_counter _1 _3  )}

opt_specif_functions:
  _1 = TOK_FUNCTIONS _2 = TOK_COLUMN _3 = list_of_functions
    {  ( buffered_output "\nSuccessfully parsed functions" ;
    flush stdout )}
| _1 = TOK_FUNCTIONS _2 = TOK_FUNCTIONS _3 = TOK_COLUMN _4 = list_of_functions
    {  ( buffered_output "\nSuccessfully parsed functions" ;
    flush stdout )}
| _1 = TOK_FUNCTIONS _2 = TOK_COLUMN
    {  ( )}
| _1 = TOK_FUNCTIONS _2 = TOK_FUNCTIONS _3 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

list_of_functions:
  _1 = specif_function
    {  ( )}
| _1 = list_of_functions _2 = specif_function
    {  ( )}

specif_function:
  _1 = TOK_IDENT _2 = TOK_COLUMN _3 = specif_profile
    {  ( process_specif_symbol function_counter _1 _3 )}

specif_profile:
  _1 = list_of_sorts _2 = TOK_ARROW _3 = list_of_sorts _4 = TOK_SEMICOLUMN
    {  ( if List.length _3 > 1 then parse_failwith "The function should return only one value" else (_1, List.hd _3) )}
| _1 = list_of_sorts _2 = TOK_SEMICOLUMN
    {  ( ([], List.hd _1) )}
| _1 = TOK_ARROW _2 = list_of_sorts _3 = TOK_SEMICOLUMN
    {  (  if List.length _2 > 1 then parse_failwith "The function should return only one value" else  ([], List.hd _2) )}

list_of_sorts:
  _1 = ident_sort
    {  (_1)}
| _1 = list_of_sorts _2 = ident_sort
    {      (_1 @ _2)}

ident_sort:
  _1 = TOK_IDENT
    {  ( let s =
      find_sort_id _1
  in [ s ] )}
| _1 = TOK_LPAR _2 = TOK_IDENT _3 = ident_sort _4 = end_of_sorts
    {  (let arg = List.hd _3 in
   let s = find_sort_id _2 in
   if _4 = [] then [ Abstr_sort1 ((def_sort_id s), arg)]
   else
     let arg' = List.hd _4 in
     [ Abstr_sort2 ((def_sort_id s), arg, arg')]
 )}

end_of_sorts:
  _1 = TOK_RPAR
    {  ([])}
| _1 = ident_sort _2 = TOK_RPAR
    {  (_1)}

opt_specif_axioms:
  _1 = TOK_AXIOMS _2 = TOK_COLUMN _3 = pos_codes_true _4 = list_of_horn_clauses
    {  ( buffered_output "\nSuccessfully parsed axioms" ; flush stdout ;
    yy_axioms := List.map introduce_var_exist _4 ;
    if !debug_mode then print_clause_list (List.map (fun (_, _, x) -> x) !yy_axioms) )}
| _1 = TOK_AXIOMS _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

opt_specif_function_props:
  _1 = TOK_FUNCTION_PROPS _2 = TOK_COLUMN _3 = list_of_raw_symbols _4 = TOK_COLUMN _5 = TOK_AC _6 = TOK_SEMICOLUMN
    {  (process_function_props _3 Prop_ac )}
| _1 = TOK_FUNCTION_PROPS _2 = TOK_COLUMN _3 = list_of_raw_symbols _4 = TOK_COLUMN _5 = TOK_ASSOC _6 = TOK_SEMICOLUMN
    {  (process_function_props _3 Prop_assoc )}
| _1 = TOK_FUNCTION_PROPS _2 = TOK_COLUMN
    {  ( )}
| 
    {  ()}

list_of_raw_symbols:
  _1 = TOK_IDENT
    {  ( [ _1 ] )}
| _1 = list_of_raw_symbols _2 = TOK_IDENT
    {  ( _1 @ [ _2 ] )}

list_of_symbols:
  _1 = TOK_IDENT
    {  ( [ find_symbol_id _1 ] )}
| _1 = list_of_symbols _2 = TOK_IDENT
    {  ( let s = find_symbol_id _2 in
    if not (List.mem s _1) then _1 @ [ find_symbol_id _2 ] else parse_failwith (_2 ^ " is duplicated") )}

opt_specif_greater:
  _1 = TOK_GREATER _2 = TOK_COLUMN _3 = init_order_dico _4 = list_of_greater
    {  (     (* print_dico_order () *))}
| _1 = TOK_GREATER _2 = TOK_COLUMN
    {  ( )}
| _1 = init_equiv_dico
    {  ( let () = buffered_output "No order provided" in default_fill_order_dico () )}

init_order_dico:
  
    {  (
    print_dico_const_string ();
    dico_order#init (!all_defined_functions @ !all_constructors) ;
    flush stdout )}

list_of_greater:
  _1 = specif_greater
    {  ( )}
| _1 = list_of_greater _2 = specif_greater
    {  ( )}

specif_greater:
  _1 = TOK_IDENT _2 = TOK_COLUMN _3 = list_of_symbols _4 = TOK_SEMICOLUMN
    {  (  let v = find_symbol_id _1 in
     List.iter (fun x -> dico_order#add_couple v x) _3 )}

opt_specif_equivs:
  _1 = TOK_EQUIV _2 = TOK_COLUMN _3 = init_equiv_dico _4 = list_of_equivs
    {  (
    if dico_order#empty
    then
      let () = buffered_output "Order dico is empty" in default_fill_order_dico ()
    else
      try
(* 	print_dico_equivalence (); *)
        dico_order#merge_equivalence_relation dico_equivalence ;
        buffered_output "\nSuccessfully parsed equivalence relation" ; flush stdout
      with (Failure "rehash") ->
        parse_failwith "t here are incompatibilities between the order and equivalence relations"
  )}
| _1 = TOK_EQUIV _2 = TOK_COLUMN
    {  ( if dico_order#empty
    then
      let () = buffered_output "Order dico is empty" in default_fill_order_dico ()
    else
      ()
  )}
| 
    {  ( if dico_order#empty
    then
      let () = buffered_output "Order dico is empty" in default_fill_order_dico ()
    else
      ()
  )}

init_equiv_dico:
  
    {  (

(*     List.iter (fun x -> (buffered_output ("init_order_dico : x = " ^ (string_of_int x)))) (!all_defined_functions @ !all_constructors); *)
    dico_equivalence#init dico_order#keys; (* (!all_defined_functions @ !all_constructors) ; *)
    flush stdout )}

list_of_equivs:
  _1 = specif_equiv
    {  ( )}
| _1 = list_of_equivs _2 = specif_equiv
    {  ( )}

specif_equiv:
  _1 = list_of_symbols _2 = TOK_SEMICOLUMN
    {  ( match _1 with
      [] -> failwith "I'm bewildered"
      | _::_ ->  dico_equivalence#fill (fun _ _ -> true) _1;  )}

opt_specif_status:
  _1 = TOK_STATUS _2 = TOK_COLUMN _3 = list_of_statuses
    {  ( buffered_output "\nSuccessfully parsed statuses" ; flush stdout ;
    print_dico_id_status () ;
    (try complete_status_dico ()
    with (Failure s) -> parse_failwith ("Symbol \"" ^ s ^ "\" is ac and must have multiset status") );
    try check_status_equivalent_symbols ()
    with (Failure "check_status_equivalent_symbols") -> parse_failwith "equivalent symbols must have the same status"
  )}
| _1 = TOK_STATUS _2 = TOK_COLUMN
    {  ( buffered_output "\nSuccessfully parsed statuses" ; flush stdout ;
    print_dico_id_status () ;
    (try complete_status_dico ()
    with (Failure s) -> parse_failwith ("Symbol \"" ^ s ^ "\" is ac and must have multiset status") );
    try check_status_equivalent_symbols ()
    with (Failure "check_status_equivalent_symbols") -> parse_failwith "equivalent symbols must have the same status"
  )}
| 
    {  ( buffered_output "\nSuccessfully parsed statuses" ; flush stdout ;
    print_dico_id_status () ;
    (try complete_status_dico ()
    with (Failure s) -> parse_failwith ("Symbol \"" ^ s ^ "\" is ac and must have multiset status") );
    try check_status_equivalent_symbols ()
    with (Failure "check_status_equivalent_symbols") -> parse_failwith "equivalent symbols must have the same status"
  )}

list_of_statuses:
  _1 = specif_status
    {  ( )}
| _1 = list_of_statuses _2 = specif_status
    {  ( )}

specif_status:
  _1 = list_of_symbols _2 = TOK_LEFTRIGHT _3 = TOK_SEMICOLUMN
    {  (
    try
      let () = List.iter (fun x -> if symbol_is_ac x then failwith (dico_const_string#find x) else ()) _1
      in List.iter (fun x -> add_to_status_dico x Left) _1
    with (Failure s) -> parse_failwith ("Symbol \"" ^ s ^ "\" is ac and must have multiset status")
      | Not_found -> failwith "raising Not_found in specif_status")}
| _1 = list_of_symbols _2 = TOK_RIGHTLEFT _3 = TOK_SEMICOLUMN
    {  ( try
      let () = List.iter (fun x -> if symbol_is_ac x then failwith (dico_const_string#find x) else ()) _1
      in List.iter (fun x -> add_to_status_dico x Right) _1
    with (Failure s) -> parse_failwith ("Symbol \"" ^ s ^ "\" is ac and must have multiset status")
      | Not_found -> failwith "raising Not_found in specif_status")}
| _1 = list_of_symbols _2 = TOK_MULTISET _3 = TOK_SEMICOLUMN
    {      ( List.iter (fun x -> add_to_status_dico x Multiset) _1 )}

opt_specif_properties:
  _1 = TOK_PROPERTIES _2 = TOK_COLUMN _3 = list_of_properties
    {  ( buffered_output "\nSuccessfully parsed properties" ; flush stdout )}
| _1 = TOK_PROPERTIES _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

list_of_properties:
  _1 = TOK_IDENT _2 = TOK_SEMICOLUMN
    {  ( try
      let p = Hashtbl.find oracles_table _1
      in p := true
    with Not_found ->
      try
        let p = Hashtbl.find tests_table _1
        in p ()
      with Not_found ->
        parse_failwith ("property \"" ^ _1 ^ "\" is not defined") )}
| _1 = list_of_properties _2 = TOK_IDENT _3 = TOK_SEMICOLUMN
    {  ( try
      let p = Hashtbl.find oracles_table _2
      in p := true
    with Not_found ->
      try
        let p = Hashtbl.find tests_table _2
        in p ()
      with Not_found -> parse_failwith ("property \"" ^ _2 ^ "\" is not defined") )}

opt_specif_priorities:
  _1 = TOK_PRIORITIES _2 = TOK_COLUMN _3 = list_of_priorities
    {  ( buffered_output "\nSuccessfully parsed priorities" ; flush stdout ;
    !fill_default_induction_positions _3 ;
    buffered_output "Generate will be attempted on the following positions:" ;
    print_induction_symbols_priorities () )}
| _1 = TOK_PRIORITIES _2 = TOK_COLUMN
    {  ( !fill_default_induction_positions [] ;
    buffered_output "Generate will be attempted on the following positions:" ;
    print_induction_symbols_priorities () )}
| 
    {  ( !fill_default_induction_positions [] ;
     buffered_output "Generate will be attempted on the following positions:" ;
     print_induction_symbols_priorities ()
  )}

list_of_priorities:
  _1 = list_of_function_symbols _2 = TOK_SEMICOLUMN
    {  ( [ _1 ] )}
| _1 = list_of_priorities _2 = list_of_function_symbols _3 = TOK_SEMICOLUMN
    {  ( _1 @ [ _2 ] )}

list_of_function_symbols:
  _1 = specif_fun_with_positions
    {  ( _1 )}
| _1 = list_of_function_symbols _2 = specif_fun_with_positions
    {  ( merge_induction_positions _1 _2 )}

specif_fun_with_positions:
  _1 = TOK_IDENT
    {  (
    let n =
      try
	let n = dico_const_string#find_key _1
	in if is_defined n
	then n
	else parse_failwith ("symbol " ^ _1 ^ " is not a defined function")
      with Failure "find_key" -> parse_failwith ("symbol " ^ _1 ^ " is not a defined function")
    in
    try
      let l = (dico_ind_positions_v0#find n) in
      let all_ind_pos = Sort.list (<=) (List.map (fun p -> n, p) (list_remove_doubles (=) (List.flatten l))) in
      Ind_pos_position all_ind_pos
    with Not_found -> parse_failwith ("symbol \"" ^ _1 ^ "\" has no induction positions") )}
| _1 = TOK_IDENT _2 = TOK_LPAR _3 = list_of_positions _4 = TOK_RPAR
    {  (
    let n =
      try
        let n = dico_const_string#find_key _1
        in if is_defined n
        then n
        else parse_failwith ("symbol " ^ _1 ^ " is not a defined function")
      with Failure "find_key" -> parse_failwith ("symbol " ^ _1 ^ " is not a defined function")
    in try
      let l = dico_ind_positions_v0#find n in
      let all_ind_pos = list_remove_doubles (=) (List.flatten l) in
      let _ = generic_setminus all_ind_pos _3
      in Ind_pos_position ((Sort.list (<=) (List.map (fun p -> n, p) _3)))
    with Not_found -> parse_failwith ("symbol \"" ^ _1 ^ "\" has no induction positions")
      | (Failure "setminus") -> parse_failwith ("provided induction positions of symbol \"" ^ _1 ^
        "\" are not a subset of actual positions") )}
| _1 = specif_path
    {  (
    Ind_pos_void
  )}

specif_path:
  _1 = TOK_LBRACKET _2 = list_of_sym_int_couples _3 = TOK_RBRACKET
    {  ( _2 )}

list_of_paths:
  _1 = specif_path
    {  ( [_1] )}
| _1 = list_of_paths _2 = specif_path
    {  ( _1 @ [_2] )}

list_of_sym_int_couples:
  _1 = sym_int_couple
    {  ( [ _1 ] )}
| _1 = list_of_sym_int_couples _2 = TOK_SEMICOLUMN _3 = sym_int_couple
    {  ( _1 @ [ _3 ] )}

sym_int_couple:
  _1 = TOK_IDENT _2 = TOK_AROBAT _3 = TOK_IDENT
    {  ( let f = find_symbol_id _1
    and i = parse_positive_int _3
    in f, i )}

opt_specif_test_sets:
  _1 = TOK_TEST_SETS _2 = TOK_COLUMN _3 = list_of_test_sets
    {  (
(*     buffered_output "\nSuccessfully parsed test sets" ;  *)
(*     flush stdout; *)
(*     !print_dico_test_set () *)
  )}
| _1 = TOK_TEST_SETS _2 = TOK_COLUMN
    {  ( )}
| 
    {  ()}

list_of_test_sets:
  _1 = specif_test_set
    {  ( )}
| _1 = list_of_test_sets _2 = specif_test_set
    {  ( )}

specif_test_set:
  _1 = TOK_IDENT _2 = TOK_COLUMN _3 = list_of_terms _4 = TOK_SEMICOLUMN
    {  (
  )}
| _1 = list_of_paths _2 = TOK_COLUMN _3 = list_of_terms _4 = TOK_SEMICOLUMN
    {  ( )}

opt_specif_nullary_sorts:
  _1 = TOK_NULLARY_SORTS _2 = TOK_COLUMN _3 = list_of_nullary_sorts _4 = TOK_SEMICOLUMN
    { (
   let fn string =
     let s = find_sort_id string in
     try
       let _ = dico_sort_nullarity#find s in
       buffered_output ("The sort \"" ^ string ^ "\" is already in the dictionary of nullary sorts"); flush stdout
     with Not_found -> dico_sort_nullarity#add s true
   in List.iter fn _3;

    buffered_output "\nSuccessfully parsed nullary sorts" ;
    flush stdout;
     buffered_output "WARNING: The user introduced the following nullary sorts !" ; flush stdout;
    print_dico_sort_nullarity ()
  )}
| _1 = TOK_NULLARY_SORTS _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

list_of_nullary_sorts:
  _1 = specif_nullary_sort
    {    ([_1] )}
| _1 = list_of_nullary_sorts _2 = specif_nullary_sort
    {    ( _1 @ [_2])}

specif_nullary_sort:
  _1 = TOK_IDENT
    {( _1
)}

list_of_contexts:
  _1 = reset_tmp_vars _2 = context
    {  ( [ _2 ] )}
| _1 = list_of_contexts _2 = reset_tmp_vars _3 = context
    {  ( _1 @ [ _3 ] )}

context:
  _1 = TOK_LBRACKET _2 = get_term _3 = TOK_COMA _4 = TOK_IDENT _5 = TOK_RBRACKET
    {  ( let t = _2
    and x =
      try List.assoc _4 !yy_tmp_vars
      with Not_found -> parse_failwith "The contextual variable is not in the context"
    in let var_sort = try List.assoc x (List.map (fun (x,y,_) -> (x, y)) t#variables) with Not_found -> failwith "raising Not_found in context"
    in let c = new context t#content  x
    in let () = Critical_context_set.critical_context_set_by_var#add var_sort c
    in c )}

context_specif:
  _1 = TOK_IDENT _2 = TOK_COLUMN _3 = list_of_contexts _4 = TOK_SEMICOLUMN
    {   ( let declared_sort = find_sort_id _1
     and contexts = _3
     in if not (List.for_all (fun c -> c#sort = declared_sort)contexts)
            then
               parse_failwith "A context is not of the declared sort"
            else
               (*Critical_context_set.critical_context_set#add declared_sort contexts*)
               critical_context_set#replace declared_sort (( let old = ref [] in let () = try old := critical_context_set#find declared_sort with _ -> () in !old ) @ contexts)

   )}

list_of_context_specif:
  _1 = context_specif
    {  ( [ _1 ] )}
| _1 = list_of_context_specif _2 = context_specif
    {  ( _1 @ [ _2 ] )}

opt_specif_critical_context_sets:
  _1 = TOK_CRITICAL_CONTEXT_SETS _2 = TOK_COLUMN _3 = list_of_context_specif
    {  ( buffered_output "Successfully parsed critical context sets" ;print_critical_context_set ();flush stdout )}
| _1 = TOK_CRITICAL_CONTEXT_SETS _2 = TOK_COLUMN
    {  ( )}
| 
    {  ( )}

specif_ind_priorities:
  _1 = TOK_IND_PRIORITIES _2 = TOK_COLUMN _3 = list_of_infs
    {  ( )}
| _1 = TOK_IND_PRIORITIES _2 = TOK_COLUMN
    {  ( )}

list_of_infs:
  _1 = specif_infs
    {  ( )}
| _1 = list_of_infs _2 = specif_infs
    {  ( )}

specif_infs:
  _1 = list_of_symbols _2 = TOK_SEMICOLUMN
    {  (
(*     let l = list_2_list_of_couples $1 *)
(*     in List.iter (fun (x, y) -> dico_infs#add_couple y x) l  *)
    let () = dico_infs#clear in
    let () = dico_infs_flag := true in
    let rec fn l =
      match l with
	  [] -> ()
	| h :: t -> let () = List.iter (fun x -> dico_infs#add h x) t in
	  fn t
    in
    let lst = if _1 <> [] then let () = list_ind_priorities := _1 in _1 @ [last_el _1] else [] in
    fn (List.rev lst)
  )}

specif_complete_terms:
  _1 = TOK_COMPLETE_TERMS _2 = TOK_COLUMN _3 = list_of_terms _4 = TOK_SEMICOLUMN
    {  (Queue.add (Cterm_token _3) yy_queue )}
| _1 = TOK_COMPLETE_TERMS _2 = TOK_COLUMN
    {  ( )}

specif_lemmas:
  _1 = TOK_LEMMAS _2 = TOK_COLUMN _3 = pos_codes_false _4 = list_of_clauses
    {  ( buffered_output "\nSuccessfully parsed lemmas" ; flush stdout ;
    print_clause_list _4 ;
    Queue.add (Lemmas_token _4) yy_queue )}
| _1 = TOK_LEMMAS _2 = TOK_COLUMN
    {  ( )}

specif_conjectures:
  _1 = TOK_CONJECTURES _2 = TOK_COLUMN _3 = pos_codes_false _4 = list_of_clauses_history
    {  ( buffered_output "\nSuccessfully parsed conjectures" ;
    print_clause_list _4 ;
    let lc =
      if !specif_LA_defined && not !specif_Rmaxs0_defined && not !specif_Rmins0_defined && not !specif_Rzmm_defined then  let res = List.fold_right (fun c l -> (del_minmax c) @ l) _4 [] in res
      else _4
    in
    Queue.add (Conjectures_token lc) yy_queue
  )}
| _1 = TOK_CONJECTURES _2 = TOK_COLUMN
    {  ( )}

specif_hypotheses:
  _1 = TOK_HYPOTHESES _2 = TOK_COLUMN _3 = pos_codes_false _4 = list_of_clauses
    {  ( buffered_output "\nSuccessfully parsed hypotheses" ;
    print_clause_list _4 ;
    Queue.add (Hypotheses_token _4) yy_queue )}
| _1 = TOK_HYPOTHESES _2 = TOK_COLUMN
    {  ( )}

list_of_clauses:
  _1 = reset_and_clause
    {  ( [_1] )}
| _1 = list_of_clauses _2 = reset_and_clause
    {  ( _1 @ [_2] )}

list_of_clauses_history:
  _1 = reset_and_clause
    {  ( [_1] )}
| _1 = reset_and_clause _2 = history_clause
    {  ( let () = _1#set_history _2 in [_1])}
| _1 = list_of_clauses_history _2 = reset_and_clause
    {  ( _1 @ [_2] )}

history_clause:
  _1 = one_history
    {([_1])}
| _1 = history_clause _2 = one_history
    {(_1 @ [_2])}

one_history:
  _1 = TOK_OPEN_SUBSTITUTION _2 = specif_substitution2 _3 = TOK_CLOSE_SUBSTITUTION _4 = garbage_history _5 = specif_clause _6 = TOK_SEMICOLUMN
    {((_2, _5))}

garbage_history:
  _1 = TOK_ON _2 = TOK_LBRACKET _3 = TOK_IDENT _4 = TOK_RBRACKET
    {()}

reset_and_clause:
  _1 = reset_tmp_vars _2 = specif_clause _3 = TOK_SEMICOLUMN
    {  ( _2 )}

list_of_horn_clauses:
  _1 = reset_and_horn_clause
    {  ( [_1] )}
| _1 = list_of_horn_clauses _2 = reset_and_horn_clause
    {  ( _1 @ [_2] )}

reset_and_horn_clause:
  _1 = reset_tmp_vars _2 = specif_horn_clause _3 = TOK_SEMICOLUMN
    {  ( (!parsed_gfile, !linenumber, _2) )}

reset_tmp_vars:
  
    {  ( yy_tmp_vars := [] ;
    yy_tmp_sorts := [] ;
(*     if !debug_mode then print_string "\nReset of yy_tmp_param_sorts"; *)
    yy_tmp_param_sorts := [] ;
    yy_tmp_equiv_dico#clear )}

specif_clause2:
  _1 = specif_clause _2 = TOK_EOF
    {  ( _1 )}

specif_clause:
  _1 = list_of_literals
    {  (
    let l' = List.map literal_of_incomplete_terms _1 in
    let new_l' = expand_sorts_list l' in
    let () = if not !specif_parameterized  && not (test_well_founded_cl ([], new_l')) then
      failwith "clause1: undefined types"
    in
    let res = new clause ([], new_l') [] ("",0,([],[])) in
(*     let () = print_detailed_clause res in *)
    res
  )}
| _1 = list_of_literals _2 = TOK_IMPLIES
    {  (
    let l = List.map literal_of_incomplete_terms _1 in
    let new_l = expand_sorts_list l in
    let () = if not !specif_parameterized && not (test_well_founded_cl (new_l, [])) then
      failwith "clause2: undefined types"
    in
    let res = new clause (new_l, []) [] ("",0,([],[])) in
(*     let () = print_detailed_clause res in *)
    res
  )}
| _1 = list_of_literals _2 = TOK_IMPLIES _3 = list_of_literals
    {  (
    let l = List.map literal_of_incomplete_terms _1 in
    let l' = List.map literal_of_incomplete_terms _3 in
    let new_l' = expand_sorts_list l' in
    let new_l = expand_sorts_list l in
    let () = if not !specif_parameterized && not (test_well_founded_cl (new_l, new_l')) then
      failwith "clause3: undefined types"
    in
    let res = new clause (new_l, new_l') [] ("",0,([],[])) in
(*     let () = print_detailed_clause res in *)
    res
  )}

specif_horn_clause:
  _1 = specif_literal
    {  (
    let l' = [ literal_of_incomplete_terms _1 ] in
    let new_l' = expand_sorts_list l' in
    let lhs, _ = (List.hd new_l')#both_sides in
    let arg_lhs = lhs#sons in
    let () = if List.exists (fun t -> not (t#is_constructor_term)) arg_lhs then failwith ("one of the arguments is not a constructor term" ) in
    let () = if not !specif_parameterized && not (test_well_founded_cl ([], new_l')) then
      failwith "clause4: undefined types"
    in
    let res = new clause ([], new_l') [] ("",0,([],[])) in
(*     let () = print_detailed_clause res in *)
    res
  )}
| _1 = list_of_literals _2 = TOK_IMPLIES _3 = specif_literal
    {  (
    let l = List.map literal_of_incomplete_terms _1
    and l' = [ literal_of_incomplete_terms _3 ] in
    let new_l' = expand_sorts_list l' in
    let new_l = expand_sorts_list l in
    let lhs, _ = (List.hd new_l')#both_sides in
    let arg_lhs = lhs#sons in
    let () = if List.exists (fun t -> not (t#is_constructor_term)) arg_lhs then failwith ("one of the arguments is not a constructor term" ) in
    let () = if not !specif_parameterized && not (test_well_founded_cl (new_l, new_l')) then
      failwith "clause5: undefined types"
    in
    let res = new clause (new_l, new_l') [] ("",0,([],[])) in
(*     let () = print_detailed_clause res in *)
    res
  )}

list_of_literals:
  _1 = specif_literal
    {  ( [ _1 ] )}
| _1 = list_of_literals _2 = TOK_COMA _3 = specif_literal
    {  ( _1 @ [ _3 ] )}

specif_literal:
  _1 = literal_get_sides
    {  (
  let lhs, rhs, type_lit = _1 in
    let t = process_term_tokens lhs
    and t' = process_term_tokens rhs in
    let content = try (defined_content t) with
	(Failure "defined_content") -> failwith "defined_content"
    in
    let term_t, term_t' =
      match content with
	  Ivar x -> (* t is a variable *)
	    begin (* dicards PM on exceptions *)
              try
		let s = List.assoc x !yy_tmp_sorts
		in
		if x < 0 then ((new term (Var_exist (x, s))), typecheck_incomplete_tree (Actual_sort s) t')
		else ((new term (Var_univ (x, s))), typecheck_incomplete_tree (Actual_sort s) t')
              with Not_found -> (* t has a fresh unknown sort *)
		let () = param_sort_counter := !param_sort_counter + 1 in
		let str = ("Undefined" ^ (string_of_int !param_sort_counter)) in
		let s' = Abstr_sort0 str in
		let new_t' = typecheck_incomplete_tree (Actual_sort s') t' in
		let () = yy_tmp_sorts := generic_insert_sorted (x, new_t'#sort) !yy_tmp_sorts in
		if x < 0 then ((new term (Var_exist (x, new_t'#sort))), new_t')
		else ((new term (Var_univ (x, new_t'#sort))), new_t')
            end
	| Iterm (x, _) -> (* t is a term *)
            let s = try dico_const_sort#find x with Not_found -> failwith "raising Not_found in specif_literal" in
	    let s' = List.hd (update_profile [s]) in (* the abstract sorts are renamed *)
            ((typecheck_incomplete_tree (Actual_sort s') t), typecheck_incomplete_tree (Actual_sort s')  t')
    in
    term_t, term_t', type_lit )}

literal_get_sides:
  _1 = specif_term _2 = TOK_EQUAL _3 = specif_term
    {  ( (_1,_3, Lit_equal (term_true, term_true)) )}
| _1 = specif_term _2 = TOK_ARROW _3 = specif_term
    {  ( (_1,_3, Lit_rule (term_true, term_true)))}
| _1 = specif_term _2 = TOK_DIFF _3 = specif_term
    {  ( (_1,_3, Lit_diff (term_true, term_true)) )}

specif_term:
  _1 = list_of_tokens
    {  (_1 )}

list_of_tokens:
  _1 = one_token
    {  ( _1 )}
| _1 = list_of_tokens _2 = one_token
    {  ( _1 @ _2 )}

one_token:
  _1 = TOK_IDENT
    {  ( [ TT_ident _1 ] )}
| _1 = TOK_LPAR _2 = TOK_IDENT _3 = TOK_COLUMN _4 = TOK_IDENT _5 = TOK_RPAR
    {  ( let () = check_explicit_type _2 _4 in
    [ TT_ident _2 ] )}
| _1 = TOK_LPAR _2 = list_of_term_tokens _3 = TOK_RPAR
    {  ( let () = if !debug_mode then (print_string"\n token list <<<<< " ; List.iter (fun x -> print_term_token x) _2) else ()
  in _2)}

list_of_term_tokens:
  _1 = list_of_tokens
    {  ( let content = (try defined_content (process_term_tokens _1) with
      (Failure "defined_content") -> failwith "defined_content")
  in [ TT_tree content ] )}
| _1 = list_of_term_tokens _2 = TOK_COMA _3 = list_of_tokens
    {  ( let content = (try (defined_content (process_term_tokens _3)) with
      (Failure "defined_content") -> failwith "defined_content")
  in _1 @ [ TT_tree content ] )}

specif_strategies:
  _1 = TOK_STRATEGIES _2 = TOK_COLUMN _3 = list_of_strategies
    {  ( buffered_output "\nSuccessfully parsed strategies" ;
    Queue.add (Strat_token _3) yy_queue )}
| _1 = TOK_STRATEGIES _2 = TOK_COLUMN
    {  ( )}

list_of_strategies:
  _1 = specif_strategy
    {  ( [_1] )}
| _1 = list_of_strategies _2 = specif_strategy
    {  ( _1 @ [_2] )}

specif_strategy:
  _1 = TOK_IDENT _2 = TOK_EQUAL _3 = strategy_term _4 = TOK_SEMICOLUMN
    {  ( (_1, _3) )}

strategy_term:
  _1 = TOK_ADDPREMISE _2 = TOK_LPAR _3 = reasoning_module _4 = TOK_COMA _5 = TOK_LBRACKET _6 = list_of_reasoning_modules _7 = TOK_RBRACKET _8 = TOK_RPAR
    {    (new strategy (Inference_rule (AddPremise (_3, new strategy (Try_ _6)))))}
| _1 = TOK_SIMPLIFY _2 = TOK_LPAR _3 = reasoning_module _4 = TOK_COMA _5 = TOK_LBRACKET _6 = list_of_reasoning_modules _7 = TOK_RBRACKET _8 = TOK_RPAR
    {    (new strategy (Inference_rule (Simplify (_3, new strategy (Try_ _6)))))}
| _1 = TOK_DELETE _2 = TOK_LPAR _3 = reasoning_module _4 = TOK_COMA _5 = TOK_LBRACKET _6 = list_of_reasoning_modules _7 = TOK_RBRACKET _8 = TOK_RPAR
    {    (new strategy (Inference_rule (Delete (_3, new strategy (Try_ _6)))))}
| _1 = TOK_GOTO _2 = TOK_IDENT
    {  ( match _2 with
      "smallest" -> new strategy (Inference_rule (Goto Goto_smallest))
    | "greatest" -> new strategy (Inference_rule (Goto Goto_greatest))
    | _ ->
        let i = parse_positive_int _2
        in new strategy (Inference_rule (Goto (Goto_number i))) )}
| _1 = TOK_LPAR _2 = list_of_strategy_terms _3 = TOK_RPAR
    {  ( new strategy (Series _2) )}
| _1 = TOK_TRY _2 = TOK_LPAR _3 = list_of_strategy_terms _4 = TOK_RPAR
    {  ( new strategy (Try_ _3) )}
| _1 = TOK_SATURATE _2 = TOK_LPAR _3 = list_of_strategy_terms _4 = TOK_RPAR
    {  ( new strategy (Saturate _3) )}
| _1 = TOK_REPEAT _2 = strategy_term
    {  ( new strategy (Repeat _2) )}
| _1 = TOK_REPEAT_PLUS _2 = strategy_term
    {  ( new strategy (Repeat_plus _2) )}
| _1 = TOK_IDENT
    {  ( new strategy (Named_strategy _1) )}
| _1 = TOK_QUESTION_MARK
    {  ( new strategy Query )}
| _1 = TOK_PRINT_GOALS
    {  ( new strategy (Print_goals (false, false)) )}
| _1 = TOK_PRINT_GOALS_HISTORY
    {  ( new strategy (Print_goals (false, true)) )}
| _1 = TOK_PRINT_GOALS _2 = TOK_LPAR _3 = TOK_IDENT _4 = TOK_RPAR
    {  ( match String.lowercase _3 with
      "t" | "true" -> new strategy (Print_goals (true, false))
    | "f" | "false" -> new strategy (Print_goals (false, false))
    | _ -> parse_failwith "Bad argument for strategy \"print_goals\"" )}
| _1 = TOK_PRINT_GOALS_HISTORY _2 = TOK_LPAR _3 = TOK_IDENT _4 = TOK_RPAR
    {  ( match String.lowercase _3 with
      "t" | "true" -> new strategy (Print_goals (true, true))
    | "f" | "false" -> new strategy (Print_goals (false, true))
    | _ -> parse_failwith "Bad argument for strategy \"print_goals_history\"" )}

list_of_strategy_terms:
  _1 = strategy_term
    {  ( [ _1 ] )}
| _1 = list_of_strategy_terms _2 = TOK_COMA _3 = strategy_term
    {  ( _1 @ [ _3 ] )}

reasoning_module:
  _1 = TOK_CONTEXTUAL_REWRITING _2 = TOK_LPAR _3 = strategy_term _4 = TOK_COMA _5 = specif_list_of_systems _6 = TOK_COMA _7 = specif_clausal_position _8 = TOK_RPAR
    {  ( Contextual_rewriting (_3, _5, _7) )}
| _1 = TOK_EQUATIONAL_REWRITING _2 = TOK_LPAR _3 = specif_literal_position_in_clause _4 = TOK_RPAR
    {  ( (Equational_rewriting _3) )}
| _1 = TOK_REWRITING _2 = TOK_LPAR _3 = TOK_IDENT _4 = TOK_COMA _5 = specif_list_of_systems _6 = TOK_COMA _7 = specif_literal_position_in_clause _8 = TOK_RPAR
    {  ( match _3 with
      "rewrite" -> (Rewriting (false, _5, _7))
    | "normalize" -> (Rewriting (true, _5, _7))
    | _ -> parse_failwith "argument of rewriting must be either \"rewrite\" or \"normalize\"" )}
| _1 = TOK_PARTIAL_CASE_REWRITING _2 = TOK_LPAR _3 = specif_list_of_systems _4 = TOK_COMA _5 = specif_literal_position_in_clause _6 = TOK_RPAR
    {  ( Partial_case_rewriting (_3, _5) )}
| _1 = TOK_TOTAL_CASE_REWRITING _2 = TOK_LPAR _3 = strategy_term _4 = TOK_COMA _5 = specif_list_of_systems _6 = TOK_COMA _7 = specif_literal_position_in_clause _8 = TOK_RPAR
    {  ( Total_case_rewriting (_3, _5, _7) )}
| _1 = TOK_GENERATE
    {  ( Generate (true, []) )}
| _1 = TOK_GENERATE _2 = TOK_LPAR _3 = TOK_QUESTION_MARK _4 = TOK_RPAR
    {  (Generate (false, []) )}
| _1 = TOK_GENERATE _2 = TOK_LPAR _3 = list_of_priorities _4 = TOK_RPAR
    {  ( Generate (true, _3) )}
| _1 = TOK_GENERATE_EQ
    {  ( Generate_eq (true, []) )}
| _1 = TOK_GENERATE_EQ _2 = TOK_LPAR _3 = TOK_QUESTION_MARK _4 = TOK_RPAR
    {  (Generate_eq (false, []) )}
| _1 = TOK_GENERATE_EQ _2 = TOK_LPAR _3 = list_of_priorities _4 = TOK_RPAR
    {  ( Generate_eq (true, _3) )}
| _1 = TOK_GENERATE_OBS
    {  ( ((Generate_obs (true, []))) )}
| _1 = TOK_GENERATE_OBS _2 = TOK_LPAR _3 = TOK_QUESTION_MARK _4 = TOK_RPAR
    {  ( ((Generate_obs (false, []))) )}
| _1 = TOK_GENERATE_OBS _2 = TOK_LPAR _3 = list_of_priorities _4 = TOK_RPAR
    {  ( ( (Generate_obs (true, _3))) )}
| _1 = TOK_POSITIVE_DECOMPOSITION
    {  ( Positive_decomposition )}
| _1 = TOK_CONGRUENCE_CLOSURE
    {  ( Congruence_closure )}
| _1 = TOK_NEGATIVE_DECOMPOSITION
    {  ( Negative_decomposition )}
| _1 = TOK_POSITIVE_CLASH
    {  ( Positive_clash )}
| _1 = TOK_TAUTOLOGY
    {  ( Tautology )}
| _1 = TOK_SUBSUMPTION _2 = TOK_LPAR _3 = specif_list_of_systems _4 = TOK_RPAR
    {  ( Subsumption (_3))}
| _1 = TOK_AUGMENTATION _2 = TOK_LPAR _3 = specif_list_of_systems _4 = TOK_RPAR
    {  ( Augmentation (_3))}
| _1 = TOK_NEGATIVE_CLASH
    {  ( Negative_clash )}
| _1 = TOK_ELIMINATE_REDUNDANT_LITERAL
    {  ( Eliminate_redundant_literal )}
| _1 = TOK_ELIMINATE_TRIVIAL_LITERAL
    {  ( Eliminate_trivial_literal )}
| _1 = TOK_AUTO_SIMPLIFICATION
    {  ( Auto_simplification )}
| _1 = TOK_COMPLEMENT
    {  ( Complement )}
| _1 = TOK_ID
    {  ( Id )}

list_of_reasoning_modules:
  _1 = reasoning_module
    {  ( [ new strategy (Inference_rule (Id_st _1)) ] )}
| _1 = list_of_reasoning_modules _2 = TOK_COMA _3 = reasoning_module
    {  ( _1 @ [ new strategy (Inference_rule (Id_st _3)) ] )}

specif_list_of_systems:
  _1 = TOK_QUESTION_MARK
    {  ( LOS_query )}
| _1 = list_of_systems
    {  ( LOS_defined _1 )}

list_of_systems:
  _1 = specif_system
    {  ( [ _1 ] )}
| _1 = list_of_systems _2 = TOK_OR _3 = specif_system
    {  ( _1 @ [ _3 ] )}

specif_system:
  _1 = TOK_IDENT
    {  ( match _1 with
    | "r"| "R" -> R
    | "c"| "C" -> C
    | "l"| "L" -> L
    | _ -> parse_failwith "bad systems specification" )}

specif_startpoint:
  _1 = TOK_START_WITH _2 = TOK_COLUMN _3 = strategy_term
    {  ( buffered_output "\nSuccessfully parsed startpoint" ;
    Queue.add (Startpoint_token _3) yy_queue )}
| _1 = TOK_START_WITH _2 = TOK_COLUMN
    {  ( )}

specif_augmentation:
  _1 = TOK_AUGMENTATION_STRATEGY _2 = TOK_COLUMN _3 = strategy_term
    {  ( buffered_output "\nSuccessfully parsed the augmentation strategy" ;
    Queue.add (Augmentation_token _3) yy_queue )}
| _1 = TOK_AUGMENTATION_STRATEGY _2 = TOK_COLUMN
    {  ( )}

specif_norm:
  _1 = TOK_NORM _2 = TOK_COLUMN _3 = list_of_terms _4 = TOK_SEMICOLUMN
    {  ( Queue.add (Norm_token _3) yy_queue )}
| _1 = TOK_NORM _2 = TOK_COLUMN
    {  ( )}

specif_rpocompare:
  _1 = TOK_RPOCOMPARE _2 = TOK_COLUMN _3 = two_terms
    {  (
     let t, t' = _3 in
    Queue.add (Rpo_token (t, t')) yy_queue )}
| _1 = TOK_RPOCOMPARE _2 = TOK_COLUMN
    {  ( )}

specif_compare:
  _1 = TOK_COMPARE _2 = TOK_COLUMN _3 = two_clauses
    {  ( let c, c' = _3 in
    Queue.add (Compare_token (c, c')) yy_queue )}
| _1 = TOK_COMPARE _2 = TOK_COLUMN
    {  ( )}

specif_max_compare:
  _1 = TOK_MAX_COMPARE _2 = TOK_COLUMN _3 = two_clauses
    {  ( let c, c' = _3 in
    Queue.add (Compare_max_token (c, c')) yy_queue )}
| _1 = TOK_MAX_COMPARE _2 = TOK_COLUMN
    {  ( )}

specif_stop_on_clause:
  _1 = TOK_STOP_ON_CLAUSE _2 = TOK_COLUMN _3 = TOK_IDENT _4 = TOK_SEMICOLUMN
    {  (
    stop_clause := int_of_string _3)}
| _1 = TOK_STOP_ON_CLAUSE _2 = TOK_COLUMN
    {  ()}

specif_extract:
  _1 = TOK_EXTRACT _2 = TOK_COLUMN _3 = list_of_symbols
    {  ( extract_specification _3)}
| _1 = TOK_EXTRACT _2 = TOK_COLUMN
    {  ( )}

specif_match:
  _1 = TOK_MATCH _2 = TOK_COLUMN _3 = two_terms _4 = TOK_SEMICOLUMN
    {  ( let t, t' = _3 in
    Queue.add (Match_token (t, t')) yy_queue )}
| _1 = TOK_MATCH _2 = TOK_COLUMN
    {  ( )}

specif_ac_subsumes:
  _1 = TOK_AC_SUBSUMES _2 = reset_tmp_vars _3 = TOK_COLUMN _4 = set_of_terms _5 = reset_tmp_vars _6 = TOK_SEMICOLUMN _7 = set_of_terms _8 = TOK_SEMICOLUMN
    {  ( Queue.add (Ac_token (_4, _7)) yy_queue )}
| _1 = TOK_AC_SUBSUMES _2 = reset_tmp_vars _3 = TOK_COLUMN
    {  ( )}

set_of_terms:
  _1 = get_term
    {  ( [ _1 ] )}
| _1 = set_of_terms _2 = TOK_COMA _3 = get_term
    {  ( _1 @ [ _3 ] )}

two_terms:
  _1 = reset_tmp_vars _2 = get_term _3 = TOK_QUESTION_MARK _4 = get_term
    {  ( (_2, _4) )}

two_clauses:
  _1 = pos_codes_false _2 = reset_tmp_vars _3 = specif_clause _4 = TOK_QUESTION_MARK _5 = specif_clause
    {  ( (_3, _5) )}

specif_literal_position_in_clause:
  _1 = TOK_IDENT
    {  ( match _1 with
      "*" -> Pos_all
    | _ -> Pos_litdefined (true, parse_positive_int _1) )}
| _1 = TOK_IDENT _2 = bracket_enclosed_list_of_positive_ints
    {  ( Pos_defined (true, parse_positive_int _1, _2) )}
| _1 = TOK_QUESTION_MARK
    {  ( Pos_query )}

specif_clausal_position:
  _1 = TOK_IDENT _2 = TOK_IDENT _3 = bracket_enclosed_list_of_positive_ints
    {  ( let i = parse_positive_int _1
    in let b =
      match i with
        0 -> false
      | 1 -> true
      | _ -> parse_failwith "clausal position must start with 0 or 1"
    in Pos_defined (b, parse_positive_int _2, _3) )}
| _1 = TOK_IDENT
    {  ( match _1 with
      "*" -> Pos_all
    | _ -> parse_failwith "clausal position is either \"*\" or a real position" )}
| _1 = TOK_QUESTION_MARK
    {  ( Pos_query )}

bracket_enclosed_list_of_positive_ints:
  _1 = TOK_LBRACKET _2 = list_of_positive_ints _3 = TOK_RBRACKET
    {  ( _2 )}
| _1 = TOK_LBRACKET _2 = TOK_RBRACKET
    {  ( [] )}

list_of_positions:
  _1 = bracket_enclosed_list_of_positive_ints
    {  ( [List.map (fun x -> (0,x)) _1 ] )}
| _1 = list_of_positions _2 = bracket_enclosed_list_of_positive_ints
    {  ( _1 @ [List.map (fun x -> (0,x))  _2 ] )}

list_of_positive_ints:
  _1 = TOK_IDENT
    {  ( [(parse_positive_int _1) - 1] )}
| _1 = list_of_positive_ints _2 = TOK_IDENT
    {  ( _1 @ [(parse_positive_int _2) - 1] )}

specif_substitution:
  _1 = specif_substitution2 _2 = TOK_EOF
    {  ( _1 )}

specif_substitution2:
  _1 = specif_var_term
    {  ( [_1] )}
| _1 = specif_substitution2 _2 = TOK_SEMICOLUMN _3 = specif_var_term
    {  ( insert_sorted (fun (x, _) (x', _) -> x = x') (fun (x, _) (x', _) -> x < x') _3 _1 )}

specif_var_term:
  _1 = TOK_IDENT _2 = TOK_COMA _3 = specif_term
    {  (
    let v =
      try List.assoc _1 !yy_tmp_vars
      with Not_found -> let tmp_v = newvar () in let () = yy_tmp_vars := (_1, tmp_v) :: !yy_tmp_vars in tmp_v
      in

(*     let s = try List.assoc v !yy_tmp_sorts2 with Not_found -> failwith "raising Not_found in specif_var_term" in *)
    let t = process_term_tokens _3 in
    let term = typecheck_incomplete_tree (Variable_sort 0) t in
    (v,  term)
  )}

specif_positive_int:
  _1 = TOK_IDENT
    {  ( parse_positive_int _1 )}

get_term:
  _1 = specif_term
    {  ( let t = process_term_tokens _1 in
    let term_t =
      match t with
          Defined (Iterm (f, _)) ->
	    begin
	      let s =
		try
		  dico_const_sort#find f
		with Not_found -> parse_failwith "get_term"
	      in
	      typecheck_incomplete_tree (Actual_sort s) t
	    end
	| Defined (Ivar x) ->
            begin
              let s =
		try
		  List.assoc x !yy_tmp_sorts
		with Not_found -> parse_failwith "unbound types"
	      in
	      typecheck_incomplete_tree (Actual_sort s) t
            end
	| Undefined -> parse_failwith "unbound types"
    in term_t )}

list_of_terms:
  _1 = reset_tmp_vars _2 = get_term
    {  ( [_2] )}
| _1 = list_of_terms _2 = TOK_COMA _3 = reset_tmp_vars _4 = get_term
    {  ( _1 @ [_4] )}

pos_codes_true:
  
    {  ( pick_pos_codes := true )}

pos_codes_false:
  
    {  ( pick_pos_codes := false )}

specif_shell_command:
  _1 = TOK_STRATEGIES _2 = strategy_term
    {  ( Command_strategy _2 )}
| _1 = TOK_IDENT
    {  ( match _1 with
      "p" -> Command_previous
    | "n" -> Command_next
    | "r" -> Command_run
    | "d" -> Command_display
    | "exit" -> Command_exit
    | _ -> Command_error )}

print_caml:
  _1 = TOK_PRINT_CAML _2 = TOK_COLUMN _3 = pos_codes_false _4 = list_of_clauses
    {  (
    buffered_output (sprint_list "\n\nThe CAML version :" compute_string_clause_caml _4);
  )}
| _1 = TOK_PRINT_CAML _2 = TOK_COLUMN
    {  ( )}

%%


